{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. \n",
    "### Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {}\n",
    "for w in words:\n",
    "  chs = ['<S>'] + list(w) + ['<E>']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    trigram = (ch1, ch2, ch3)\n",
    "    t[trigram] = t.get(trigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'h', '<E>'), 1714),\n",
       " (('n', 'a', '<E>'), 1673),\n",
       " (('a', 'n', '<E>'), 1509),\n",
       " (('o', 'n', '<E>'), 1503),\n",
       " (('<S>', 'm', 'a'), 1453),\n",
       " (('<S>', 'j', 'a'), 1255),\n",
       " (('<S>', 'k', 'a'), 1254),\n",
       " (('e', 'n', '<E>'), 1217),\n",
       " (('l', 'y', 'n'), 976),\n",
       " (('y', 'n', '<E>'), 953),\n",
       " (('a', 'r', 'i'), 950),\n",
       " (('i', 'a', '<E>'), 903),\n",
       " (('i', 'e', '<E>'), 858),\n",
       " (('a', 'n', 'n'), 825),\n",
       " (('e', 'l', 'l'), 822),\n",
       " (('a', 'n', 'a'), 804),\n",
       " (('i', 'a', 'n'), 790),\n",
       " (('m', 'a', 'r'), 776),\n",
       " (('i', 'n', '<E>'), 766),\n",
       " (('e', 'l', '<E>'), 727),\n",
       " (('y', 'a', '<E>'), 716),\n",
       " (('a', 'n', 'i'), 703),\n",
       " (('<S>', 'd', 'a'), 700),\n",
       " (('l', 'a', '<E>'), 684),\n",
       " (('e', 'r', '<E>'), 683),\n",
       " (('i', 'y', 'a'), 669),\n",
       " (('l', 'a', 'n'), 647),\n",
       " (('<S>', 'b', 'r'), 646),\n",
       " (('n', 'n', 'a'), 633),\n",
       " (('<S>', 'a', 'l'), 632),\n",
       " (('<S>', 'c', 'a'), 628),\n",
       " (('r', 'a', '<E>'), 627),\n",
       " (('n', 'i', '<E>'), 625),\n",
       " (('<S>', 'a', 'n'), 623),\n",
       " (('n', 'n', '<E>'), 619),\n",
       " (('n', 'e', '<E>'), 607),\n",
       " (('e', 'e', '<E>'), 605),\n",
       " (('e', 'y', '<E>'), 602),\n",
       " (('<S>', 'k', 'e'), 601),\n",
       " (('a', 'l', 'e'), 601),\n",
       " (('<S>', 's', 'a'), 595),\n",
       " (('a', 'l', 'i'), 575),\n",
       " (('s', 'h', 'a'), 562),\n",
       " (('e', 'l', 'i'), 537),\n",
       " (('<S>', 'd', 'e'), 524),\n",
       " (('l', 'i', 'a'), 518),\n",
       " (('l', 'e', 'e'), 517),\n",
       " (('y', 'n', 'n'), 516),\n",
       " (('y', 'a', 'h'), 511),\n",
       " (('<S>', 'h', 'a'), 505),\n",
       " (('l', 'i', 'n'), 505),\n",
       " (('r', 'i', 'a'), 499),\n",
       " (('<S>', 'e', 'l'), 488),\n",
       " (('a', 'y', 'l'), 483),\n",
       " (('<S>', 'a', 'r'), 482),\n",
       " (('y', 'a', 'n'), 479),\n",
       " (('<S>', 'r', 'a'), 472),\n",
       " (('<S>', 'n', 'a'), 470),\n",
       " (('h', 'a', 'n'), 469),\n",
       " (('<S>', 'l', 'a'), 463),\n",
       " (('i', 'a', 'h'), 461),\n",
       " (('<S>', 'z', 'a'), 456),\n",
       " (('r', 'i', '<E>'), 452),\n",
       " (('l', 'e', 'y'), 443),\n",
       " (('<S>', 's', 'h'), 434),\n",
       " (('a', 'm', 'a'), 431),\n",
       " (('<S>', 'j', 'o'), 429),\n",
       " (('<S>', 't', 'a'), 424),\n",
       " (('<S>', 'j', 'e'), 403),\n",
       " (('l', 'e', 'i'), 401),\n",
       " (('i', 'e', 'l'), 395),\n",
       " (('r', 'i', 'e'), 394),\n",
       " (('<S>', 'm', 'i'), 393),\n",
       " (('a', 'n', 'd'), 392),\n",
       " (('a', 'y', 'a'), 389),\n",
       " (('<S>', 'a', 'm'), 384),\n",
       " (('l', 'e', 'n'), 383),\n",
       " (('<S>', 'r', 'o'), 382),\n",
       " (('y', 'l', 'a'), 381),\n",
       " (('i', 'n', 'a'), 379),\n",
       " (('t', 'o', 'n'), 377),\n",
       " (('a', 'r', 'a'), 371),\n",
       " (('<S>', 'a', 'd'), 366),\n",
       " (('<S>', 'l', 'e'), 366),\n",
       " (('l', 'e', '<E>'), 362),\n",
       " (('r', 'i', 's'), 360),\n",
       " (('a', 'm', 'i'), 355),\n",
       " (('e', 'l', 'y'), 353),\n",
       " (('a', 'l', 'a'), 353),\n",
       " (('<S>', 'c', 'h'), 352),\n",
       " (('s', 'o', 'n'), 341),\n",
       " (('l', 'l', 'a'), 337),\n",
       " (('l', 'l', 'e'), 331),\n",
       " (('h', 'a', 'r'), 329),\n",
       " (('d', 'e', 'n'), 318),\n",
       " (('a', 'l', 'y'), 310),\n",
       " (('e', 'l', 'a'), 308),\n",
       " (('a', 'v', 'i'), 306),\n",
       " (('y', 'l', 'e'), 303),\n",
       " (('i', 'g', 'h'), 290),\n",
       " (('i', 'o', 'n'), 290),\n",
       " (('<S>', 'e', 'm'), 288),\n",
       " (('a', 'r', 'l'), 287),\n",
       " (('i', 's', '<E>'), 287),\n",
       " (('a', 'e', 'l'), 287),\n",
       " (('l', 'i', 'e'), 285),\n",
       " (('h', 'a', '<E>'), 284),\n",
       " (('<S>', 'm', 'e'), 284),\n",
       " (('r', 'e', 'n'), 281),\n",
       " (('u', 's', '<E>'), 280),\n",
       " (('i', 'l', 'a'), 279),\n",
       " (('e', 'n', 'a'), 279),\n",
       " (('e', 'i', 'g'), 279),\n",
       " (('a', 's', 'h'), 276),\n",
       " (('m', 'a', 'n'), 274),\n",
       " (('l', 'l', 'i'), 271),\n",
       " (('l', 'y', '<E>'), 270),\n",
       " (('<S>', 'l', 'i'), 269),\n",
       " (('<S>', 'r', 'e'), 268),\n",
       " (('e', 'r', 'i'), 268),\n",
       " (('n', 'n', 'e'), 261),\n",
       " (('a', 'i', 'l'), 259),\n",
       " (('m', 'i', 'l'), 259),\n",
       " (('<S>', 'c', 'o'), 255),\n",
       " (('b', 'r', 'i'), 254),\n",
       " (('r', 'a', 'y'), 254),\n",
       " (('<S>', 'b', 'e'), 253),\n",
       " (('s', 'a', '<E>'), 253),\n",
       " (('k', 'e', 'n'), 252),\n",
       " (('<S>', 'k', 'i'), 250),\n",
       " (('i', 'r', 'a'), 248),\n",
       " (('r', 'a', 'n'), 248),\n",
       " (('i', 'r', '<E>'), 248),\n",
       " (('<S>', 'y', 'a'), 246),\n",
       " (('<S>', 'a', 'v'), 243),\n",
       " (('i', 'n', 'e'), 241),\n",
       " (('e', 'n', 'n'), 240),\n",
       " (('<S>', 'k', 'h'), 240),\n",
       " (('v', 'a', 'n'), 237),\n",
       " (('c', 'h', 'a'), 236),\n",
       " (('g', 'h', '<E>'), 235),\n",
       " (('c', 'e', '<E>'), 234),\n",
       " (('l', 'a', 'y'), 234),\n",
       " (('r', 'i', 'n'), 234),\n",
       " (('r', 'e', '<E>'), 231),\n",
       " (('<S>', 'k', 'y'), 229),\n",
       " (('a', 'r', '<E>'), 228),\n",
       " (('s', 'e', '<E>'), 228),\n",
       " (('i', 's', 'h'), 227),\n",
       " (('a', 'm', 'e'), 226),\n",
       " (('<S>', 'n', 'i'), 226),\n",
       " (('k', 'a', 'i'), 226),\n",
       " (('l', 'a', 'h'), 224),\n",
       " (('a', 'n', 'e'), 224),\n",
       " (('n', 'i', 'e'), 223),\n",
       " (('r', 'a', 'h'), 222),\n",
       " (('l', 'i', '<E>'), 221),\n",
       " (('n', 'n', 'i'), 221),\n",
       " (('o', 'r', 'i'), 220),\n",
       " (('e', 'l', 'e'), 219),\n",
       " (('k', 'a', 'r'), 218),\n",
       " (('d', 'e', 'l'), 217),\n",
       " (('k', 'a', 'y'), 215),\n",
       " (('j', 'a', 'y'), 212),\n",
       " (('i', 'l', 'l'), 211),\n",
       " (('m', 'a', 'l'), 210),\n",
       " (('k', 'a', '<E>'), 210),\n",
       " (('m', 'e', 'r'), 209),\n",
       " (('y', 'l', 'i'), 209),\n",
       " (('<S>', 't', 'r'), 209),\n",
       " (('r', 'i', 'c'), 209),\n",
       " (('l', 'i', 's'), 208),\n",
       " (('<S>', 'a', 'a'), 207),\n",
       " (('d', 'a', 'n'), 207),\n",
       " (('r', 'e', 'e'), 205),\n",
       " (('i', 'l', 'y'), 203),\n",
       " (('e', 't', 't'), 203),\n",
       " (('d', 'a', 'l'), 203),\n",
       " (('l', 'l', '<E>'), 203),\n",
       " (('b', 'r', 'a'), 203),\n",
       " (('o', 'r', 'a'), 202),\n",
       " (('b', 'e', 'l'), 201),\n",
       " (('r', 'y', '<E>'), 201),\n",
       " (('<S>', 'r', 'i'), 201),\n",
       " (('m', 'o', 'n'), 201),\n",
       " (('e', 'e', 'n'), 200),\n",
       " (('a', 'r', 'e'), 198),\n",
       " (('i', 'l', 'e'), 197),\n",
       " (('t', 'a', '<E>'), 197),\n",
       " (('d', 'a', '<E>'), 197),\n",
       " (('e', 'a', 'n'), 196),\n",
       " (('a', 'l', 'l'), 196),\n",
       " (('r', 'o', 's'), 196),\n",
       " (('a', 'r', 'y'), 195),\n",
       " (('a', 'd', 'e'), 194),\n",
       " (('<S>', 'a', 's'), 194),\n",
       " (('o', 'n', 'n'), 194),\n",
       " (('c', 'a', 'r'), 193),\n",
       " (('n', 'y', '<E>'), 192),\n",
       " (('<S>', 'k', 'o'), 192),\n",
       " (('a', 'r', 'r'), 192),\n",
       " (('<S>', 'a', 'b'), 190),\n",
       " (('a', 'd', 'i'), 190),\n",
       " (('b', 'r', 'e'), 189),\n",
       " (('a', 'i', 'r'), 189),\n",
       " (('a', 'm', '<E>'), 189),\n",
       " (('o', 'n', 'i'), 189),\n",
       " (('m', 'e', 'l'), 188),\n",
       " (('<S>', 'l', 'o'), 186),\n",
       " (('n', 'a', 'h'), 185),\n",
       " (('n', 'd', 'r'), 184),\n",
       " (('a', 'i', '<E>'), 183),\n",
       " (('<S>', 's', 'e'), 182),\n",
       " (('r', 'r', 'i'), 182),\n",
       " (('<S>', 't', 'e'), 181),\n",
       " (('i', 'l', 'i'), 180),\n",
       " (('e', 'y', 'a'), 179),\n",
       " (('t', 'h', '<E>'), 178),\n",
       " (('<S>', 'j', 'u'), 178),\n",
       " (('a', 'y', 'd'), 178),\n",
       " (('l', 'a', 'i'), 177),\n",
       " (('a', 'n', 't'), 177),\n",
       " (('a', 'i', 'n'), 177),\n",
       " (('t', 'e', '<E>'), 175),\n",
       " (('<S>', 'p', 'a'), 175),\n",
       " (('i', 'k', 'a'), 175),\n",
       " (('a', 'n', 'y'), 175),\n",
       " (('a', 'l', '<E>'), 175),\n",
       " (('m', 'a', '<E>'), 174),\n",
       " (('a', 'a', 'n'), 174),\n",
       " (('a', 'b', 'e'), 173),\n",
       " (('l', 'e', 'a'), 173),\n",
       " (('<S>', 'a', 'y'), 173),\n",
       " (('a', 's', '<E>'), 173),\n",
       " (('<S>', 's', 'i'), 172),\n",
       " (('m', 'i', 'r'), 172),\n",
       " (('s', 'i', 'a'), 171),\n",
       " (('k', 'h', 'a'), 171),\n",
       " (('e', 'r', 'e'), 170),\n",
       " (('s', 'h', 'i'), 170),\n",
       " (('<S>', 'b', 'a'), 169),\n",
       " (('t', 'h', 'a'), 168),\n",
       " (('e', 'n', 'i'), 168),\n",
       " (('<S>', 'm', 'o'), 168),\n",
       " (('k', 'a', 'l'), 168),\n",
       " (('r', 'o', 'n'), 168),\n",
       " (('a', 'v', 'e'), 166),\n",
       " (('o', 's', 'e'), 166),\n",
       " (('s', 's', 'a'), 166),\n",
       " (('<S>', 'g', 'r'), 165),\n",
       " (('s', 't', 'o'), 165),\n",
       " (('<S>', 'n', 'e'), 164),\n",
       " (('a', 'd', 'a'), 164),\n",
       " (('r', 'e', 'y'), 163),\n",
       " (('a', 'y', '<E>'), 163),\n",
       " (('<S>', 'l', 'u'), 162),\n",
       " (('d', 'r', 'i'), 162),\n",
       " (('a', 'v', 'a'), 161),\n",
       " (('<S>', 'v', 'i'), 161),\n",
       " (('e', 'm', 'i'), 160),\n",
       " (('v', 'e', 'r'), 160),\n",
       " (('s', 't', 'i'), 159),\n",
       " (('s', 'a', 'n'), 159),\n",
       " (('<S>', 'f', 'a'), 158),\n",
       " (('e', 'a', '<E>'), 158),\n",
       " (('a', 's', 'i'), 157),\n",
       " (('<S>', 'n', 'o'), 156),\n",
       " (('i', 's', 't'), 156),\n",
       " (('<S>', 'e', 'v'), 154),\n",
       " (('s', 't', 'e'), 154),\n",
       " (('<S>', 'a', 'i'), 154),\n",
       " (('t', 'a', 'l'), 153),\n",
       " (('l', 'a', 'r'), 153),\n",
       " (('m', 'a', 'y'), 153),\n",
       " (('e', 's', 's'), 153),\n",
       " (('h', 'a', 'l'), 153),\n",
       " (('d', 'a', 'r'), 153),\n",
       " (('h', 'a', 'm'), 153),\n",
       " (('<S>', 's', 'o'), 152),\n",
       " (('<S>', 'a', 'u'), 152),\n",
       " (('b', 'e', 'r'), 152),\n",
       " (('<S>', 'a', 'z'), 152),\n",
       " (('e', 'n', 'e'), 151),\n",
       " (('k', 'a', 'm'), 151),\n",
       " (('<S>', 'h', 'e'), 151),\n",
       " (('j', 'a', 'm'), 151),\n",
       " (('s', 'h', '<E>'), 149),\n",
       " (('d', 'e', 'r'), 149),\n",
       " (('o', 'r', '<E>'), 148),\n",
       " (('v', 'i', 'n'), 148),\n",
       " (('v', 'i', 'a'), 147),\n",
       " (('e', 's', 't'), 147),\n",
       " (('l', 'o', 'n'), 147),\n",
       " (('o', 'n', 'a'), 147),\n",
       " (('a', 'e', '<E>'), 147),\n",
       " (('r', 'l', 'e'), 146),\n",
       " (('r', 'i', 'o'), 146),\n",
       " (('n', 'e', 'l'), 145),\n",
       " (('a', 'i', 's'), 145),\n",
       " (('e', 'r', 'a'), 145),\n",
       " (('n', 'l', 'e'), 143),\n",
       " (('r', 'e', 'l'), 143),\n",
       " (('h', 'i', '<E>'), 143),\n",
       " (('i', 's', 'a'), 142),\n",
       " (('e', 'v', 'e'), 142),\n",
       " (('t', 'i', 'n'), 142),\n",
       " (('a', 't', 'h'), 142),\n",
       " (('d', 'o', 'n'), 142),\n",
       " (('s', 'e', 'n'), 142),\n",
       " (('m', 'i', 'n'), 141),\n",
       " (('<S>', 's', 'u'), 141),\n",
       " (('k', 'e', 'l'), 141),\n",
       " (('t', 'a', 'n'), 141),\n",
       " (('n', 'i', 'a'), 141),\n",
       " (('r', 'y', 'n'), 140),\n",
       " (('j', 'a', 'n'), 140),\n",
       " (('n', 'a', 'l'), 140),\n",
       " (('e', 'r', 'r'), 140),\n",
       " (('e', 'm', 'a'), 140),\n",
       " (('s', 't', 'a'), 139),\n",
       " (('i', 'o', '<E>'), 139),\n",
       " (('s', 'l', 'e'), 138),\n",
       " (('a', 'i', 'd'), 138),\n",
       " (('e', 's', '<E>'), 138),\n",
       " (('l', 'o', 'r'), 137),\n",
       " (('m', 'a', 'd'), 136),\n",
       " (('s', 'a', 'm'), 136),\n",
       " (('<S>', 'g', 'a'), 136),\n",
       " (('r', 'i', 'y'), 136),\n",
       " (('<S>', 's', 't'), 135),\n",
       " (('i', 'e', 'r'), 135),\n",
       " (('<S>', 'z', 'e'), 135),\n",
       " (('j', 'a', 'h'), 135),\n",
       " (('k', 'i', 'n'), 134),\n",
       " (('l', 'i', 'l'), 133),\n",
       " (('e', 'v', 'a'), 133),\n",
       " (('h', 'a', 'y'), 133),\n",
       " (('t', 'e', 'r'), 133),\n",
       " (('a', 'y', 's'), 133),\n",
       " (('<S>', 't', 'y'), 133),\n",
       " (('h', 'e', 'r'), 132),\n",
       " (('r', 'a', 'i'), 132),\n",
       " (('e', 'o', 'n'), 131),\n",
       " (('<S>', 'd', 'i'), 130),\n",
       " (('c', 'h', 'e'), 130),\n",
       " (('a', 'c', 'e'), 129),\n",
       " (('i', 'c', 'k'), 129),\n",
       " (('d', 'y', '<E>'), 128),\n",
       " (('<S>', 'g', 'i'), 128),\n",
       " (('e', 'm', '<E>'), 128),\n",
       " (('y', 'o', 'n'), 128),\n",
       " (('r', 'a', 'e'), 127),\n",
       " (('n', 'c', 'e'), 127),\n",
       " (('i', 's', 'e'), 126),\n",
       " (('n', 'd', '<E>'), 126),\n",
       " (('<S>', 'p', 'r'), 125),\n",
       " (('i', 'n', 'g'), 125),\n",
       " (('<S>', 'i', 's'), 124),\n",
       " (('m', 'i', '<E>'), 124),\n",
       " (('i', 't', 'h'), 124),\n",
       " (('l', 'l', 'y'), 124),\n",
       " (('o', 'l', 'a'), 124),\n",
       " (('u', 'r', 'i'), 123),\n",
       " (('a', 'z', 'a'), 123),\n",
       " (('j', 'e', 'r'), 123),\n",
       " (('i', 'r', 'e'), 122),\n",
       " (('i', 's', 's'), 122),\n",
       " (('t', 't', 'e'), 121),\n",
       " (('<S>', 'v', 'a'), 121),\n",
       " (('c', 'a', 'l'), 121),\n",
       " (('a', 'k', 'a'), 121),\n",
       " (('z', 'a', 'r'), 121),\n",
       " (('y', 'd', 'e'), 121),\n",
       " (('v', 'i', '<E>'), 121),\n",
       " (('g', 'r', 'a'), 120),\n",
       " (('m', 'a', 'i'), 120),\n",
       " (('c', 'k', '<E>'), 120),\n",
       " (('i', 'l', '<E>'), 119),\n",
       " (('h', 'a', 'i'), 119),\n",
       " (('e', 'n', 'd'), 119),\n",
       " (('v', 'e', 'n'), 119),\n",
       " (('<S>', 'd', 'o'), 119),\n",
       " (('r', 'i', 't'), 119),\n",
       " (('v', 'o', 'n'), 119),\n",
       " (('<S>', 'l', 'y'), 118),\n",
       " (('r', 'y', 'a'), 118),\n",
       " (('l', 'i', 'y'), 117),\n",
       " (('s', 'e', 'l'), 117),\n",
       " (('i', 'm', 'a'), 117),\n",
       " (('b', 'r', 'y'), 116),\n",
       " (('e', 't', 'h'), 114),\n",
       " (('d', 'r', 'e'), 113),\n",
       " (('n', 'a', 'y'), 113),\n",
       " (('k', 'a', 's'), 113),\n",
       " (('t', 'e', 'n'), 113),\n",
       " (('h', 'e', 'l'), 112),\n",
       " (('o', 'r', 'e'), 112),\n",
       " (('<S>', 't', 'o'), 112),\n",
       " (('a', 't', 'a'), 111),\n",
       " (('<S>', 'r', 'y'), 111),\n",
       " (('e', 'i', 'l'), 111),\n",
       " (('r', 'a', 'l'), 111),\n",
       " (('h', 'r', 'i'), 111),\n",
       " (('a', 'h', 'a'), 111),\n",
       " (('t', 'o', 'r'), 110),\n",
       " (('<S>', 'g', 'e'), 110),\n",
       " (('a', 'n', 'g'), 110),\n",
       " (('i', 'd', 'e'), 110),\n",
       " (('m', 'a', 'k'), 109),\n",
       " (('<S>', 't', 'i'), 109),\n",
       " (('n', 'd', 'e'), 109),\n",
       " (('a', 'u', 'r'), 108),\n",
       " (('<S>', 'r', 'u'), 108),\n",
       " (('d', 'y', 'n'), 108),\n",
       " (('n', 'i', 'y'), 108),\n",
       " (('s', 'h', 'e'), 108),\n",
       " (('t', 'r', 'i'), 107),\n",
       " (('n', 'i', 's'), 107),\n",
       " (('n', 'o', '<E>'), 107),\n",
       " (('e', 't', '<E>'), 106),\n",
       " (('d', 'i', 'e'), 106),\n",
       " (('t', 'h', 'e'), 106),\n",
       " (('h', 'e', 'n'), 106),\n",
       " (('a', 'd', '<E>'), 106),\n",
       " (('a', 'i', 'a'), 105),\n",
       " (('j', 'a', 'i'), 105),\n",
       " (('<S>', 'o', 'l'), 104),\n",
       " (('k', 'y', 'l'), 104),\n",
       " (('d', 'i', '<E>'), 104),\n",
       " (('n', 'a', 'n'), 104),\n",
       " (('t', 'r', 'e'), 104),\n",
       " (('l', 'o', '<E>'), 104),\n",
       " (('r', 'a', 'c'), 103),\n",
       " (('a', 'r', 'o'), 103),\n",
       " (('i', 'n', 'n'), 103),\n",
       " (('<S>', 'm', 'y'), 103),\n",
       " (('s', 's', 'i'), 103),\n",
       " (('t', 't', '<E>'), 102),\n",
       " (('c', 'o', 'r'), 102),\n",
       " (('a', 's', 't'), 102),\n",
       " (('a', 'r', 't'), 102),\n",
       " (('n', 'a', 'i'), 102),\n",
       " (('n', 'o', 'r'), 101),\n",
       " (('n', 'a', 't'), 101),\n",
       " (('e', 'r', 'l'), 101),\n",
       " (('l', 'e', 's'), 101),\n",
       " (('a', 'm', 'o'), 101),\n",
       " (('a', 'h', 'i'), 101),\n",
       " (('a', 'i', 'y'), 101),\n",
       " (('o', 'n', 't'), 101),\n",
       " (('e', 'm', 'm'), 100),\n",
       " (('t', 'y', 'n'), 100),\n",
       " (('h', 'a', 'd'), 99),\n",
       " (('g', 'a', 'n'), 99),\n",
       " (('<S>', 't', 'h'), 99),\n",
       " (('i', 't', 'a'), 99),\n",
       " (('l', 'y', 'a'), 99),\n",
       " (('a', 'n', 's'), 99),\n",
       " (('a', 'k', 'i'), 99),\n",
       " (('a', 'n', 'o'), 98),\n",
       " (('d', 'i', 'a'), 98),\n",
       " (('z', 'a', '<E>'), 98),\n",
       " (('m', 'o', 'r'), 98),\n",
       " (('a', 'y', 'n'), 98),\n",
       " (('a', 'k', 'e'), 98),\n",
       " (('m', 'a', 't'), 98),\n",
       " (('y', 'i', 'a'), 98),\n",
       " (('r', 'l', 'i'), 97),\n",
       " (('y', 'e', 'l'), 97),\n",
       " (('z', 'a', 'y'), 97),\n",
       " (('r', 'a', 'm'), 97),\n",
       " (('v', 'a', 'l'), 96),\n",
       " (('u', 'l', 'i'), 96),\n",
       " (('y', 'r', 'i'), 96),\n",
       " (('a', 's', 's'), 96),\n",
       " (('i', 'd', 'a'), 96),\n",
       " (('h', 'o', 'n'), 96),\n",
       " (('<S>', 'k', 'r'), 96),\n",
       " (('m', 'i', 'a'), 95),\n",
       " (('e', 'n', 't'), 95),\n",
       " (('v', 'i', 'e'), 95),\n",
       " (('i', 'm', '<E>'), 95),\n",
       " (('a', 'd', 'd'), 94),\n",
       " (('c', 'h', 'i'), 94),\n",
       " (('i', 'k', '<E>'), 94),\n",
       " (('v', 'a', '<E>'), 93),\n",
       " (('i', 'z', 'a'), 93),\n",
       " (('n', 'e', 's'), 93),\n",
       " (('j', 'o', 's'), 93),\n",
       " (('k', 'a', 't'), 93),\n",
       " (('<S>', 'e', 's'), 93),\n",
       " (('y', 'n', 'e'), 93),\n",
       " (('a', 'z', 'i'), 93),\n",
       " (('c', 'a', 'm'), 92),\n",
       " (('<S>', 'p', 'e'), 92),\n",
       " (('e', 'a', 'h'), 92),\n",
       " (('d', 'e', '<E>'), 92),\n",
       " (('c', 'e', 'l'), 92),\n",
       " (('<S>', 'n', 'y'), 92),\n",
       " (('a', 'r', 's'), 92),\n",
       " (('a', 'r', 'd'), 92),\n",
       " (('l', 'e', 't'), 91),\n",
       " (('<S>', 'w', 'i'), 91),\n",
       " (('i', 'e', 'n'), 91),\n",
       " (('a', 'm', 'y'), 91),\n",
       " (('e', 'i', '<E>'), 91),\n",
       " (('<S>', 'z', 'y'), 91),\n",
       " (('d', 'a', 'm'), 91),\n",
       " (('r', 'o', '<E>'), 91),\n",
       " (('<S>', 'a', 'h'), 91),\n",
       " (('i', 'u', 's'), 91),\n",
       " (('o', 'v', 'a'), 90),\n",
       " (('s', 'a', 'l'), 90),\n",
       " (('n', 'i', 'c'), 90),\n",
       " (('y', 'n', 'a'), 90),\n",
       " (('n', 'd', 'a'), 90),\n",
       " (('<S>', 'e', 'r'), 90),\n",
       " (('d', 'a', 'y'), 90),\n",
       " (('<S>', 'r', 'h'), 90),\n",
       " (('v', 'i', 'o'), 89),\n",
       " (('s', 'y', 'n'), 89),\n",
       " (('n', 'a', 's'), 89),\n",
       " (('m', 'a', 'h'), 89),\n",
       " (('t', 'y', '<E>'), 88),\n",
       " (('a', 'r', 'm'), 88),\n",
       " (('a', 'h', 'm'), 88),\n",
       " (('r', 'e', 't'), 87),\n",
       " (('l', 'e', 'r'), 87),\n",
       " (('i', 'n', 'i'), 87),\n",
       " (('j', 'e', 'n'), 87),\n",
       " (('i', 'n', 'd'), 87),\n",
       " (('g', 'e', 'n'), 86),\n",
       " (('d', 'r', 'a'), 86),\n",
       " (('r', 'e', 's'), 86),\n",
       " (('n', 'g', 'e'), 86),\n",
       " (('o', 'n', 'e'), 86),\n",
       " (('<S>', 'z', 'i'), 86),\n",
       " (('<S>', 'y', 'u'), 86),\n",
       " (('<S>', 'y', 'o'), 86),\n",
       " (('a', 'b', 'r'), 85),\n",
       " (('g', 'e', 'l'), 85),\n",
       " (('<S>', 'b', 'l'), 85),\n",
       " (('d', 'e', 'm'), 85),\n",
       " (('e', 'y', 'l'), 85),\n",
       " (('<S>', 'm', 'u'), 85),\n",
       " (('e', 'r', 'y'), 84),\n",
       " (('l', 'y', 's'), 84),\n",
       " (('h', 'i', 'r'), 84),\n",
       " (('b', 'e', 'n'), 84),\n",
       " (('o', 'l', 'u'), 84),\n",
       " (('u', 'w', 'a'), 84),\n",
       " (('e', 'l', 'o'), 83),\n",
       " (('z', 'e', 'l'), 83),\n",
       " (('o', 'l', 'e'), 83),\n",
       " (('s', 'a', 'r'), 83),\n",
       " (('l', 'e', 'x'), 83),\n",
       " (('e', 'v', 'i'), 83),\n",
       " (('a', 'n', 'c'), 83),\n",
       " (('a', 'a', 'r'), 83),\n",
       " (('e', 's', 'h'), 83),\n",
       " (('<S>', 'q', 'u'), 82),\n",
       " (('j', 'a', 's'), 82),\n",
       " (('m', 'i', 'k'), 82),\n",
       " (('r', 'e', 'i'), 82),\n",
       " (('a', 's', 'e'), 82),\n",
       " (('y', 'l', 'y'), 82),\n",
       " (('n', 'g', '<E>'), 82),\n",
       " (('n', 't', 'a'), 82),\n",
       " (('h', 'i', 'a'), 81),\n",
       " (('l', 'i', 'z'), 81),\n",
       " (('t', 'a', 'y'), 81),\n",
       " (('m', 'a', 'e'), 81),\n",
       " (('j', 'a', 'c'), 81),\n",
       " (('a', 'l', 'o'), 81),\n",
       " (('h', 'i', 'l'), 81),\n",
       " (('n', 'i', 'k'), 81),\n",
       " (('n', 'n', 'y'), 81),\n",
       " (('s', 's', 'e'), 81),\n",
       " (('r', 'l', 'y'), 80),\n",
       " (('e', 'm', 'e'), 80),\n",
       " (('<S>', 'e', 'd'), 80),\n",
       " (('n', 'e', 'e'), 80),\n",
       " (('r', 'r', 'a'), 80),\n",
       " (('m', 'i', 'e'), 80),\n",
       " (('n', 'y', 'a'), 80),\n",
       " (('o', 'u', 'r'), 79),\n",
       " (('<S>', 'f', 'r'), 79),\n",
       " (('a', 'y', 'v'), 79),\n",
       " (('e', 'e', 'l'), 79),\n",
       " (('l', 'u', 'w'), 79),\n",
       " (('i', 'v', 'i'), 78),\n",
       " (('z', 'i', 'e'), 78),\n",
       " (('c', 'o', 'l'), 78),\n",
       " (('y', 'r', 'a'), 78),\n",
       " (('l', 'i', 'o'), 78),\n",
       " (('u', 'n', '<E>'), 78),\n",
       " (('p', 'e', 'r'), 77),\n",
       " (('m', 'a', 'c'), 77),\n",
       " (('o', 'r', 'd'), 77),\n",
       " (('a', 'c', 'h'), 77),\n",
       " (('<S>', 'h', 'o'), 77),\n",
       " (('n', 't', 'e'), 77),\n",
       " (('y', 'a', 'r'), 77),\n",
       " (('j', 'a', 'l'), 77),\n",
       " (('<S>', 'd', 'r'), 77),\n",
       " (('<S>', 'b', 'o'), 77),\n",
       " (('y', 'c', 'e'), 77),\n",
       " (('o', 's', '<E>'), 77),\n",
       " (('s', 'a', 'b'), 76),\n",
       " (('v', 'e', 'l'), 76),\n",
       " (('a', 'b', 'i'), 76),\n",
       " (('e', 'r', 's'), 76),\n",
       " (('n', 'e', 'y'), 76),\n",
       " (('i', 'c', 'h'), 76),\n",
       " (('c', 'a', 's'), 76),\n",
       " (('a', 'y', 'e'), 76),\n",
       " (('u', 's', 't'), 76),\n",
       " (('n', 'a', 'v'), 76),\n",
       " (('d', 'i', 'n'), 76),\n",
       " (('t', 'r', 'a'), 76),\n",
       " (('e', 'e', 'm'), 76),\n",
       " (('u', 'a', 'n'), 76),\n",
       " (('r', 'y', 'l'), 75),\n",
       " (('i', 'r', 'i'), 75),\n",
       " (('m', 'i', 'y'), 75),\n",
       " (('u', 'e', 'l'), 75),\n",
       " (('k', 'e', 'i'), 75),\n",
       " (('k', 'y', 'n'), 75),\n",
       " (('t', 'i', 'a'), 75),\n",
       " (('<S>', 'a', 'k'), 75),\n",
       " (('o', 'm', 'i'), 74),\n",
       " (('j', 'u', 'l'), 74),\n",
       " (('s', 'i', 'e'), 74),\n",
       " (('a', 't', 'i'), 74),\n",
       " (('a', 'h', 'l'), 73),\n",
       " (('<S>', 'j', 'i'), 73),\n",
       " (('a', 't', 't'), 73),\n",
       " (('z', 'a', 'n'), 73),\n",
       " (('e', 'e', 'r'), 73),\n",
       " (('m', 'm', 'a'), 72),\n",
       " (('<S>', 'z', 'o'), 72),\n",
       " (('r', 'e', 'a'), 72),\n",
       " (('<S>', 'a', 't'), 72),\n",
       " (('y', 'l', 'o'), 72),\n",
       " (('t', 'h', 'i'), 72),\n",
       " (('k', 'e', 'y'), 72),\n",
       " (('n', 'a', 'r'), 72),\n",
       " (('r', 'r', 'e'), 72),\n",
       " (('<S>', 'f', 'i'), 71),\n",
       " (('<S>', 's', 'y'), 71),\n",
       " (('c', 'i', 'a'), 71),\n",
       " (('d', 'e', 's'), 71),\n",
       " (('o', 'h', 'a'), 71),\n",
       " (('s', 'a', 'i'), 71),\n",
       " (('t', 'a', 'r'), 71),\n",
       " (('z', 'i', 'a'), 71),\n",
       " (('i', 'n', 'o'), 71),\n",
       " (('e', 'd', '<E>'), 71),\n",
       " (('o', 'l', 'l'), 70),\n",
       " (('q', 'u', 'e'), 70),\n",
       " (('i', 'v', 'a'), 70),\n",
       " (('a', 'r', 'c'), 70),\n",
       " (('k', 'a', 'n'), 70),\n",
       " (('o', 'l', 'i'), 69),\n",
       " (('b', 'r', 'o'), 69),\n",
       " (('l', 'u', 'c'), 69),\n",
       " (('k', 'e', 'r'), 69),\n",
       " (('d', 'a', 'i'), 69),\n",
       " (('r', 'e', 'm'), 69),\n",
       " (('a', 'd', 'r'), 69),\n",
       " (('c', 'h', 'r'), 69),\n",
       " (('d', 'a', 'v'), 69),\n",
       " (('z', 'a', 'i'), 69),\n",
       " (('l', 'a', 'm'), 69),\n",
       " (('y', 'a', 's'), 69),\n",
       " (('m', 'e', 'e'), 69),\n",
       " (('i', 's', 'o'), 68),\n",
       " (('<S>', 'c', 'l'), 68),\n",
       " (('e', 'n', 'z'), 68),\n",
       " (('r', 'y', 's'), 68),\n",
       " (('<S>', 'w', 'a'), 68),\n",
       " (('s', 'i', 'r'), 68),\n",
       " (('i', 'h', 'a'), 68),\n",
       " (('o', 'u', 's'), 68),\n",
       " (('s', 'e', 'r'), 67),\n",
       " (('q', 'u', 'i'), 67),\n",
       " (('<S>', 'v', 'e'), 67),\n",
       " (('m', 'i', 'c'), 67),\n",
       " (('<S>', 'c', 'r'), 67),\n",
       " (('<S>', 'h', 'u'), 67),\n",
       " (('<S>', 'i', 'l'), 67),\n",
       " (('s', 't', 'y'), 67),\n",
       " (('a', 'i', 'z'), 67),\n",
       " (('l', 'a', 'k'), 66),\n",
       " (('a', 't', 'e'), 66),\n",
       " (('i', 'c', '<E>'), 66),\n",
       " (('z', 'a', 'l'), 66),\n",
       " (('i', 'd', '<E>'), 66),\n",
       " (('o', 'm', 'a'), 66),\n",
       " (('h', 'a', 'w'), 66),\n",
       " (('a', 'u', 'n'), 66),\n",
       " (('<S>', 'c', 'e'), 65),\n",
       " (('i', 'l', 'o'), 65),\n",
       " (('a', 'b', 'd'), 65),\n",
       " (('d', 'o', '<E>'), 65),\n",
       " (('d', 'i', 'l'), 64),\n",
       " (('e', 'r', 'o'), 64),\n",
       " (('k', 'r', 'i'), 64),\n",
       " (('y', 's', '<E>'), 64),\n",
       " (('o', 'r', 'r'), 64),\n",
       " (('t', 'e', 'l'), 63),\n",
       " (('i', 's', 'l'), 63),\n",
       " (('n', 's', 'l'), 63),\n",
       " (('i', 'c', 'e'), 63),\n",
       " (('m', 'y', 'a'), 63),\n",
       " (('o', 's', 'a'), 63),\n",
       " (('c', 'a', '<E>'), 63),\n",
       " (('n', 'e', 't'), 63),\n",
       " (('k', 'e', 'e'), 63),\n",
       " (('k', 'o', 'l'), 63),\n",
       " (('d', 'e', 'e'), 63),\n",
       " (('r', 'i', 'l'), 62),\n",
       " (('o', 'r', 'y'), 62),\n",
       " (('k', 'o', 'r'), 62),\n",
       " (('j', 'a', 'k'), 62),\n",
       " (('h', 'a', 's'), 62),\n",
       " (('h', 'a', 'a'), 62),\n",
       " (('i', 'm', 'i'), 62),\n",
       " (('p', 'h', 'i'), 61),\n",
       " (('b', 'e', 't'), 61),\n",
       " (('u', 'n', 'a'), 61),\n",
       " (('a', 'r', 'k'), 61),\n",
       " (('e', 's', 'l'), 61),\n",
       " (('a', 'y', 't'), 61),\n",
       " (('i', 'v', 'e'), 61),\n",
       " (('j', 'e', 's'), 61),\n",
       " (('e', 'n', 's'), 61),\n",
       " (('e', 'n', 'l'), 61),\n",
       " (('k', 'a', 'e'), 61),\n",
       " (('<S>', 'w', 'e'), 61),\n",
       " (('<S>', 'y', 'e'), 61),\n",
       " (('a', 'z', 'e'), 60),\n",
       " (('c', 'l', 'a'), 60),\n",
       " (('m', 'e', 'n'), 60),\n",
       " (('l', 'e', 'o'), 60),\n",
       " (('<S>', 'e', 'n'), 60),\n",
       " (('n', 'd', 'i'), 60),\n",
       " (('r', 'i', 'k'), 60),\n",
       " (('<S>', 'i', 'n'), 60),\n",
       " (('t', 'l', 'e'), 60),\n",
       " (('s', 'i', 'n'), 60),\n",
       " (('t', 'i', '<E>'), 60),\n",
       " (('g', 'e', 'r'), 60),\n",
       " (('a', 's', 'a'), 60),\n",
       " (('a', 'c', 'k'), 59),\n",
       " (('m', 'b', 'e'), 59),\n",
       " (('c', 'i', 'e'), 59),\n",
       " (('<S>', 'i', 'z'), 59),\n",
       " (('a', 'd', 'o'), 59),\n",
       " (('d', 'o', 'r'), 59),\n",
       " (('y', 's', 'e'), 59),\n",
       " (('s', 'l', 'y'), 59),\n",
       " (('z', 'l', 'e'), 59),\n",
       " (('i', 'j', 'a'), 59),\n",
       " (('n', 'e', 'r'), 59),\n",
       " (('w', 'a', '<E>'), 59),\n",
       " (('a', 'v', 'o'), 59),\n",
       " (('i', 'i', '<E>'), 59),\n",
       " (('k', 'o', '<E>'), 59),\n",
       " (('l', 'l', 'o'), 58),\n",
       " (('i', 'n', 's'), 58),\n",
       " (('n', 'i', 't'), 58),\n",
       " (('e', 'n', 'c'), 58),\n",
       " (('y', 's', 'o'), 58),\n",
       " (('g', 'h', 'a'), 58),\n",
       " (('a', 'y', 'c'), 58),\n",
       " (('i', 'z', 'e'), 58),\n",
       " (('v', 'i', 'k'), 58),\n",
       " (('k', 'i', '<E>'), 58),\n",
       " (('t', 'o', '<E>'), 58),\n",
       " (('e', 's', 'i'), 57),\n",
       " (('h', 'i', 'n'), 57),\n",
       " (('e', 'i', 'a'), 57),\n",
       " (('i', 'c', 'a'), 57),\n",
       " (('r', 'o', 'm'), 57),\n",
       " (('r', 'm', 'a'), 57),\n",
       " (('h', 'y', 'a'), 57),\n",
       " (('a', 'd', 'y'), 57),\n",
       " (('a', 'h', 'n'), 57),\n",
       " (('<S>', 'x', 'a'), 57),\n",
       " (('r', 'd', '<E>'), 57),\n",
       " (('w', 'i', 'l'), 56),\n",
       " (('e', 'd', 'e'), 56),\n",
       " (('a', 'c', 'i'), 56),\n",
       " (('u', 'r', 'a'), 56),\n",
       " (('h', 'l', 'a'), 56),\n",
       " (('j', 'a', 'z'), 56),\n",
       " (('s', 's', '<E>'), 56),\n",
       " (('a', 't', '<E>'), 56),\n",
       " (('c', 'a', 'i'), 56),\n",
       " (('d', 'e', 'v'), 56),\n",
       " (('v', 'a', 'r'), 56),\n",
       " (('q', 'u', 'a'), 56),\n",
       " (('<S>', 's', 'k'), 55),\n",
       " (('b', 'y', '<E>'), 55),\n",
       " (('k', 'i', 'a'), 55),\n",
       " (('w', 'i', 'n'), 55),\n",
       " (('t', 'a', 'v'), 55),\n",
       " (('j', 'o', 'h'), 55),\n",
       " (('l', 'a', 's'), 55),\n",
       " (('e', 'd', 'a'), 55),\n",
       " (('f', 'a', 'r'), 55),\n",
       " (('z', 'e', 'n'), 55),\n",
       " (('j', 'a', '<E>'), 55),\n",
       " (('<S>', 'a', 'e'), 55),\n",
       " (('<S>', 'h', 'i'), 55),\n",
       " (('i', 't', '<E>'), 55),\n",
       " (('a', 'y', 'm'), 55),\n",
       " (('t', 'a', 'i'), 55),\n",
       " (('i', 'a', 's'), 55),\n",
       " (('l', 'i', 'v'), 54),\n",
       " (('f', 'i', 'n'), 54),\n",
       " (('j', 'o', 'r'), 54),\n",
       " (('m', 'y', '<E>'), 54),\n",
       " (('r', 'n', 'e'), 54),\n",
       " (('b', 'l', 'a'), 54),\n",
       " (('i', 'a', 'r'), 54),\n",
       " (('a', 'l', 'd'), 54),\n",
       " (('a', 'm', 'r'), 54),\n",
       " (('f', 'r', 'a'), 54),\n",
       " (('n', 't', 'o'), 54),\n",
       " (('s', 'i', '<E>'), 54),\n",
       " (('<S>', 'e', 'i'), 54),\n",
       " (('n', 's', 'h'), 54),\n",
       " (('y', 'r', 'e'), 54),\n",
       " (('n', 'd', 'y'), 53),\n",
       " (('h', 'a', 'v'), 53),\n",
       " (('k', 'a', 'h'), 53),\n",
       " (('t', 't', 'a'), 53),\n",
       " (('s', 'o', 'l'), 53),\n",
       " (('r', 'i', 'g'), 53),\n",
       " (('a', 'e', 'd'), 53),\n",
       " (('n', 'o', 'v'), 52),\n",
       " (('c', 'k', 'e'), 52),\n",
       " (('e', 'g', 'a'), 52),\n",
       " (('i', 'a', 'm'), 52),\n",
       " (('<S>', 'p', 'h'), 52),\n",
       " (('e', 's', 'a'), 52),\n",
       " (('<S>', 'e', 'z'), 52),\n",
       " (('u', 'e', '<E>'), 52),\n",
       " (('h', 'y', 'l'), 52),\n",
       " (('a', 'k', 'y'), 52),\n",
       " (('a', 'w', 'n'), 52),\n",
       " (('a', 'j', 'a'), 52),\n",
       " (('i', 'k', 'o'), 52),\n",
       " (('d', 'd', 'i'), 51),\n",
       " (('g', 'a', 'r'), 51),\n",
       " (('n', 'd', 'o'), 51),\n",
       " (('e', 'i', 'r'), 51),\n",
       " (('s', 'e', 'y'), 51),\n",
       " (('t', 'i', 'e'), 51),\n",
       " (('a', 'm', 'b'), 51),\n",
       " (('p', 'r', 'i'), 51),\n",
       " (('e', 'r', 't'), 51),\n",
       " (('r', 'i', 'd'), 51),\n",
       " (('k', 'i', 'e'), 51),\n",
       " (('j', 'a', 'e'), 51),\n",
       " (('i', 't', 't'), 51),\n",
       " (('h', 'i', 't'), 51),\n",
       " (('a', 'i', 'm'), 51),\n",
       " (('w', 'n', '<E>'), 51),\n",
       " (('r', 'a', 'd'), 51),\n",
       " (('a', 'y', 'o'), 51),\n",
       " (('e', 'a', 'l'), 51),\n",
       " (('g', 'i', 'a'), 50),\n",
       " (('e', 'p', 'h'), 50),\n",
       " (('a', 'i', 't'), 50),\n",
       " (('i', 'x', '<E>'), 50),\n",
       " (('z', 'a', 'h'), 50),\n",
       " (('c', 'a', 'y'), 50),\n",
       " (('a', 'n', 'u'), 50),\n",
       " (('e', 'k', '<E>'), 50),\n",
       " (('r', 'i', 'u'), 50),\n",
       " (('a', 'u', 'd'), 49),\n",
       " (('<S>', 'i', 'v'), 49),\n",
       " (('<S>', 'i', 'r'), 49),\n",
       " (('e', 's', 'e'), 49),\n",
       " (('m', 'y', 'l'), 49),\n",
       " (('<S>', 'f', 'e'), 49),\n",
       " (('i', 'd', 'y'), 49),\n",
       " (('y', 'a', 'l'), 49),\n",
       " (('r', 'e', 'd'), 49),\n",
       " (('h', 'a', 'e'), 49),\n",
       " (('g', 'r', 'e'), 49),\n",
       " (('k', 'y', 'r'), 49),\n",
       " (('b', 'a', 'r'), 49),\n",
       " (('a', 'n', 'v'), 49),\n",
       " (('e', 'r', 'm'), 49),\n",
       " (('m', 'e', 's'), 49),\n",
       " (('j', 'a', 'r'), 49),\n",
       " (('a', 'r', 'v'), 49),\n",
       " (('n', 't', 'i'), 48),\n",
       " (('u', 'r', 'e'), 48),\n",
       " (('k', 'e', '<E>'), 48),\n",
       " (('<S>', 'm', 'c'), 48),\n",
       " (('a', 'k', 'o'), 48),\n",
       " (('w', 'y', 'n'), 48),\n",
       " (('u', 'l', 'a'), 48),\n",
       " (('m', 'e', 'i'), 48),\n",
       " (('n', 'a', 'e'), 48),\n",
       " (('o', 'm', 'e'), 48),\n",
       " (('m', 'a', 's'), 48),\n",
       " (('r', 'a', 's'), 48),\n",
       " (('j', 'a', 'v'), 48),\n",
       " (('u', 'i', 'n'), 47),\n",
       " (('o', 'e', 'l'), 47),\n",
       " (('<S>', 'z', 'u'), 47),\n",
       " (('w', 'e', 'n'), 47),\n",
       " (('n', 'o', 'n'), 47),\n",
       " (('e', 'd', 'i'), 47),\n",
       " (('i', 'n', 'c'), 47),\n",
       " (('a', 'a', 'd'), 47),\n",
       " (('e', 'i', 's'), 47),\n",
       " (('c', 'e', 'n'), 47),\n",
       " (('<S>', 'o', 'r'), 47),\n",
       " (('z', 'a', 'm'), 47),\n",
       " (('z', 'a', 'k'), 47),\n",
       " (('i', 'r', 'o'), 47),\n",
       " (('a', 'a', 'l'), 46),\n",
       " (('n', 'z', 'i'), 46),\n",
       " (('e', 'e', 's'), 46),\n",
       " (('l', 'a', 'u'), 46),\n",
       " (('o', 'n', 'd'), 46),\n",
       " (('n', 'y', 'l'), 46),\n",
       " (('s', 'e', 'a'), 46),\n",
       " (('e', 'm', 'o'), 46),\n",
       " (('<S>', 'c', 'y'), 46),\n",
       " (('s', 'i', 'm'), 46),\n",
       " (('m', 'i', 's'), 46),\n",
       " (('a', 'v', 'y'), 46),\n",
       " (('b', 'a', '<E>'), 46),\n",
       " (('u', 'm', 'a'), 46),\n",
       " (('k', 'h', 'y'), 46),\n",
       " (('r', 'u', 's'), 46),\n",
       " (('a', 'h', 'e'), 46),\n",
       " (('r', 's', 'h'), 46),\n",
       " (('y', 'a', 'a'), 46),\n",
       " (('p', 'a', 'r'), 45),\n",
       " (('h', 'e', 'a'), 45),\n",
       " (('f', 'e', 'r'), 45),\n",
       " (('y', 's', 'i'), 45),\n",
       " (('y', 'd', 'a'), 45),\n",
       " (('m', 'a', 'x'), 45),\n",
       " (('<S>', 'g', 'u'), 45),\n",
       " (('n', 'v', 'i'), 45),\n",
       " (('z', 'e', '<E>'), 45),\n",
       " (('t', 'a', 'm'), 45),\n",
       " (('a', 't', 'o'), 45),\n",
       " (('j', 'o', 'n'), 45),\n",
       " (('a', 'j', '<E>'), 45),\n",
       " (('a', 'v', '<E>'), 45),\n",
       " (('r', 'l', 'o'), 44),\n",
       " (('s', 'k', 'y'), 44),\n",
       " (('n', 't', 'h'), 44),\n",
       " (('i', 't', 'y'), 44),\n",
       " (('j', 'a', 'd'), 44),\n",
       " (('i', 'n', 'l'), 44),\n",
       " (('k', 'i', 'm'), 44),\n",
       " (('o', 's', 'i'), 44),\n",
       " (('g', 'e', '<E>'), 44),\n",
       " (('f', 'r', 'e'), 44),\n",
       " (('k', 'l', 'e'), 44),\n",
       " (('i', 't', 'z'), 44),\n",
       " (('s', 'a', 'h'), 44),\n",
       " (('<S>', 'c', 'i'), 44),\n",
       " (('e', 'n', 'o'), 44),\n",
       " (('d', 'e', 'a'), 44),\n",
       " (('a', 'y', 'r'), 44),\n",
       " (('e', 'v', 'o'), 44),\n",
       " (('c', 'o', 'n'), 44),\n",
       " (('s', 'h', 'o'), 44),\n",
       " (('h', 'm', 'a'), 44),\n",
       " (('e', 'c', 'k'), 44),\n",
       " (('j', 'a', 'x'), 44),\n",
       " (('b', 'a', 's'), 44),\n",
       " (('d', 'h', 'a'), 44),\n",
       " (('o', 'n', 'y'), 43),\n",
       " (('s', 'i', 'd'), 43),\n",
       " (('y', 'e', '<E>'), 43),\n",
       " (('y', 's', 't'), 43),\n",
       " (('l', 'o', 'u'), 43),\n",
       " (('e', 'n', 'y'), 43),\n",
       " (('y', 'v', 'i'), 43),\n",
       " (('s', 'm', 'a'), 43),\n",
       " (('u', 'h', 'a'), 43),\n",
       " (('v', 'e', 'e'), 43),\n",
       " (('m', 'i', 't'), 43),\n",
       " (('t', 'h', 'o'), 43),\n",
       " (('y', 'm', 'a'), 43),\n",
       " (('d', 'i', 's'), 42),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khole', 'harbour', 'devon', 'baine', 'erisha']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check if we have same shuffle in both notebooks using our own local random object,\n",
    "# with the same seed - it works\n",
    "r = random.Random(2147483647)\n",
    "r.shuffle(words)\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p80=25626, p90=28829\n",
      "train %: 79.99875128773452, dev %: 9.999063465800893, test %: 10.002185246464583\n"
     ]
    }
   ],
   "source": [
    "p80 = int(len(words) * 0.8)\n",
    "p90 = int(len(words) * 0.9)\n",
    "print(f'{p80=}, {p90=}')\n",
    "train = words[:p80]\n",
    "dev = words[p80:p90]\n",
    "test = words[p90:]\n",
    "print(f'train %: {len(train)/len(words)*100}, dev %: {len(dev)/len(words)*100}, test %: {len(test)/len(words)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['khole', 'harbour', 'devon', 'baine', 'erisha']\n",
      "['shterna', 'tyanna', 'sarra', 'malachy', 'zenaya']\n",
      "['phoenyx', 'christionna', 'bastien', 'niloufar', 'masa']\n"
     ]
    }
   ],
   "source": [
    "print(train[:5])\n",
    "print(dev[:5])\n",
    "print(test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair -> char\n",
    "# m = number of pairs; n = number of chars: same as in bigrams\n",
    "# so our matrix of counts/probs will be m x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually need all possible pairs of our chars, as sampling can come up\n",
    "# with a pair not seen it the actual data. 27*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as with chars, but we need all pairs\n",
    "pairs = []\n",
    "for i in range(27):\n",
    "  for j in range(27):\n",
    "    pairs.append(itos[i] + itos[j])\n",
    "pairs.sort()\n",
    "# need to populate pair to ix and ix to pair dicts\n",
    "pairtoi = {p:i for i,p in enumerate(pairs)}\n",
    "itopair = {i:p for p,i in pairtoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairtoi), len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matrix of counts how often a pair followed by a char\n",
    "# we build it only from train dataset\n",
    "N = torch.zeros((729, 27), dtype=torch.int32)\n",
    "for w in train:\n",
    "  # as we now using pairs, we start with ..\n",
    "  # didn't come up with better solution\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  # we can use indecies, but for simplicity just 3 iters\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    N[ix1, ix2] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 3522, 1040, 1238, 1351, 1248,  349,  534,  713,  477, 1935, 2305,\n",
       "        1272, 2026,  941,  310,  412,   75, 1304, 1634, 1036,   68,  296,  244,\n",
       "         110,  443,  743], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1374, 0.0406, 0.0483, 0.0527, 0.0487, 0.0136, 0.0208, 0.0278,\n",
       "        0.0186, 0.0755, 0.0899, 0.0496, 0.0791, 0.0367, 0.0121, 0.0161, 0.0029,\n",
       "        0.0509, 0.0638, 0.0404, 0.0027, 0.0116, 0.0095, 0.0043, 0.0173, 0.0290])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float() # N+1 is smoothing, so to not have inf loss on zero prob\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasid.\n",
      "prelay.\n",
      "adin.\n",
      "kairritoper.\n",
      "sathen.\n",
      "sameia.\n",
      "yanileniassibduinrwin.\n",
      "lessiyanayla.\n",
      "te.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "  \n",
    "  out = ['.']  # prepopulate with first .\n",
    "  i = 0 # start sampling from what char follows '..'\n",
    "  while True:\n",
    "    p = P[i]\n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0: # we've sampled end of word\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different seeds, it looks like more generated words became name-like. Tend to generate very long words as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate on train\n",
      "log_likelihood=tensor(-404414.3438)\n",
      "nll=tensor(404414.3438)\n",
      "2.2154107093811035\n"
     ]
    }
   ],
   "source": [
    "# evaluate on train\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in train:\n",
    "# for w in [\"alexey\"]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    # print(f'{ch1}{ch2}{ch3}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print('evaluate on train')\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate on dev\n",
      "log_likelihood=tensor(-51308.7266)\n",
      "nll=tensor(51308.7266)\n",
      "2.246441602706909\n"
     ]
    }
   ],
   "source": [
    "# evaluate on dev\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in dev:\n",
    "# for w in [\"alexey\"]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    # print(f'{ch1}{ch2}{ch3}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print('evaluate on dev')\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate on test\n",
      "log_likelihood=tensor(-50781.2344)\n",
      "nll=tensor(50781.2344)\n",
      "2.23116135597229\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in test:\n",
    "# for w in [\"alexey\"]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    # print(f'{ch1}{ch2}{ch3}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print('evaluate on test')\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing context to have a probability of char following a pair improves loss.\n",
    "# Also, the loss is slightly worse on dev and test data, train data counts do not\n",
    "# ideally correspond to dev and test data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . k\n",
      ". k h\n",
      "k h o\n",
      "h o l\n",
      "o l e\n",
      "l e .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of trigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    print(ch1, ch2, ch3)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  11, 305, 231, 417, 329])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  8, 15, 12,  5,  0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=729).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 729])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2384,  2.0809, -2.3702,  1.4668, -0.1945, -1.1215, -0.0506, -0.1151,\n",
       "         -0.1295,  0.0205, -0.8201,  0.1926, -0.1934, -1.2083,  0.0183, -1.2770,\n",
       "         -0.9674, -0.0900, -0.8087,  0.8243, -1.1320, -2.6060,  2.5413,  0.2313,\n",
       "          0.2510,  1.5200,  1.2974],\n",
       "        [ 0.7607, -0.4167, -0.4673, -0.1785,  0.6204, -0.5107, -1.3191,  1.6901,\n",
       "          1.4808, -1.5397, -0.0837, -0.1209,  1.8576,  0.0862, -1.1492, -0.1593,\n",
       "         -1.7086, -1.0545, -1.1250,  2.1263, -0.5392,  0.2980, -1.0450,  1.5037,\n",
       "          1.6793, -1.1685, -0.1143],\n",
       "        [ 1.0057, -1.3103,  2.1707, -0.4504, -0.0673, -0.5259, -0.0898, -0.0342,\n",
       "          0.1120, -0.4122,  0.7286, -0.4306, -1.2055,  0.4941, -0.6138, -0.3939,\n",
       "         -0.1062,  0.6107,  1.6400, -0.3373,  0.1924,  1.1623, -0.3114, -0.8499,\n",
       "          2.0497,  0.6942, -0.7097],\n",
       "        [ 0.7067, -0.0482, -1.0318, -1.1885, -0.5738, -0.2340, -0.6224, -2.7967,\n",
       "         -0.2383,  0.6450, -0.2388,  0.9423,  0.5386, -0.3682, -0.4345, -0.1393,\n",
       "          0.0426, -0.8765,  0.0680,  1.1139, -2.2804, -0.6830, -1.7349, -1.3346,\n",
       "          1.7683,  0.4390, -0.6049],\n",
       "        [-0.5154,  1.3450, -1.6141, -1.7831, -0.4911, -0.6433, -0.3531,  1.3696,\n",
       "         -0.4976, -0.0434,  0.8861,  0.3475,  0.3660,  0.6782,  1.1721,  1.3097,\n",
       "         -1.3358, -1.3503,  1.5649,  0.0404, -0.6831, -0.3444, -0.7086, -0.3246,\n",
       "          1.2518,  0.7076,  0.5145],\n",
       "        [-0.2140,  0.3450, -0.9675,  1.9752,  0.7540,  0.3159, -1.0836, -0.7367,\n",
       "          0.7106, -0.8890, -0.0945,  0.4244,  0.4160,  0.5285,  0.3289,  0.5538,\n",
       "          1.3088,  0.6834, -1.6581, -1.2664, -1.3188, -1.2869, -1.0361,  0.6708,\n",
       "          0.3028,  0.7316,  0.3389]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((729, 27))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0022, 0.1622, 0.0019, 0.0878, 0.0167, 0.0066, 0.0192, 0.0180, 0.0178,\n",
       "         0.0207, 0.0089, 0.0245, 0.0167, 0.0060, 0.0206, 0.0056, 0.0077, 0.0185,\n",
       "         0.0090, 0.0462, 0.0065, 0.0015, 0.2570, 0.0255, 0.0260, 0.0926, 0.0741],\n",
       "        [0.0427, 0.0132, 0.0125, 0.0167, 0.0371, 0.0120, 0.0053, 0.1082, 0.0878,\n",
       "         0.0043, 0.0184, 0.0177, 0.1280, 0.0218, 0.0063, 0.0170, 0.0036, 0.0070,\n",
       "         0.0065, 0.1674, 0.0116, 0.0269, 0.0070, 0.0898, 0.1071, 0.0062, 0.0178],\n",
       "        [0.0571, 0.0056, 0.1829, 0.0133, 0.0195, 0.0123, 0.0191, 0.0202, 0.0233,\n",
       "         0.0138, 0.0433, 0.0136, 0.0063, 0.0342, 0.0113, 0.0141, 0.0188, 0.0384,\n",
       "         0.1076, 0.0149, 0.0253, 0.0667, 0.0153, 0.0089, 0.1621, 0.0418, 0.0103],\n",
       "        [0.0673, 0.0316, 0.0118, 0.0101, 0.0187, 0.0263, 0.0178, 0.0020, 0.0261,\n",
       "         0.0632, 0.0261, 0.0851, 0.0568, 0.0230, 0.0215, 0.0289, 0.0346, 0.0138,\n",
       "         0.0355, 0.1010, 0.0034, 0.0168, 0.0059, 0.0087, 0.1944, 0.0515, 0.0181],\n",
       "        [0.0141, 0.0907, 0.0047, 0.0040, 0.0145, 0.0124, 0.0166, 0.0930, 0.0144,\n",
       "         0.0226, 0.0573, 0.0335, 0.0341, 0.0466, 0.0763, 0.0876, 0.0062, 0.0061,\n",
       "         0.1131, 0.0246, 0.0119, 0.0168, 0.0116, 0.0171, 0.0827, 0.0480, 0.0395],\n",
       "        [0.0206, 0.0360, 0.0097, 0.1839, 0.0542, 0.0350, 0.0086, 0.0122, 0.0519,\n",
       "         0.0105, 0.0232, 0.0390, 0.0387, 0.0433, 0.0355, 0.0444, 0.0945, 0.0505,\n",
       "         0.0049, 0.0072, 0.0068, 0.0070, 0.0091, 0.0499, 0.0345, 0.0530, 0.0358]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0022, 0.1622, 0.0019, 0.0878, 0.0167, 0.0066, 0.0192, 0.0180, 0.0178,\n",
       "        0.0207, 0.0089, 0.0245, 0.0167, 0.0060, 0.0206, 0.0056, 0.0077, 0.0185,\n",
       "        0.0090, 0.0462, 0.0065, 0.0015, 0.2570, 0.0255, 0.0260, 0.0926, 0.0741])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY ------------------------------>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  11, 305, 231, 417, 329])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  8, 15, 12,  5,  0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 729 inputs (all possible pairs)\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 27])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: ..k (indexes 0,11)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 11\n",
      "probability assigned by the net to the the correct character: 0.027797512710094452\n",
      "log likelihood: -3.58280873298645\n",
      "negative log likelihood: 3.58280873298645\n",
      "--------\n",
      "bigram example 2: .kh (indexes 11,8)\n",
      "input to the neural net: 11\n",
      "output probabilities from the neural net: tensor([0.0065, 0.0446, 0.0052, 0.0091, 0.0787, 0.0122, 0.0621, 0.0676, 0.0543,\n",
      "        0.0146, 0.0066, 0.0622, 0.1245, 0.0203, 0.0145, 0.0502, 0.0342, 0.0201,\n",
      "        0.0365, 0.0386, 0.0637, 0.0165, 0.0617, 0.0343, 0.0405, 0.0025, 0.0182])\n",
      "label (actual next character): 8\n",
      "probability assigned by the net to the the correct character: 0.054324932396411896\n",
      "log likelihood: -2.9127719402313232\n",
      "negative log likelihood: 2.9127719402313232\n",
      "--------\n",
      "bigram example 3: kho (indexes 305,15)\n",
      "input to the neural net: 305\n",
      "output probabilities from the neural net: tensor([0.0059, 0.0677, 0.0352, 0.0082, 0.1392, 0.0311, 0.0374, 0.0312, 0.0614,\n",
      "        0.0320, 0.0374, 0.0429, 0.0233, 0.0326, 0.0265, 0.0218, 0.0817, 0.0304,\n",
      "        0.0404, 0.0080, 0.0581, 0.0324, 0.0230, 0.0306, 0.0124, 0.0268, 0.0222])\n",
      "label (actual next character): 15\n",
      "probability assigned by the net to the the correct character: 0.021830126643180847\n",
      "log likelihood: -3.8244643211364746\n",
      "negative log likelihood: 3.8244643211364746\n",
      "--------\n",
      "bigram example 4: hol (indexes 231,12)\n",
      "input to the neural net: 231\n",
      "output probabilities from the neural net: tensor([0.0306, 0.0188, 0.0287, 0.0140, 0.0119, 0.0347, 0.0467, 0.0352, 0.0213,\n",
      "        0.0436, 0.0017, 0.0313, 0.2497, 0.0362, 0.0575, 0.0045, 0.0398, 0.0066,\n",
      "        0.0084, 0.1037, 0.0333, 0.0418, 0.0411, 0.0221, 0.0133, 0.0024, 0.0211])\n",
      "label (actual next character): 12\n",
      "probability assigned by the net to the the correct character: 0.24970604479312897\n",
      "log likelihood: -1.3874708414077759\n",
      "negative log likelihood: 1.3874708414077759\n",
      "--------\n",
      "bigram example 5: ole (indexes 417,5)\n",
      "input to the neural net: 417\n",
      "output probabilities from the neural net: tensor([0.0751, 0.0333, 0.0325, 0.0368, 0.0102, 0.0444, 0.0180, 0.0693, 0.0350,\n",
      "        0.0122, 0.0113, 0.0380, 0.0184, 0.0746, 0.0122, 0.0438, 0.0477, 0.0028,\n",
      "        0.0267, 0.0627, 0.0611, 0.0154, 0.0748, 0.0060, 0.0880, 0.0328, 0.0168])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.044430483132600784\n",
      "log likelihood: -3.1138296127319336\n",
      "negative log likelihood: 3.1138296127319336\n",
      "--------\n",
      "bigram example 6: le. (indexes 329,0)\n",
      "input to the neural net: 329\n",
      "output probabilities from the neural net: tensor([0.0263, 0.0119, 0.0375, 0.0298, 0.0093, 0.0262, 0.0407, 0.0297, 0.1125,\n",
      "        0.0178, 0.1864, 0.0468, 0.0688, 0.1337, 0.0284, 0.0110, 0.0045, 0.0073,\n",
      "        0.0047, 0.0057, 0.0175, 0.0082, 0.0074, 0.0689, 0.0157, 0.0230, 0.0203])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.026309538632631302\n",
      "log likelihood: -3.6378238201141357\n",
      "negative log likelihood: 3.6378238201141357\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 3.076528310775757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlls = torch.zeros(6)\n",
    "for i in range(6):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itopair[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  11, 305, 231, 417, 329])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  8, 15, 12,  5,  0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(6), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02982497215271\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  182546\n"
     ]
    }
   ],
   "source": [
    "# create the dataset only from train data\n",
    "xs, ys = [], []\n",
    "for w in train:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, 3.803398847579956\n",
      "k=1, 3.6497108936309814\n",
      "k=2, 3.5580077171325684\n",
      "k=3, 3.490262746810913\n",
      "k=4, 3.434335231781006\n",
      "k=5, 3.385187864303589\n",
      "k=6, 3.3409881591796875\n",
      "k=7, 3.3007566928863525\n",
      "k=8, 3.263888359069824\n",
      "k=9, 3.2299532890319824\n",
      "k=10, 3.1986024379730225\n",
      "k=11, 3.1695306301116943\n",
      "k=12, 3.142467498779297\n",
      "k=13, 3.117175579071045\n",
      "k=14, 3.093453884124756\n",
      "k=15, 3.0711305141448975\n",
      "k=16, 3.050062656402588\n",
      "k=17, 3.030130624771118\n",
      "k=18, 3.011232376098633\n",
      "k=19, 2.9932830333709717\n",
      "k=20, 2.976207733154297\n",
      "k=21, 2.959941864013672\n",
      "k=22, 2.9444282054901123\n",
      "k=23, 2.929616689682007\n",
      "k=24, 2.915461778640747\n",
      "k=25, 2.9019227027893066\n",
      "k=26, 2.8889617919921875\n",
      "k=27, 2.8765451908111572\n",
      "k=28, 2.864640951156616\n",
      "k=29, 2.8532207012176514\n",
      "k=30, 2.8422560691833496\n",
      "k=31, 2.8317229747772217\n",
      "k=32, 2.82159686088562\n",
      "k=33, 2.8118555545806885\n",
      "k=34, 2.802478075027466\n",
      "k=35, 2.7934436798095703\n",
      "k=36, 2.7847342491149902\n",
      "k=37, 2.776331663131714\n",
      "k=38, 2.768218517303467\n",
      "k=39, 2.7603793144226074\n",
      "k=40, 2.7527990341186523\n",
      "k=41, 2.7454638481140137\n",
      "k=42, 2.738360643386841\n",
      "k=43, 2.7314767837524414\n",
      "k=44, 2.7248005867004395\n",
      "k=45, 2.7183213233947754\n",
      "k=46, 2.7120296955108643\n",
      "k=47, 2.7059154510498047\n",
      "k=48, 2.6999707221984863\n",
      "k=49, 2.6941864490509033\n",
      "k=50, 2.688555955886841\n",
      "k=51, 2.6830718517303467\n",
      "k=52, 2.677727460861206\n",
      "k=53, 2.6725165843963623\n",
      "k=54, 2.667433500289917\n",
      "k=55, 2.66247296333313\n",
      "k=56, 2.6576297283172607\n",
      "k=57, 2.6528992652893066\n",
      "k=58, 2.6482765674591064\n",
      "k=59, 2.6437582969665527\n",
      "k=60, 2.6393396854400635\n",
      "k=61, 2.6350178718566895\n",
      "k=62, 2.6307883262634277\n",
      "k=63, 2.626648426055908\n",
      "k=64, 2.6225945949554443\n",
      "k=65, 2.618623971939087\n",
      "k=66, 2.6147336959838867\n",
      "k=67, 2.6109213829040527\n",
      "k=68, 2.6071841716766357\n",
      "k=69, 2.6035192012786865\n",
      "k=70, 2.5999252796173096\n",
      "k=71, 2.5963985919952393\n",
      "k=72, 2.5929388999938965\n",
      "k=73, 2.589542865753174\n",
      "k=74, 2.5862090587615967\n",
      "k=75, 2.582935094833374\n",
      "k=76, 2.5797200202941895\n",
      "k=77, 2.576561212539673\n",
      "k=78, 2.573458194732666\n",
      "k=79, 2.570408821105957\n",
      "k=80, 2.5674118995666504\n",
      "k=81, 2.564465284347534\n",
      "k=82, 2.561568260192871\n",
      "k=83, 2.5587193965911865\n",
      "k=84, 2.555917739868164\n",
      "k=85, 2.553161382675171\n",
      "k=86, 2.5504493713378906\n",
      "k=87, 2.547780990600586\n",
      "k=88, 2.5451550483703613\n",
      "k=89, 2.542570114135742\n",
      "k=90, 2.540025472640991\n",
      "k=91, 2.537520170211792\n",
      "k=92, 2.535053253173828\n",
      "k=93, 2.532623767852783\n",
      "k=94, 2.530230760574341\n",
      "k=95, 2.5278735160827637\n",
      "k=96, 2.5255515575408936\n",
      "k=97, 2.5232629776000977\n",
      "k=98, 2.5210084915161133\n",
      "k=99, 2.5187861919403076\n",
      "k=100, 2.5165958404541016\n",
      "k=101, 2.514436960220337\n",
      "k=102, 2.512308120727539\n",
      "k=103, 2.510209560394287\n",
      "k=104, 2.5081393718719482\n",
      "k=105, 2.506098747253418\n",
      "k=106, 2.5040860176086426\n",
      "k=107, 2.5021004676818848\n",
      "k=108, 2.5001420974731445\n",
      "k=109, 2.4982094764709473\n",
      "k=110, 2.496302843093872\n",
      "k=111, 2.4944214820861816\n",
      "k=112, 2.492565155029297\n",
      "k=113, 2.4907329082489014\n",
      "k=114, 2.488924264907837\n",
      "k=115, 2.4871392250061035\n",
      "k=116, 2.485377073287964\n",
      "k=117, 2.4836366176605225\n",
      "k=118, 2.481919050216675\n",
      "k=119, 2.4802229404449463\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(120):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(f'{k=}, {loss.item()}')\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate loss on dev dataset\n",
      "number of examples:  22840\n",
      "k=119, 2.4913697242736816\n"
     ]
    }
   ],
   "source": [
    "# create the dataset from dev data\n",
    "print('evaluate loss on dev dataset')\n",
    "xs, ys = [], []\n",
    "for w in dev:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# forward pass to evaluate loss\n",
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "print(f'{k=}, {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate loss on test dataset\n",
      "number of examples:  22760\n",
      "k=119, 2.4849367141723633\n"
     ]
    }
   ],
   "source": [
    "# create the dataset from test data\n",
    "print('evaluate loss on test dataset')\n",
    "xs, ys = [], []\n",
    "for w in test:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# forward pass to evaluate loss\n",
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "print(f'{k=}, {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss for nn trigram model is about the same as for bigram. Quality of generation is not much better.\n",
    "# NN also can't achieve 2.21 trigram statistical model result. Counting model has exact answers,\n",
    "# it counted trigrams. On the other hand with nn we are trying to learn these counts from data using gradient\n",
    "# descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on dev and test gives just a bit worse loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juwjded.\n",
      "anaqah.\n",
      "pacfqjwein.\n",
      "avoiibltohcaus.\n",
      "ter.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(5):\n",
    "  \n",
    "  out = ['.']\n",
    "  i = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([i]), num_classes=729).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0:\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7113,  2.1159,  0.8952,  1.0696,  1.1571,  1.0777, -0.1992,  0.2274,\n",
       "         0.5171,  0.1143,  1.5166,  1.6917,  1.0968,  1.5626,  0.7950, -0.3182,\n",
       "        -0.0327, -1.7431,  1.1216,  1.3474,  0.8913, -1.7654, -0.3648, -0.5589,\n",
       "        -1.3467,  0.0401,  0.5584], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6632,  0.6028,  0.4133, -1.1712,  1.1766, -0.6634, -0.9772, -1.4414,\n",
       "        -0.3502,  0.1478, -0.9474, -0.5754,  1.6878,  1.1625,  1.7101, -1.4293,\n",
       "        -1.1534, -1.8035,  1.4607,  0.4853, -0.3756,  0.2106,  0.6671, -1.3427,\n",
       "        -0.9443,  0.4153,  0.1868], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
