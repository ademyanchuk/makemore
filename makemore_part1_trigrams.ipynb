{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. \n",
    "### Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {}\n",
    "for w in words:\n",
    "  chs = ['<S>'] + list(w) + ['<E>']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    trigram = (ch1, ch2, ch3)\n",
    "    t[trigram] = t.get(trigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'h', '<E>'), 1714),\n",
       " (('n', 'a', '<E>'), 1673),\n",
       " (('a', 'n', '<E>'), 1509),\n",
       " (('o', 'n', '<E>'), 1503),\n",
       " (('<S>', 'm', 'a'), 1453),\n",
       " (('<S>', 'j', 'a'), 1255),\n",
       " (('<S>', 'k', 'a'), 1254),\n",
       " (('e', 'n', '<E>'), 1217),\n",
       " (('l', 'y', 'n'), 976),\n",
       " (('y', 'n', '<E>'), 953),\n",
       " (('a', 'r', 'i'), 950),\n",
       " (('i', 'a', '<E>'), 903),\n",
       " (('i', 'e', '<E>'), 858),\n",
       " (('a', 'n', 'n'), 825),\n",
       " (('e', 'l', 'l'), 822),\n",
       " (('a', 'n', 'a'), 804),\n",
       " (('i', 'a', 'n'), 790),\n",
       " (('m', 'a', 'r'), 776),\n",
       " (('i', 'n', '<E>'), 766),\n",
       " (('e', 'l', '<E>'), 727),\n",
       " (('y', 'a', '<E>'), 716),\n",
       " (('a', 'n', 'i'), 703),\n",
       " (('<S>', 'd', 'a'), 700),\n",
       " (('l', 'a', '<E>'), 684),\n",
       " (('e', 'r', '<E>'), 683),\n",
       " (('i', 'y', 'a'), 669),\n",
       " (('l', 'a', 'n'), 647),\n",
       " (('<S>', 'b', 'r'), 646),\n",
       " (('n', 'n', 'a'), 633),\n",
       " (('<S>', 'a', 'l'), 632),\n",
       " (('<S>', 'c', 'a'), 628),\n",
       " (('r', 'a', '<E>'), 627),\n",
       " (('n', 'i', '<E>'), 625),\n",
       " (('<S>', 'a', 'n'), 623),\n",
       " (('n', 'n', '<E>'), 619),\n",
       " (('n', 'e', '<E>'), 607),\n",
       " (('e', 'e', '<E>'), 605),\n",
       " (('e', 'y', '<E>'), 602),\n",
       " (('<S>', 'k', 'e'), 601),\n",
       " (('a', 'l', 'e'), 601),\n",
       " (('<S>', 's', 'a'), 595),\n",
       " (('a', 'l', 'i'), 575),\n",
       " (('s', 'h', 'a'), 562),\n",
       " (('e', 'l', 'i'), 537),\n",
       " (('<S>', 'd', 'e'), 524),\n",
       " (('l', 'i', 'a'), 518),\n",
       " (('l', 'e', 'e'), 517),\n",
       " (('y', 'n', 'n'), 516),\n",
       " (('y', 'a', 'h'), 511),\n",
       " (('<S>', 'h', 'a'), 505),\n",
       " (('l', 'i', 'n'), 505),\n",
       " (('r', 'i', 'a'), 499),\n",
       " (('<S>', 'e', 'l'), 488),\n",
       " (('a', 'y', 'l'), 483),\n",
       " (('<S>', 'a', 'r'), 482),\n",
       " (('y', 'a', 'n'), 479),\n",
       " (('<S>', 'r', 'a'), 472),\n",
       " (('<S>', 'n', 'a'), 470),\n",
       " (('h', 'a', 'n'), 469),\n",
       " (('<S>', 'l', 'a'), 463),\n",
       " (('i', 'a', 'h'), 461),\n",
       " (('<S>', 'z', 'a'), 456),\n",
       " (('r', 'i', '<E>'), 452),\n",
       " (('l', 'e', 'y'), 443),\n",
       " (('<S>', 's', 'h'), 434),\n",
       " (('a', 'm', 'a'), 431),\n",
       " (('<S>', 'j', 'o'), 429),\n",
       " (('<S>', 't', 'a'), 424),\n",
       " (('<S>', 'j', 'e'), 403),\n",
       " (('l', 'e', 'i'), 401),\n",
       " (('i', 'e', 'l'), 395),\n",
       " (('r', 'i', 'e'), 394),\n",
       " (('<S>', 'm', 'i'), 393),\n",
       " (('a', 'n', 'd'), 392),\n",
       " (('a', 'y', 'a'), 389),\n",
       " (('<S>', 'a', 'm'), 384),\n",
       " (('l', 'e', 'n'), 383),\n",
       " (('<S>', 'r', 'o'), 382),\n",
       " (('y', 'l', 'a'), 381),\n",
       " (('i', 'n', 'a'), 379),\n",
       " (('t', 'o', 'n'), 377),\n",
       " (('a', 'r', 'a'), 371),\n",
       " (('<S>', 'a', 'd'), 366),\n",
       " (('<S>', 'l', 'e'), 366),\n",
       " (('l', 'e', '<E>'), 362),\n",
       " (('r', 'i', 's'), 360),\n",
       " (('a', 'm', 'i'), 355),\n",
       " (('e', 'l', 'y'), 353),\n",
       " (('a', 'l', 'a'), 353),\n",
       " (('<S>', 'c', 'h'), 352),\n",
       " (('s', 'o', 'n'), 341),\n",
       " (('l', 'l', 'a'), 337),\n",
       " (('l', 'l', 'e'), 331),\n",
       " (('h', 'a', 'r'), 329),\n",
       " (('d', 'e', 'n'), 318),\n",
       " (('a', 'l', 'y'), 310),\n",
       " (('e', 'l', 'a'), 308),\n",
       " (('a', 'v', 'i'), 306),\n",
       " (('y', 'l', 'e'), 303),\n",
       " (('i', 'g', 'h'), 290),\n",
       " (('i', 'o', 'n'), 290),\n",
       " (('<S>', 'e', 'm'), 288),\n",
       " (('a', 'r', 'l'), 287),\n",
       " (('i', 's', '<E>'), 287),\n",
       " (('a', 'e', 'l'), 287),\n",
       " (('l', 'i', 'e'), 285),\n",
       " (('h', 'a', '<E>'), 284),\n",
       " (('<S>', 'm', 'e'), 284),\n",
       " (('r', 'e', 'n'), 281),\n",
       " (('u', 's', '<E>'), 280),\n",
       " (('i', 'l', 'a'), 279),\n",
       " (('e', 'n', 'a'), 279),\n",
       " (('e', 'i', 'g'), 279),\n",
       " (('a', 's', 'h'), 276),\n",
       " (('m', 'a', 'n'), 274),\n",
       " (('l', 'l', 'i'), 271),\n",
       " (('l', 'y', '<E>'), 270),\n",
       " (('<S>', 'l', 'i'), 269),\n",
       " (('<S>', 'r', 'e'), 268),\n",
       " (('e', 'r', 'i'), 268),\n",
       " (('n', 'n', 'e'), 261),\n",
       " (('a', 'i', 'l'), 259),\n",
       " (('m', 'i', 'l'), 259),\n",
       " (('<S>', 'c', 'o'), 255),\n",
       " (('b', 'r', 'i'), 254),\n",
       " (('r', 'a', 'y'), 254),\n",
       " (('<S>', 'b', 'e'), 253),\n",
       " (('s', 'a', '<E>'), 253),\n",
       " (('k', 'e', 'n'), 252),\n",
       " (('<S>', 'k', 'i'), 250),\n",
       " (('i', 'r', 'a'), 248),\n",
       " (('r', 'a', 'n'), 248),\n",
       " (('i', 'r', '<E>'), 248),\n",
       " (('<S>', 'y', 'a'), 246),\n",
       " (('<S>', 'a', 'v'), 243),\n",
       " (('i', 'n', 'e'), 241),\n",
       " (('e', 'n', 'n'), 240),\n",
       " (('<S>', 'k', 'h'), 240),\n",
       " (('v', 'a', 'n'), 237),\n",
       " (('c', 'h', 'a'), 236),\n",
       " (('g', 'h', '<E>'), 235),\n",
       " (('c', 'e', '<E>'), 234),\n",
       " (('l', 'a', 'y'), 234),\n",
       " (('r', 'i', 'n'), 234),\n",
       " (('r', 'e', '<E>'), 231),\n",
       " (('<S>', 'k', 'y'), 229),\n",
       " (('a', 'r', '<E>'), 228),\n",
       " (('s', 'e', '<E>'), 228),\n",
       " (('i', 's', 'h'), 227),\n",
       " (('a', 'm', 'e'), 226),\n",
       " (('<S>', 'n', 'i'), 226),\n",
       " (('k', 'a', 'i'), 226),\n",
       " (('l', 'a', 'h'), 224),\n",
       " (('a', 'n', 'e'), 224),\n",
       " (('n', 'i', 'e'), 223),\n",
       " (('r', 'a', 'h'), 222),\n",
       " (('l', 'i', '<E>'), 221),\n",
       " (('n', 'n', 'i'), 221),\n",
       " (('o', 'r', 'i'), 220),\n",
       " (('e', 'l', 'e'), 219),\n",
       " (('k', 'a', 'r'), 218),\n",
       " (('d', 'e', 'l'), 217),\n",
       " (('k', 'a', 'y'), 215),\n",
       " (('j', 'a', 'y'), 212),\n",
       " (('i', 'l', 'l'), 211),\n",
       " (('m', 'a', 'l'), 210),\n",
       " (('k', 'a', '<E>'), 210),\n",
       " (('m', 'e', 'r'), 209),\n",
       " (('y', 'l', 'i'), 209),\n",
       " (('<S>', 't', 'r'), 209),\n",
       " (('r', 'i', 'c'), 209),\n",
       " (('l', 'i', 's'), 208),\n",
       " (('<S>', 'a', 'a'), 207),\n",
       " (('d', 'a', 'n'), 207),\n",
       " (('r', 'e', 'e'), 205),\n",
       " (('i', 'l', 'y'), 203),\n",
       " (('e', 't', 't'), 203),\n",
       " (('d', 'a', 'l'), 203),\n",
       " (('l', 'l', '<E>'), 203),\n",
       " (('b', 'r', 'a'), 203),\n",
       " (('o', 'r', 'a'), 202),\n",
       " (('b', 'e', 'l'), 201),\n",
       " (('r', 'y', '<E>'), 201),\n",
       " (('<S>', 'r', 'i'), 201),\n",
       " (('m', 'o', 'n'), 201),\n",
       " (('e', 'e', 'n'), 200),\n",
       " (('a', 'r', 'e'), 198),\n",
       " (('i', 'l', 'e'), 197),\n",
       " (('t', 'a', '<E>'), 197),\n",
       " (('d', 'a', '<E>'), 197),\n",
       " (('e', 'a', 'n'), 196),\n",
       " (('a', 'l', 'l'), 196),\n",
       " (('r', 'o', 's'), 196),\n",
       " (('a', 'r', 'y'), 195),\n",
       " (('a', 'd', 'e'), 194),\n",
       " (('<S>', 'a', 's'), 194),\n",
       " (('o', 'n', 'n'), 194),\n",
       " (('c', 'a', 'r'), 193),\n",
       " (('n', 'y', '<E>'), 192),\n",
       " (('<S>', 'k', 'o'), 192),\n",
       " (('a', 'r', 'r'), 192),\n",
       " (('<S>', 'a', 'b'), 190),\n",
       " (('a', 'd', 'i'), 190),\n",
       " (('b', 'r', 'e'), 189),\n",
       " (('a', 'i', 'r'), 189),\n",
       " (('a', 'm', '<E>'), 189),\n",
       " (('o', 'n', 'i'), 189),\n",
       " (('m', 'e', 'l'), 188),\n",
       " (('<S>', 'l', 'o'), 186),\n",
       " (('n', 'a', 'h'), 185),\n",
       " (('n', 'd', 'r'), 184),\n",
       " (('a', 'i', '<E>'), 183),\n",
       " (('<S>', 's', 'e'), 182),\n",
       " (('r', 'r', 'i'), 182),\n",
       " (('<S>', 't', 'e'), 181),\n",
       " (('i', 'l', 'i'), 180),\n",
       " (('e', 'y', 'a'), 179),\n",
       " (('t', 'h', '<E>'), 178),\n",
       " (('<S>', 'j', 'u'), 178),\n",
       " (('a', 'y', 'd'), 178),\n",
       " (('l', 'a', 'i'), 177),\n",
       " (('a', 'n', 't'), 177),\n",
       " (('a', 'i', 'n'), 177),\n",
       " (('t', 'e', '<E>'), 175),\n",
       " (('<S>', 'p', 'a'), 175),\n",
       " (('i', 'k', 'a'), 175),\n",
       " (('a', 'n', 'y'), 175),\n",
       " (('a', 'l', '<E>'), 175),\n",
       " (('m', 'a', '<E>'), 174),\n",
       " (('a', 'a', 'n'), 174),\n",
       " (('a', 'b', 'e'), 173),\n",
       " (('l', 'e', 'a'), 173),\n",
       " (('<S>', 'a', 'y'), 173),\n",
       " (('a', 's', '<E>'), 173),\n",
       " (('<S>', 's', 'i'), 172),\n",
       " (('m', 'i', 'r'), 172),\n",
       " (('s', 'i', 'a'), 171),\n",
       " (('k', 'h', 'a'), 171),\n",
       " (('e', 'r', 'e'), 170),\n",
       " (('s', 'h', 'i'), 170),\n",
       " (('<S>', 'b', 'a'), 169),\n",
       " (('t', 'h', 'a'), 168),\n",
       " (('e', 'n', 'i'), 168),\n",
       " (('<S>', 'm', 'o'), 168),\n",
       " (('k', 'a', 'l'), 168),\n",
       " (('r', 'o', 'n'), 168),\n",
       " (('a', 'v', 'e'), 166),\n",
       " (('o', 's', 'e'), 166),\n",
       " (('s', 's', 'a'), 166),\n",
       " (('<S>', 'g', 'r'), 165),\n",
       " (('s', 't', 'o'), 165),\n",
       " (('<S>', 'n', 'e'), 164),\n",
       " (('a', 'd', 'a'), 164),\n",
       " (('r', 'e', 'y'), 163),\n",
       " (('a', 'y', '<E>'), 163),\n",
       " (('<S>', 'l', 'u'), 162),\n",
       " (('d', 'r', 'i'), 162),\n",
       " (('a', 'v', 'a'), 161),\n",
       " (('<S>', 'v', 'i'), 161),\n",
       " (('e', 'm', 'i'), 160),\n",
       " (('v', 'e', 'r'), 160),\n",
       " (('s', 't', 'i'), 159),\n",
       " (('s', 'a', 'n'), 159),\n",
       " (('<S>', 'f', 'a'), 158),\n",
       " (('e', 'a', '<E>'), 158),\n",
       " (('a', 's', 'i'), 157),\n",
       " (('<S>', 'n', 'o'), 156),\n",
       " (('i', 's', 't'), 156),\n",
       " (('<S>', 'e', 'v'), 154),\n",
       " (('s', 't', 'e'), 154),\n",
       " (('<S>', 'a', 'i'), 154),\n",
       " (('t', 'a', 'l'), 153),\n",
       " (('l', 'a', 'r'), 153),\n",
       " (('m', 'a', 'y'), 153),\n",
       " (('e', 's', 's'), 153),\n",
       " (('h', 'a', 'l'), 153),\n",
       " (('d', 'a', 'r'), 153),\n",
       " (('h', 'a', 'm'), 153),\n",
       " (('<S>', 's', 'o'), 152),\n",
       " (('<S>', 'a', 'u'), 152),\n",
       " (('b', 'e', 'r'), 152),\n",
       " (('<S>', 'a', 'z'), 152),\n",
       " (('e', 'n', 'e'), 151),\n",
       " (('k', 'a', 'm'), 151),\n",
       " (('<S>', 'h', 'e'), 151),\n",
       " (('j', 'a', 'm'), 151),\n",
       " (('s', 'h', '<E>'), 149),\n",
       " (('d', 'e', 'r'), 149),\n",
       " (('o', 'r', '<E>'), 148),\n",
       " (('v', 'i', 'n'), 148),\n",
       " (('v', 'i', 'a'), 147),\n",
       " (('e', 's', 't'), 147),\n",
       " (('l', 'o', 'n'), 147),\n",
       " (('o', 'n', 'a'), 147),\n",
       " (('a', 'e', '<E>'), 147),\n",
       " (('r', 'l', 'e'), 146),\n",
       " (('r', 'i', 'o'), 146),\n",
       " (('n', 'e', 'l'), 145),\n",
       " (('a', 'i', 's'), 145),\n",
       " (('e', 'r', 'a'), 145),\n",
       " (('n', 'l', 'e'), 143),\n",
       " (('r', 'e', 'l'), 143),\n",
       " (('h', 'i', '<E>'), 143),\n",
       " (('i', 's', 'a'), 142),\n",
       " (('e', 'v', 'e'), 142),\n",
       " (('t', 'i', 'n'), 142),\n",
       " (('a', 't', 'h'), 142),\n",
       " (('d', 'o', 'n'), 142),\n",
       " (('s', 'e', 'n'), 142),\n",
       " (('m', 'i', 'n'), 141),\n",
       " (('<S>', 's', 'u'), 141),\n",
       " (('k', 'e', 'l'), 141),\n",
       " (('t', 'a', 'n'), 141),\n",
       " (('n', 'i', 'a'), 141),\n",
       " (('r', 'y', 'n'), 140),\n",
       " (('j', 'a', 'n'), 140),\n",
       " (('n', 'a', 'l'), 140),\n",
       " (('e', 'r', 'r'), 140),\n",
       " (('e', 'm', 'a'), 140),\n",
       " (('s', 't', 'a'), 139),\n",
       " (('i', 'o', '<E>'), 139),\n",
       " (('s', 'l', 'e'), 138),\n",
       " (('a', 'i', 'd'), 138),\n",
       " (('e', 's', '<E>'), 138),\n",
       " (('l', 'o', 'r'), 137),\n",
       " (('m', 'a', 'd'), 136),\n",
       " (('s', 'a', 'm'), 136),\n",
       " (('<S>', 'g', 'a'), 136),\n",
       " (('r', 'i', 'y'), 136),\n",
       " (('<S>', 's', 't'), 135),\n",
       " (('i', 'e', 'r'), 135),\n",
       " (('<S>', 'z', 'e'), 135),\n",
       " (('j', 'a', 'h'), 135),\n",
       " (('k', 'i', 'n'), 134),\n",
       " (('l', 'i', 'l'), 133),\n",
       " (('e', 'v', 'a'), 133),\n",
       " (('h', 'a', 'y'), 133),\n",
       " (('t', 'e', 'r'), 133),\n",
       " (('a', 'y', 's'), 133),\n",
       " (('<S>', 't', 'y'), 133),\n",
       " (('h', 'e', 'r'), 132),\n",
       " (('r', 'a', 'i'), 132),\n",
       " (('e', 'o', 'n'), 131),\n",
       " (('<S>', 'd', 'i'), 130),\n",
       " (('c', 'h', 'e'), 130),\n",
       " (('a', 'c', 'e'), 129),\n",
       " (('i', 'c', 'k'), 129),\n",
       " (('d', 'y', '<E>'), 128),\n",
       " (('<S>', 'g', 'i'), 128),\n",
       " (('e', 'm', '<E>'), 128),\n",
       " (('y', 'o', 'n'), 128),\n",
       " (('r', 'a', 'e'), 127),\n",
       " (('n', 'c', 'e'), 127),\n",
       " (('i', 's', 'e'), 126),\n",
       " (('n', 'd', '<E>'), 126),\n",
       " (('<S>', 'p', 'r'), 125),\n",
       " (('i', 'n', 'g'), 125),\n",
       " (('<S>', 'i', 's'), 124),\n",
       " (('m', 'i', '<E>'), 124),\n",
       " (('i', 't', 'h'), 124),\n",
       " (('l', 'l', 'y'), 124),\n",
       " (('o', 'l', 'a'), 124),\n",
       " (('u', 'r', 'i'), 123),\n",
       " (('a', 'z', 'a'), 123),\n",
       " (('j', 'e', 'r'), 123),\n",
       " (('i', 'r', 'e'), 122),\n",
       " (('i', 's', 's'), 122),\n",
       " (('t', 't', 'e'), 121),\n",
       " (('<S>', 'v', 'a'), 121),\n",
       " (('c', 'a', 'l'), 121),\n",
       " (('a', 'k', 'a'), 121),\n",
       " (('z', 'a', 'r'), 121),\n",
       " (('y', 'd', 'e'), 121),\n",
       " (('v', 'i', '<E>'), 121),\n",
       " (('g', 'r', 'a'), 120),\n",
       " (('m', 'a', 'i'), 120),\n",
       " (('c', 'k', '<E>'), 120),\n",
       " (('i', 'l', '<E>'), 119),\n",
       " (('h', 'a', 'i'), 119),\n",
       " (('e', 'n', 'd'), 119),\n",
       " (('v', 'e', 'n'), 119),\n",
       " (('<S>', 'd', 'o'), 119),\n",
       " (('r', 'i', 't'), 119),\n",
       " (('v', 'o', 'n'), 119),\n",
       " (('<S>', 'l', 'y'), 118),\n",
       " (('r', 'y', 'a'), 118),\n",
       " (('l', 'i', 'y'), 117),\n",
       " (('s', 'e', 'l'), 117),\n",
       " (('i', 'm', 'a'), 117),\n",
       " (('b', 'r', 'y'), 116),\n",
       " (('e', 't', 'h'), 114),\n",
       " (('d', 'r', 'e'), 113),\n",
       " (('n', 'a', 'y'), 113),\n",
       " (('k', 'a', 's'), 113),\n",
       " (('t', 'e', 'n'), 113),\n",
       " (('h', 'e', 'l'), 112),\n",
       " (('o', 'r', 'e'), 112),\n",
       " (('<S>', 't', 'o'), 112),\n",
       " (('a', 't', 'a'), 111),\n",
       " (('<S>', 'r', 'y'), 111),\n",
       " (('e', 'i', 'l'), 111),\n",
       " (('r', 'a', 'l'), 111),\n",
       " (('h', 'r', 'i'), 111),\n",
       " (('a', 'h', 'a'), 111),\n",
       " (('t', 'o', 'r'), 110),\n",
       " (('<S>', 'g', 'e'), 110),\n",
       " (('a', 'n', 'g'), 110),\n",
       " (('i', 'd', 'e'), 110),\n",
       " (('m', 'a', 'k'), 109),\n",
       " (('<S>', 't', 'i'), 109),\n",
       " (('n', 'd', 'e'), 109),\n",
       " (('a', 'u', 'r'), 108),\n",
       " (('<S>', 'r', 'u'), 108),\n",
       " (('d', 'y', 'n'), 108),\n",
       " (('n', 'i', 'y'), 108),\n",
       " (('s', 'h', 'e'), 108),\n",
       " (('t', 'r', 'i'), 107),\n",
       " (('n', 'i', 's'), 107),\n",
       " (('n', 'o', '<E>'), 107),\n",
       " (('e', 't', '<E>'), 106),\n",
       " (('d', 'i', 'e'), 106),\n",
       " (('t', 'h', 'e'), 106),\n",
       " (('h', 'e', 'n'), 106),\n",
       " (('a', 'd', '<E>'), 106),\n",
       " (('a', 'i', 'a'), 105),\n",
       " (('j', 'a', 'i'), 105),\n",
       " (('<S>', 'o', 'l'), 104),\n",
       " (('k', 'y', 'l'), 104),\n",
       " (('d', 'i', '<E>'), 104),\n",
       " (('n', 'a', 'n'), 104),\n",
       " (('t', 'r', 'e'), 104),\n",
       " (('l', 'o', '<E>'), 104),\n",
       " (('r', 'a', 'c'), 103),\n",
       " (('a', 'r', 'o'), 103),\n",
       " (('i', 'n', 'n'), 103),\n",
       " (('<S>', 'm', 'y'), 103),\n",
       " (('s', 's', 'i'), 103),\n",
       " (('t', 't', '<E>'), 102),\n",
       " (('c', 'o', 'r'), 102),\n",
       " (('a', 's', 't'), 102),\n",
       " (('a', 'r', 't'), 102),\n",
       " (('n', 'a', 'i'), 102),\n",
       " (('n', 'o', 'r'), 101),\n",
       " (('n', 'a', 't'), 101),\n",
       " (('e', 'r', 'l'), 101),\n",
       " (('l', 'e', 's'), 101),\n",
       " (('a', 'm', 'o'), 101),\n",
       " (('a', 'h', 'i'), 101),\n",
       " (('a', 'i', 'y'), 101),\n",
       " (('o', 'n', 't'), 101),\n",
       " (('e', 'm', 'm'), 100),\n",
       " (('t', 'y', 'n'), 100),\n",
       " (('h', 'a', 'd'), 99),\n",
       " (('g', 'a', 'n'), 99),\n",
       " (('<S>', 't', 'h'), 99),\n",
       " (('i', 't', 'a'), 99),\n",
       " (('l', 'y', 'a'), 99),\n",
       " (('a', 'n', 's'), 99),\n",
       " (('a', 'k', 'i'), 99),\n",
       " (('a', 'n', 'o'), 98),\n",
       " (('d', 'i', 'a'), 98),\n",
       " (('z', 'a', '<E>'), 98),\n",
       " (('m', 'o', 'r'), 98),\n",
       " (('a', 'y', 'n'), 98),\n",
       " (('a', 'k', 'e'), 98),\n",
       " (('m', 'a', 't'), 98),\n",
       " (('y', 'i', 'a'), 98),\n",
       " (('r', 'l', 'i'), 97),\n",
       " (('y', 'e', 'l'), 97),\n",
       " (('z', 'a', 'y'), 97),\n",
       " (('r', 'a', 'm'), 97),\n",
       " (('v', 'a', 'l'), 96),\n",
       " (('u', 'l', 'i'), 96),\n",
       " (('y', 'r', 'i'), 96),\n",
       " (('a', 's', 's'), 96),\n",
       " (('i', 'd', 'a'), 96),\n",
       " (('h', 'o', 'n'), 96),\n",
       " (('<S>', 'k', 'r'), 96),\n",
       " (('m', 'i', 'a'), 95),\n",
       " (('e', 'n', 't'), 95),\n",
       " (('v', 'i', 'e'), 95),\n",
       " (('i', 'm', '<E>'), 95),\n",
       " (('a', 'd', 'd'), 94),\n",
       " (('c', 'h', 'i'), 94),\n",
       " (('i', 'k', '<E>'), 94),\n",
       " (('v', 'a', '<E>'), 93),\n",
       " (('i', 'z', 'a'), 93),\n",
       " (('n', 'e', 's'), 93),\n",
       " (('j', 'o', 's'), 93),\n",
       " (('k', 'a', 't'), 93),\n",
       " (('<S>', 'e', 's'), 93),\n",
       " (('y', 'n', 'e'), 93),\n",
       " (('a', 'z', 'i'), 93),\n",
       " (('c', 'a', 'm'), 92),\n",
       " (('<S>', 'p', 'e'), 92),\n",
       " (('e', 'a', 'h'), 92),\n",
       " (('d', 'e', '<E>'), 92),\n",
       " (('c', 'e', 'l'), 92),\n",
       " (('<S>', 'n', 'y'), 92),\n",
       " (('a', 'r', 's'), 92),\n",
       " (('a', 'r', 'd'), 92),\n",
       " (('l', 'e', 't'), 91),\n",
       " (('<S>', 'w', 'i'), 91),\n",
       " (('i', 'e', 'n'), 91),\n",
       " (('a', 'm', 'y'), 91),\n",
       " (('e', 'i', '<E>'), 91),\n",
       " (('<S>', 'z', 'y'), 91),\n",
       " (('d', 'a', 'm'), 91),\n",
       " (('r', 'o', '<E>'), 91),\n",
       " (('<S>', 'a', 'h'), 91),\n",
       " (('i', 'u', 's'), 91),\n",
       " (('o', 'v', 'a'), 90),\n",
       " (('s', 'a', 'l'), 90),\n",
       " (('n', 'i', 'c'), 90),\n",
       " (('y', 'n', 'a'), 90),\n",
       " (('n', 'd', 'a'), 90),\n",
       " (('<S>', 'e', 'r'), 90),\n",
       " (('d', 'a', 'y'), 90),\n",
       " (('<S>', 'r', 'h'), 90),\n",
       " (('v', 'i', 'o'), 89),\n",
       " (('s', 'y', 'n'), 89),\n",
       " (('n', 'a', 's'), 89),\n",
       " (('m', 'a', 'h'), 89),\n",
       " (('t', 'y', '<E>'), 88),\n",
       " (('a', 'r', 'm'), 88),\n",
       " (('a', 'h', 'm'), 88),\n",
       " (('r', 'e', 't'), 87),\n",
       " (('l', 'e', 'r'), 87),\n",
       " (('i', 'n', 'i'), 87),\n",
       " (('j', 'e', 'n'), 87),\n",
       " (('i', 'n', 'd'), 87),\n",
       " (('g', 'e', 'n'), 86),\n",
       " (('d', 'r', 'a'), 86),\n",
       " (('r', 'e', 's'), 86),\n",
       " (('n', 'g', 'e'), 86),\n",
       " (('o', 'n', 'e'), 86),\n",
       " (('<S>', 'z', 'i'), 86),\n",
       " (('<S>', 'y', 'u'), 86),\n",
       " (('<S>', 'y', 'o'), 86),\n",
       " (('a', 'b', 'r'), 85),\n",
       " (('g', 'e', 'l'), 85),\n",
       " (('<S>', 'b', 'l'), 85),\n",
       " (('d', 'e', 'm'), 85),\n",
       " (('e', 'y', 'l'), 85),\n",
       " (('<S>', 'm', 'u'), 85),\n",
       " (('e', 'r', 'y'), 84),\n",
       " (('l', 'y', 's'), 84),\n",
       " (('h', 'i', 'r'), 84),\n",
       " (('b', 'e', 'n'), 84),\n",
       " (('o', 'l', 'u'), 84),\n",
       " (('u', 'w', 'a'), 84),\n",
       " (('e', 'l', 'o'), 83),\n",
       " (('z', 'e', 'l'), 83),\n",
       " (('o', 'l', 'e'), 83),\n",
       " (('s', 'a', 'r'), 83),\n",
       " (('l', 'e', 'x'), 83),\n",
       " (('e', 'v', 'i'), 83),\n",
       " (('a', 'n', 'c'), 83),\n",
       " (('a', 'a', 'r'), 83),\n",
       " (('e', 's', 'h'), 83),\n",
       " (('<S>', 'q', 'u'), 82),\n",
       " (('j', 'a', 's'), 82),\n",
       " (('m', 'i', 'k'), 82),\n",
       " (('r', 'e', 'i'), 82),\n",
       " (('a', 's', 'e'), 82),\n",
       " (('y', 'l', 'y'), 82),\n",
       " (('n', 'g', '<E>'), 82),\n",
       " (('n', 't', 'a'), 82),\n",
       " (('h', 'i', 'a'), 81),\n",
       " (('l', 'i', 'z'), 81),\n",
       " (('t', 'a', 'y'), 81),\n",
       " (('m', 'a', 'e'), 81),\n",
       " (('j', 'a', 'c'), 81),\n",
       " (('a', 'l', 'o'), 81),\n",
       " (('h', 'i', 'l'), 81),\n",
       " (('n', 'i', 'k'), 81),\n",
       " (('n', 'n', 'y'), 81),\n",
       " (('s', 's', 'e'), 81),\n",
       " (('r', 'l', 'y'), 80),\n",
       " (('e', 'm', 'e'), 80),\n",
       " (('<S>', 'e', 'd'), 80),\n",
       " (('n', 'e', 'e'), 80),\n",
       " (('r', 'r', 'a'), 80),\n",
       " (('m', 'i', 'e'), 80),\n",
       " (('n', 'y', 'a'), 80),\n",
       " (('o', 'u', 'r'), 79),\n",
       " (('<S>', 'f', 'r'), 79),\n",
       " (('a', 'y', 'v'), 79),\n",
       " (('e', 'e', 'l'), 79),\n",
       " (('l', 'u', 'w'), 79),\n",
       " (('i', 'v', 'i'), 78),\n",
       " (('z', 'i', 'e'), 78),\n",
       " (('c', 'o', 'l'), 78),\n",
       " (('y', 'r', 'a'), 78),\n",
       " (('l', 'i', 'o'), 78),\n",
       " (('u', 'n', '<E>'), 78),\n",
       " (('p', 'e', 'r'), 77),\n",
       " (('m', 'a', 'c'), 77),\n",
       " (('o', 'r', 'd'), 77),\n",
       " (('a', 'c', 'h'), 77),\n",
       " (('<S>', 'h', 'o'), 77),\n",
       " (('n', 't', 'e'), 77),\n",
       " (('y', 'a', 'r'), 77),\n",
       " (('j', 'a', 'l'), 77),\n",
       " (('<S>', 'd', 'r'), 77),\n",
       " (('<S>', 'b', 'o'), 77),\n",
       " (('y', 'c', 'e'), 77),\n",
       " (('o', 's', '<E>'), 77),\n",
       " (('s', 'a', 'b'), 76),\n",
       " (('v', 'e', 'l'), 76),\n",
       " (('a', 'b', 'i'), 76),\n",
       " (('e', 'r', 's'), 76),\n",
       " (('n', 'e', 'y'), 76),\n",
       " (('i', 'c', 'h'), 76),\n",
       " (('c', 'a', 's'), 76),\n",
       " (('a', 'y', 'e'), 76),\n",
       " (('u', 's', 't'), 76),\n",
       " (('n', 'a', 'v'), 76),\n",
       " (('d', 'i', 'n'), 76),\n",
       " (('t', 'r', 'a'), 76),\n",
       " (('e', 'e', 'm'), 76),\n",
       " (('u', 'a', 'n'), 76),\n",
       " (('r', 'y', 'l'), 75),\n",
       " (('i', 'r', 'i'), 75),\n",
       " (('m', 'i', 'y'), 75),\n",
       " (('u', 'e', 'l'), 75),\n",
       " (('k', 'e', 'i'), 75),\n",
       " (('k', 'y', 'n'), 75),\n",
       " (('t', 'i', 'a'), 75),\n",
       " (('<S>', 'a', 'k'), 75),\n",
       " (('o', 'm', 'i'), 74),\n",
       " (('j', 'u', 'l'), 74),\n",
       " (('s', 'i', 'e'), 74),\n",
       " (('a', 't', 'i'), 74),\n",
       " (('a', 'h', 'l'), 73),\n",
       " (('<S>', 'j', 'i'), 73),\n",
       " (('a', 't', 't'), 73),\n",
       " (('z', 'a', 'n'), 73),\n",
       " (('e', 'e', 'r'), 73),\n",
       " (('m', 'm', 'a'), 72),\n",
       " (('<S>', 'z', 'o'), 72),\n",
       " (('r', 'e', 'a'), 72),\n",
       " (('<S>', 'a', 't'), 72),\n",
       " (('y', 'l', 'o'), 72),\n",
       " (('t', 'h', 'i'), 72),\n",
       " (('k', 'e', 'y'), 72),\n",
       " (('n', 'a', 'r'), 72),\n",
       " (('r', 'r', 'e'), 72),\n",
       " (('<S>', 'f', 'i'), 71),\n",
       " (('<S>', 's', 'y'), 71),\n",
       " (('c', 'i', 'a'), 71),\n",
       " (('d', 'e', 's'), 71),\n",
       " (('o', 'h', 'a'), 71),\n",
       " (('s', 'a', 'i'), 71),\n",
       " (('t', 'a', 'r'), 71),\n",
       " (('z', 'i', 'a'), 71),\n",
       " (('i', 'n', 'o'), 71),\n",
       " (('e', 'd', '<E>'), 71),\n",
       " (('o', 'l', 'l'), 70),\n",
       " (('q', 'u', 'e'), 70),\n",
       " (('i', 'v', 'a'), 70),\n",
       " (('a', 'r', 'c'), 70),\n",
       " (('k', 'a', 'n'), 70),\n",
       " (('o', 'l', 'i'), 69),\n",
       " (('b', 'r', 'o'), 69),\n",
       " (('l', 'u', 'c'), 69),\n",
       " (('k', 'e', 'r'), 69),\n",
       " (('d', 'a', 'i'), 69),\n",
       " (('r', 'e', 'm'), 69),\n",
       " (('a', 'd', 'r'), 69),\n",
       " (('c', 'h', 'r'), 69),\n",
       " (('d', 'a', 'v'), 69),\n",
       " (('z', 'a', 'i'), 69),\n",
       " (('l', 'a', 'm'), 69),\n",
       " (('y', 'a', 's'), 69),\n",
       " (('m', 'e', 'e'), 69),\n",
       " (('i', 's', 'o'), 68),\n",
       " (('<S>', 'c', 'l'), 68),\n",
       " (('e', 'n', 'z'), 68),\n",
       " (('r', 'y', 's'), 68),\n",
       " (('<S>', 'w', 'a'), 68),\n",
       " (('s', 'i', 'r'), 68),\n",
       " (('i', 'h', 'a'), 68),\n",
       " (('o', 'u', 's'), 68),\n",
       " (('s', 'e', 'r'), 67),\n",
       " (('q', 'u', 'i'), 67),\n",
       " (('<S>', 'v', 'e'), 67),\n",
       " (('m', 'i', 'c'), 67),\n",
       " (('<S>', 'c', 'r'), 67),\n",
       " (('<S>', 'h', 'u'), 67),\n",
       " (('<S>', 'i', 'l'), 67),\n",
       " (('s', 't', 'y'), 67),\n",
       " (('a', 'i', 'z'), 67),\n",
       " (('l', 'a', 'k'), 66),\n",
       " (('a', 't', 'e'), 66),\n",
       " (('i', 'c', '<E>'), 66),\n",
       " (('z', 'a', 'l'), 66),\n",
       " (('i', 'd', '<E>'), 66),\n",
       " (('o', 'm', 'a'), 66),\n",
       " (('h', 'a', 'w'), 66),\n",
       " (('a', 'u', 'n'), 66),\n",
       " (('<S>', 'c', 'e'), 65),\n",
       " (('i', 'l', 'o'), 65),\n",
       " (('a', 'b', 'd'), 65),\n",
       " (('d', 'o', '<E>'), 65),\n",
       " (('d', 'i', 'l'), 64),\n",
       " (('e', 'r', 'o'), 64),\n",
       " (('k', 'r', 'i'), 64),\n",
       " (('y', 's', '<E>'), 64),\n",
       " (('o', 'r', 'r'), 64),\n",
       " (('t', 'e', 'l'), 63),\n",
       " (('i', 's', 'l'), 63),\n",
       " (('n', 's', 'l'), 63),\n",
       " (('i', 'c', 'e'), 63),\n",
       " (('m', 'y', 'a'), 63),\n",
       " (('o', 's', 'a'), 63),\n",
       " (('c', 'a', '<E>'), 63),\n",
       " (('n', 'e', 't'), 63),\n",
       " (('k', 'e', 'e'), 63),\n",
       " (('k', 'o', 'l'), 63),\n",
       " (('d', 'e', 'e'), 63),\n",
       " (('r', 'i', 'l'), 62),\n",
       " (('o', 'r', 'y'), 62),\n",
       " (('k', 'o', 'r'), 62),\n",
       " (('j', 'a', 'k'), 62),\n",
       " (('h', 'a', 's'), 62),\n",
       " (('h', 'a', 'a'), 62),\n",
       " (('i', 'm', 'i'), 62),\n",
       " (('p', 'h', 'i'), 61),\n",
       " (('b', 'e', 't'), 61),\n",
       " (('u', 'n', 'a'), 61),\n",
       " (('a', 'r', 'k'), 61),\n",
       " (('e', 's', 'l'), 61),\n",
       " (('a', 'y', 't'), 61),\n",
       " (('i', 'v', 'e'), 61),\n",
       " (('j', 'e', 's'), 61),\n",
       " (('e', 'n', 's'), 61),\n",
       " (('e', 'n', 'l'), 61),\n",
       " (('k', 'a', 'e'), 61),\n",
       " (('<S>', 'w', 'e'), 61),\n",
       " (('<S>', 'y', 'e'), 61),\n",
       " (('a', 'z', 'e'), 60),\n",
       " (('c', 'l', 'a'), 60),\n",
       " (('m', 'e', 'n'), 60),\n",
       " (('l', 'e', 'o'), 60),\n",
       " (('<S>', 'e', 'n'), 60),\n",
       " (('n', 'd', 'i'), 60),\n",
       " (('r', 'i', 'k'), 60),\n",
       " (('<S>', 'i', 'n'), 60),\n",
       " (('t', 'l', 'e'), 60),\n",
       " (('s', 'i', 'n'), 60),\n",
       " (('t', 'i', '<E>'), 60),\n",
       " (('g', 'e', 'r'), 60),\n",
       " (('a', 's', 'a'), 60),\n",
       " (('a', 'c', 'k'), 59),\n",
       " (('m', 'b', 'e'), 59),\n",
       " (('c', 'i', 'e'), 59),\n",
       " (('<S>', 'i', 'z'), 59),\n",
       " (('a', 'd', 'o'), 59),\n",
       " (('d', 'o', 'r'), 59),\n",
       " (('y', 's', 'e'), 59),\n",
       " (('s', 'l', 'y'), 59),\n",
       " (('z', 'l', 'e'), 59),\n",
       " (('i', 'j', 'a'), 59),\n",
       " (('n', 'e', 'r'), 59),\n",
       " (('w', 'a', '<E>'), 59),\n",
       " (('a', 'v', 'o'), 59),\n",
       " (('i', 'i', '<E>'), 59),\n",
       " (('k', 'o', '<E>'), 59),\n",
       " (('l', 'l', 'o'), 58),\n",
       " (('i', 'n', 's'), 58),\n",
       " (('n', 'i', 't'), 58),\n",
       " (('e', 'n', 'c'), 58),\n",
       " (('y', 's', 'o'), 58),\n",
       " (('g', 'h', 'a'), 58),\n",
       " (('a', 'y', 'c'), 58),\n",
       " (('i', 'z', 'e'), 58),\n",
       " (('v', 'i', 'k'), 58),\n",
       " (('k', 'i', '<E>'), 58),\n",
       " (('t', 'o', '<E>'), 58),\n",
       " (('e', 's', 'i'), 57),\n",
       " (('h', 'i', 'n'), 57),\n",
       " (('e', 'i', 'a'), 57),\n",
       " (('i', 'c', 'a'), 57),\n",
       " (('r', 'o', 'm'), 57),\n",
       " (('r', 'm', 'a'), 57),\n",
       " (('h', 'y', 'a'), 57),\n",
       " (('a', 'd', 'y'), 57),\n",
       " (('a', 'h', 'n'), 57),\n",
       " (('<S>', 'x', 'a'), 57),\n",
       " (('r', 'd', '<E>'), 57),\n",
       " (('w', 'i', 'l'), 56),\n",
       " (('e', 'd', 'e'), 56),\n",
       " (('a', 'c', 'i'), 56),\n",
       " (('u', 'r', 'a'), 56),\n",
       " (('h', 'l', 'a'), 56),\n",
       " (('j', 'a', 'z'), 56),\n",
       " (('s', 's', '<E>'), 56),\n",
       " (('a', 't', '<E>'), 56),\n",
       " (('c', 'a', 'i'), 56),\n",
       " (('d', 'e', 'v'), 56),\n",
       " (('v', 'a', 'r'), 56),\n",
       " (('q', 'u', 'a'), 56),\n",
       " (('<S>', 's', 'k'), 55),\n",
       " (('b', 'y', '<E>'), 55),\n",
       " (('k', 'i', 'a'), 55),\n",
       " (('w', 'i', 'n'), 55),\n",
       " (('t', 'a', 'v'), 55),\n",
       " (('j', 'o', 'h'), 55),\n",
       " (('l', 'a', 's'), 55),\n",
       " (('e', 'd', 'a'), 55),\n",
       " (('f', 'a', 'r'), 55),\n",
       " (('z', 'e', 'n'), 55),\n",
       " (('j', 'a', '<E>'), 55),\n",
       " (('<S>', 'a', 'e'), 55),\n",
       " (('<S>', 'h', 'i'), 55),\n",
       " (('i', 't', '<E>'), 55),\n",
       " (('a', 'y', 'm'), 55),\n",
       " (('t', 'a', 'i'), 55),\n",
       " (('i', 'a', 's'), 55),\n",
       " (('l', 'i', 'v'), 54),\n",
       " (('f', 'i', 'n'), 54),\n",
       " (('j', 'o', 'r'), 54),\n",
       " (('m', 'y', '<E>'), 54),\n",
       " (('r', 'n', 'e'), 54),\n",
       " (('b', 'l', 'a'), 54),\n",
       " (('i', 'a', 'r'), 54),\n",
       " (('a', 'l', 'd'), 54),\n",
       " (('a', 'm', 'r'), 54),\n",
       " (('f', 'r', 'a'), 54),\n",
       " (('n', 't', 'o'), 54),\n",
       " (('s', 'i', '<E>'), 54),\n",
       " (('<S>', 'e', 'i'), 54),\n",
       " (('n', 's', 'h'), 54),\n",
       " (('y', 'r', 'e'), 54),\n",
       " (('n', 'd', 'y'), 53),\n",
       " (('h', 'a', 'v'), 53),\n",
       " (('k', 'a', 'h'), 53),\n",
       " (('t', 't', 'a'), 53),\n",
       " (('s', 'o', 'l'), 53),\n",
       " (('r', 'i', 'g'), 53),\n",
       " (('a', 'e', 'd'), 53),\n",
       " (('n', 'o', 'v'), 52),\n",
       " (('c', 'k', 'e'), 52),\n",
       " (('e', 'g', 'a'), 52),\n",
       " (('i', 'a', 'm'), 52),\n",
       " (('<S>', 'p', 'h'), 52),\n",
       " (('e', 's', 'a'), 52),\n",
       " (('<S>', 'e', 'z'), 52),\n",
       " (('u', 'e', '<E>'), 52),\n",
       " (('h', 'y', 'l'), 52),\n",
       " (('a', 'k', 'y'), 52),\n",
       " (('a', 'w', 'n'), 52),\n",
       " (('a', 'j', 'a'), 52),\n",
       " (('i', 'k', 'o'), 52),\n",
       " (('d', 'd', 'i'), 51),\n",
       " (('g', 'a', 'r'), 51),\n",
       " (('n', 'd', 'o'), 51),\n",
       " (('e', 'i', 'r'), 51),\n",
       " (('s', 'e', 'y'), 51),\n",
       " (('t', 'i', 'e'), 51),\n",
       " (('a', 'm', 'b'), 51),\n",
       " (('p', 'r', 'i'), 51),\n",
       " (('e', 'r', 't'), 51),\n",
       " (('r', 'i', 'd'), 51),\n",
       " (('k', 'i', 'e'), 51),\n",
       " (('j', 'a', 'e'), 51),\n",
       " (('i', 't', 't'), 51),\n",
       " (('h', 'i', 't'), 51),\n",
       " (('a', 'i', 'm'), 51),\n",
       " (('w', 'n', '<E>'), 51),\n",
       " (('r', 'a', 'd'), 51),\n",
       " (('a', 'y', 'o'), 51),\n",
       " (('e', 'a', 'l'), 51),\n",
       " (('g', 'i', 'a'), 50),\n",
       " (('e', 'p', 'h'), 50),\n",
       " (('a', 'i', 't'), 50),\n",
       " (('i', 'x', '<E>'), 50),\n",
       " (('z', 'a', 'h'), 50),\n",
       " (('c', 'a', 'y'), 50),\n",
       " (('a', 'n', 'u'), 50),\n",
       " (('e', 'k', '<E>'), 50),\n",
       " (('r', 'i', 'u'), 50),\n",
       " (('a', 'u', 'd'), 49),\n",
       " (('<S>', 'i', 'v'), 49),\n",
       " (('<S>', 'i', 'r'), 49),\n",
       " (('e', 's', 'e'), 49),\n",
       " (('m', 'y', 'l'), 49),\n",
       " (('<S>', 'f', 'e'), 49),\n",
       " (('i', 'd', 'y'), 49),\n",
       " (('y', 'a', 'l'), 49),\n",
       " (('r', 'e', 'd'), 49),\n",
       " (('h', 'a', 'e'), 49),\n",
       " (('g', 'r', 'e'), 49),\n",
       " (('k', 'y', 'r'), 49),\n",
       " (('b', 'a', 'r'), 49),\n",
       " (('a', 'n', 'v'), 49),\n",
       " (('e', 'r', 'm'), 49),\n",
       " (('m', 'e', 's'), 49),\n",
       " (('j', 'a', 'r'), 49),\n",
       " (('a', 'r', 'v'), 49),\n",
       " (('n', 't', 'i'), 48),\n",
       " (('u', 'r', 'e'), 48),\n",
       " (('k', 'e', '<E>'), 48),\n",
       " (('<S>', 'm', 'c'), 48),\n",
       " (('a', 'k', 'o'), 48),\n",
       " (('w', 'y', 'n'), 48),\n",
       " (('u', 'l', 'a'), 48),\n",
       " (('m', 'e', 'i'), 48),\n",
       " (('n', 'a', 'e'), 48),\n",
       " (('o', 'm', 'e'), 48),\n",
       " (('m', 'a', 's'), 48),\n",
       " (('r', 'a', 's'), 48),\n",
       " (('j', 'a', 'v'), 48),\n",
       " (('u', 'i', 'n'), 47),\n",
       " (('o', 'e', 'l'), 47),\n",
       " (('<S>', 'z', 'u'), 47),\n",
       " (('w', 'e', 'n'), 47),\n",
       " (('n', 'o', 'n'), 47),\n",
       " (('e', 'd', 'i'), 47),\n",
       " (('i', 'n', 'c'), 47),\n",
       " (('a', 'a', 'd'), 47),\n",
       " (('e', 'i', 's'), 47),\n",
       " (('c', 'e', 'n'), 47),\n",
       " (('<S>', 'o', 'r'), 47),\n",
       " (('z', 'a', 'm'), 47),\n",
       " (('z', 'a', 'k'), 47),\n",
       " (('i', 'r', 'o'), 47),\n",
       " (('a', 'a', 'l'), 46),\n",
       " (('n', 'z', 'i'), 46),\n",
       " (('e', 'e', 's'), 46),\n",
       " (('l', 'a', 'u'), 46),\n",
       " (('o', 'n', 'd'), 46),\n",
       " (('n', 'y', 'l'), 46),\n",
       " (('s', 'e', 'a'), 46),\n",
       " (('e', 'm', 'o'), 46),\n",
       " (('<S>', 'c', 'y'), 46),\n",
       " (('s', 'i', 'm'), 46),\n",
       " (('m', 'i', 's'), 46),\n",
       " (('a', 'v', 'y'), 46),\n",
       " (('b', 'a', '<E>'), 46),\n",
       " (('u', 'm', 'a'), 46),\n",
       " (('k', 'h', 'y'), 46),\n",
       " (('r', 'u', 's'), 46),\n",
       " (('a', 'h', 'e'), 46),\n",
       " (('r', 's', 'h'), 46),\n",
       " (('y', 'a', 'a'), 46),\n",
       " (('p', 'a', 'r'), 45),\n",
       " (('h', 'e', 'a'), 45),\n",
       " (('f', 'e', 'r'), 45),\n",
       " (('y', 's', 'i'), 45),\n",
       " (('y', 'd', 'a'), 45),\n",
       " (('m', 'a', 'x'), 45),\n",
       " (('<S>', 'g', 'u'), 45),\n",
       " (('n', 'v', 'i'), 45),\n",
       " (('z', 'e', '<E>'), 45),\n",
       " (('t', 'a', 'm'), 45),\n",
       " (('a', 't', 'o'), 45),\n",
       " (('j', 'o', 'n'), 45),\n",
       " (('a', 'j', '<E>'), 45),\n",
       " (('a', 'v', '<E>'), 45),\n",
       " (('r', 'l', 'o'), 44),\n",
       " (('s', 'k', 'y'), 44),\n",
       " (('n', 't', 'h'), 44),\n",
       " (('i', 't', 'y'), 44),\n",
       " (('j', 'a', 'd'), 44),\n",
       " (('i', 'n', 'l'), 44),\n",
       " (('k', 'i', 'm'), 44),\n",
       " (('o', 's', 'i'), 44),\n",
       " (('g', 'e', '<E>'), 44),\n",
       " (('f', 'r', 'e'), 44),\n",
       " (('k', 'l', 'e'), 44),\n",
       " (('i', 't', 'z'), 44),\n",
       " (('s', 'a', 'h'), 44),\n",
       " (('<S>', 'c', 'i'), 44),\n",
       " (('e', 'n', 'o'), 44),\n",
       " (('d', 'e', 'a'), 44),\n",
       " (('a', 'y', 'r'), 44),\n",
       " (('e', 'v', 'o'), 44),\n",
       " (('c', 'o', 'n'), 44),\n",
       " (('s', 'h', 'o'), 44),\n",
       " (('h', 'm', 'a'), 44),\n",
       " (('e', 'c', 'k'), 44),\n",
       " (('j', 'a', 'x'), 44),\n",
       " (('b', 'a', 's'), 44),\n",
       " (('d', 'h', 'a'), 44),\n",
       " (('o', 'n', 'y'), 43),\n",
       " (('s', 'i', 'd'), 43),\n",
       " (('y', 'e', '<E>'), 43),\n",
       " (('y', 's', 't'), 43),\n",
       " (('l', 'o', 'u'), 43),\n",
       " (('e', 'n', 'y'), 43),\n",
       " (('y', 'v', 'i'), 43),\n",
       " (('s', 'm', 'a'), 43),\n",
       " (('u', 'h', 'a'), 43),\n",
       " (('v', 'e', 'e'), 43),\n",
       " (('m', 'i', 't'), 43),\n",
       " (('t', 'h', 'o'), 43),\n",
       " (('y', 'm', 'a'), 43),\n",
       " (('d', 'i', 's'), 42),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair -> char\n",
    "# m = number of pairs; n = number of chars: same as in bigrams\n",
    "# so our matrix of counts/probs will be m x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually need all possible pairs of our chars, as sampling can come up\n",
    "# with a pair not seen it the actual data. 27*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as with chars, but we need all pairs\n",
    "pairs = []\n",
    "for i in range(27):\n",
    "  for j in range(27):\n",
    "    pairs.append(itos[i] + itos[j])\n",
    "pairs.sort()\n",
    "# need to populate pair to ix and ix to pair dicts\n",
    "pairtoi = {p:i for i,p in enumerate(pairs)}\n",
    "itopair = {i:p for p,i in pairtoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 27)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairtoi), len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matrix of counts how often a pair followed by a char\n",
    "N = torch.zeros((729, 27), dtype=torch.int32)\n",
    "for w in words:\n",
    "  # as we now using pairs, we start with ..\n",
    "  # didn't come up with better solution\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  # we can use indecies, but for simplicity just 3 iters\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    N[ix1, ix2] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float() # N+1 is smoothing, so to not have inf loss on zero prob\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "jakasid.\n",
      "prelay.\n",
      "adin.\n",
      "kairritoper.\n",
      "sathen.\n",
      "sameia.\n",
      "yanileniassibduinrwin.\n",
      "lessiyanayla.\n",
      "te.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "  \n",
    "  out = ['.']  # prepopulate with first .\n",
    "  i = 0 # start sampling from what char follows '..'\n",
    "  while True:\n",
    "    p = P[i]\n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0: # we've sampled end of word\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different seeds, it looks like more generated words became name-like. Tend to generate very long words as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-504653.)\n",
      "nll=tensor(504653.)\n",
      "2.2119739055633545\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "# for w in [\"alexey\"]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    # print(f'{ch1}{ch2}{ch3}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing context to have a probability of char following a pair improves loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . e\n",
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of trigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    print(ch1, ch2, ch3)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=729).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 729])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3815,  0.0175,  0.0541, -0.0177, -2.5514,  1.3628,  0.7797,  0.7665,\n",
       "         -1.1949, -0.6674, -0.7216,  0.0961,  1.6246,  1.2666,  0.7603,  0.6153,\n",
       "          1.3104,  1.2735,  0.6359,  0.3995,  1.0126,  0.1056, -1.9424, -0.6486,\n",
       "          1.3768,  0.8932, -1.0436],\n",
       "        [-0.0555, -0.2170,  0.6552, -0.9323, -0.4071, -1.7409, -0.1845, -2.1906,\n",
       "         -0.2675, -0.7234, -0.8160, -0.6237, -0.4340,  0.7525,  0.8160,  0.2127,\n",
       "         -1.0352, -0.9936, -0.0191, -1.0491,  1.4477, -0.0094, -0.5521,  1.4184,\n",
       "         -0.4808,  0.2031,  1.0628],\n",
       "        [-1.3213,  0.5866, -0.6162,  1.0366, -1.5004,  0.2157,  0.8076,  0.1225,\n",
       "         -0.5910,  0.7536,  0.9210, -0.3806, -0.5538,  1.2908, -0.9108, -0.4861,\n",
       "         -0.1263,  0.0079, -0.3208, -1.1787, -0.5603,  0.9574, -0.5309, -0.4200,\n",
       "         -0.2792,  1.0428,  2.7781],\n",
       "        [-0.2687, -0.4145,  0.3681,  0.1470, -0.6927, -0.3118, -1.4349, -0.5806,\n",
       "         -0.4621, -0.3751, -0.5762, -0.7392,  0.2264,  1.0696,  0.5438,  0.3717,\n",
       "         -1.6656,  0.7067,  0.9301,  0.1998,  0.9102,  2.4448, -0.8101, -1.8009,\n",
       "         -0.6599, -1.0971,  0.6082],\n",
       "        [-0.8636,  0.3186, -0.8668, -1.6749,  0.0031, -0.9745,  0.6340,  1.4380,\n",
       "          0.9378,  0.9944, -1.2422, -0.3523, -0.1459,  1.1013, -0.4666,  0.2216,\n",
       "          0.3979, -1.4365,  0.4101,  0.2478,  1.8727,  0.7681, -0.8983,  0.7593,\n",
       "          1.5357, -0.5145, -1.6819]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((729, 27))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0294, 0.0204, 0.0212, 0.0197, 0.0016, 0.0784, 0.0438, 0.0432, 0.0061,\n",
       "         0.0103, 0.0098, 0.0221, 0.1019, 0.0713, 0.0429, 0.0372, 0.0744, 0.0717,\n",
       "         0.0379, 0.0299, 0.0553, 0.0223, 0.0029, 0.0105, 0.0796, 0.0491, 0.0071],\n",
       "        [0.0304, 0.0259, 0.0619, 0.0127, 0.0214, 0.0056, 0.0267, 0.0036, 0.0246,\n",
       "         0.0156, 0.0142, 0.0172, 0.0208, 0.0682, 0.0727, 0.0398, 0.0114, 0.0119,\n",
       "         0.0315, 0.0113, 0.1368, 0.0319, 0.0185, 0.1328, 0.0199, 0.0394, 0.0931],\n",
       "        [0.0055, 0.0372, 0.0112, 0.0583, 0.0046, 0.0256, 0.0463, 0.0234, 0.0114,\n",
       "         0.0439, 0.0519, 0.0141, 0.0119, 0.0751, 0.0083, 0.0127, 0.0182, 0.0208,\n",
       "         0.0150, 0.0064, 0.0118, 0.0538, 0.0122, 0.0136, 0.0156, 0.0586, 0.3325],\n",
       "        [0.0196, 0.0169, 0.0370, 0.0297, 0.0128, 0.0188, 0.0061, 0.0143, 0.0161,\n",
       "         0.0176, 0.0144, 0.0122, 0.0321, 0.0746, 0.0441, 0.0371, 0.0048, 0.0519,\n",
       "         0.0649, 0.0313, 0.0637, 0.2953, 0.0114, 0.0042, 0.0132, 0.0086, 0.0471],\n",
       "        [0.0098, 0.0320, 0.0098, 0.0044, 0.0233, 0.0088, 0.0438, 0.0979, 0.0594,\n",
       "         0.0628, 0.0067, 0.0163, 0.0201, 0.0699, 0.0146, 0.0290, 0.0346, 0.0055,\n",
       "         0.0350, 0.0298, 0.1512, 0.0501, 0.0095, 0.0497, 0.1079, 0.0139, 0.0043]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0294, 0.0204, 0.0212, 0.0197, 0.0016, 0.0784, 0.0438, 0.0432, 0.0061,\n",
       "        0.0103, 0.0098, 0.0221, 0.1019, 0.0713, 0.0429, 0.0372, 0.0744, 0.0717,\n",
       "        0.0379, 0.0299, 0.0553, 0.0223, 0.0029, 0.0105, 0.0796, 0.0491, 0.0071])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5, 27) @ (27, 27) -> (5, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY ------------------------------>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 729 inputs (all possible pairs)\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: ..e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.01228625513613224\n",
      "log likelihood: -4.399273872375488\n",
      "negative log likelihood: 4.399273872375488\n",
      "--------\n",
      "bigram example 2: .em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.018050700426101685\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "bigram example 3: emm (indexes 148,13)\n",
      "input to the neural net: 148\n",
      "output probabilities from the neural net: tensor([0.0225, 0.1182, 0.0491, 0.0079, 0.0210, 0.0090, 0.0082, 0.0792, 0.0857,\n",
      "        0.0670, 0.0166, 0.0229, 0.0127, 0.0082, 0.1269, 0.0384, 0.0237, 0.0041,\n",
      "        0.0257, 0.0761, 0.0642, 0.0330, 0.0047, 0.0161, 0.0190, 0.0322, 0.0077])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.00817218329757452\n",
      "log likelihood: -4.807019233703613\n",
      "negative log likelihood: 4.807019233703613\n",
      "--------\n",
      "bigram example 4: mma (indexes 364,1)\n",
      "input to the neural net: 364\n",
      "output probabilities from the neural net: tensor([0.0749, 0.0326, 0.0100, 0.0488, 0.0360, 0.0102, 0.0430, 0.0246, 0.0238,\n",
      "        0.0511, 0.0037, 0.0019, 0.0767, 0.0118, 0.0222, 0.0137, 0.0130, 0.0087,\n",
      "        0.0104, 0.0319, 0.0474, 0.0094, 0.0037, 0.2830, 0.0036, 0.0918, 0.0120])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.032586511224508286\n",
      "log likelihood: -3.423856735229492\n",
      "negative log likelihood: 3.423856735229492\n",
      "--------\n",
      "bigram example 5: ma. (indexes 352,0)\n",
      "input to the neural net: 352\n",
      "output probabilities from the neural net: tensor([0.0108, 0.0381, 0.0228, 0.0631, 0.0425, 0.0151, 0.0231, 0.0194, 0.0038,\n",
      "        0.0091, 0.0537, 0.1120, 0.0369, 0.0126, 0.0208, 0.0180, 0.0141, 0.0290,\n",
      "        0.2448, 0.0187, 0.0165, 0.0254, 0.0155, 0.0227, 0.0569, 0.0238, 0.0307])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.010833128355443478\n",
      "log likelihood: -4.525146484375\n",
      "negative log likelihood: 4.525146484375\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 4.233973503112793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itopair[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.170337677001953\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, 3.7927768230438232\n",
      "k=1, 3.6387429237365723\n",
      "k=2, 3.5469932556152344\n",
      "k=3, 3.4792749881744385\n",
      "k=4, 3.4233877658843994\n",
      "k=5, 3.374289035797119\n",
      "k=6, 3.330148458480835\n",
      "k=7, 3.28998064994812\n",
      "k=8, 3.2531771659851074\n",
      "k=9, 3.219308614730835\n",
      "k=10, 3.18802547454834\n",
      "k=11, 3.159024238586426\n",
      "k=12, 3.13203501701355\n",
      "k=13, 3.106820821762085\n",
      "k=14, 3.0831780433654785\n",
      "k=15, 3.0609352588653564\n",
      "k=16, 3.039947509765625\n",
      "k=17, 3.020094394683838\n",
      "k=18, 3.0012738704681396\n",
      "k=19, 2.9833996295928955\n",
      "k=20, 2.9663970470428467\n",
      "k=21, 2.9502012729644775\n",
      "k=22, 2.93475604057312\n",
      "k=23, 2.920011043548584\n",
      "k=24, 2.905919313430786\n",
      "k=25, 2.8924405574798584\n",
      "k=26, 2.8795382976531982\n",
      "k=27, 2.8671772480010986\n",
      "k=28, 2.8553264141082764\n",
      "k=29, 2.843956470489502\n",
      "k=30, 2.833040952682495\n",
      "k=31, 2.8225536346435547\n",
      "k=32, 2.812471628189087\n",
      "k=33, 2.80277156829834\n",
      "k=34, 2.79343318939209\n",
      "k=35, 2.7844369411468506\n",
      "k=36, 2.7757630348205566\n",
      "k=37, 2.7673940658569336\n",
      "k=38, 2.7593135833740234\n",
      "k=39, 2.7515058517456055\n",
      "k=40, 2.743955612182617\n",
      "k=41, 2.73664927482605\n",
      "k=42, 2.7295737266540527\n",
      "k=43, 2.7227165699005127\n",
      "k=44, 2.716066598892212\n",
      "k=45, 2.70961332321167\n",
      "k=46, 2.703346014022827\n",
      "k=47, 2.697256326675415\n",
      "k=48, 2.6913349628448486\n",
      "k=49, 2.6855740547180176\n",
      "k=50, 2.6799657344818115\n",
      "k=51, 2.6745033264160156\n",
      "k=52, 2.669180393218994\n",
      "k=53, 2.6639904975891113\n",
      "k=54, 2.6589276790618896\n",
      "k=55, 2.653986692428589\n",
      "k=56, 2.649163007736206\n",
      "k=57, 2.644451141357422\n",
      "k=58, 2.6398468017578125\n",
      "k=59, 2.6353461742401123\n",
      "k=60, 2.6309449672698975\n",
      "k=61, 2.6266393661499023\n",
      "k=62, 2.6224260330200195\n",
      "k=63, 2.6183013916015625\n",
      "k=64, 2.614262819290161\n",
      "k=65, 2.61030650138855\n",
      "k=66, 2.6064305305480957\n",
      "k=67, 2.6026313304901123\n",
      "k=68, 2.598906993865967\n",
      "k=69, 2.595255136489868\n",
      "k=70, 2.591672658920288\n",
      "k=71, 2.588158369064331\n",
      "k=72, 2.584709405899048\n",
      "k=73, 2.581324338912964\n",
      "k=74, 2.578000545501709\n",
      "k=75, 2.574737071990967\n",
      "k=76, 2.571531295776367\n",
      "k=77, 2.5683822631835938\n",
      "k=78, 2.5652883052825928\n",
      "k=79, 2.5622470378875732\n",
      "k=80, 2.559258222579956\n",
      "k=81, 2.55631947517395\n",
      "k=82, 2.5534300804138184\n",
      "k=83, 2.550588607788086\n",
      "k=84, 2.547793388366699\n",
      "k=85, 2.545043706893921\n",
      "k=86, 2.5423383712768555\n",
      "k=87, 2.539675712585449\n",
      "k=88, 2.537055492401123\n",
      "k=89, 2.5344762802124023\n",
      "k=90, 2.5319371223449707\n",
      "k=91, 2.5294368267059326\n",
      "k=92, 2.526974678039551\n",
      "k=93, 2.524549722671509\n",
      "k=94, 2.5221612453460693\n",
      "k=95, 2.519808053970337\n",
      "k=96, 2.5174899101257324\n",
      "k=97, 2.5152053833007812\n",
      "k=98, 2.5129542350769043\n",
      "k=99, 2.510735273361206\n",
      "k=100, 2.5085480213165283\n",
      "k=101, 2.506392002105713\n",
      "k=102, 2.5042662620544434\n",
      "k=103, 2.502169609069824\n",
      "k=104, 2.5001025199890137\n",
      "k=105, 2.4980642795562744\n",
      "k=106, 2.4960532188415527\n",
      "k=107, 2.494069814682007\n",
      "k=108, 2.4921131134033203\n",
      "k=109, 2.4901821613311768\n",
      "k=110, 2.4882771968841553\n",
      "k=111, 2.4863975048065186\n",
      "k=112, 2.484541893005371\n",
      "k=113, 2.482710838317871\n",
      "k=114, 2.480903148651123\n",
      "k=115, 2.479118824005127\n",
      "k=116, 2.4773571491241455\n",
      "k=117, 2.4756178855895996\n",
      "k=118, 2.473900556564331\n",
      "k=119, 2.4722044467926025\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(120):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() #+ 0.01*(W**2).mean()\n",
    "  print(f'{k=}, {loss.item()}')\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss for nn trigram model is about the same as for bigram. Quality of generation is not much better.\n",
    "# NN also can't achieve 2.21 trigram statistical model result. Counting model has exact answers,\n",
    "# it counted trigrams. On the other hand with nn we are trying to learn these counts from data using gradient\n",
    "# descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jana.\n",
      "szmjutson.\n",
      "ar.\n",
      "xwuxaimmarocu.\n",
      "ruar.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647 + 191)\n",
    "\n",
    "for _ in range(5):\n",
    "  \n",
    "  out = ['.']\n",
    "  i = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([i]), num_classes=729).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0:\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7120,  2.1271,  0.9092,  1.0755,  1.1673,  1.0684, -0.2357,  0.2389,\n",
       "         0.5069,  0.1146,  1.5275,  1.7292,  1.0948,  1.5743,  0.7783, -0.2927,\n",
       "        -0.0236, -1.7571,  1.1366,  1.3630,  0.9107, -1.8276, -0.3398, -0.5439,\n",
       "        -1.3649,  0.0147,  0.5680], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6692,  0.5492,  0.4784, -1.2648,  1.1573, -0.6648, -0.9993, -1.4115,\n",
       "        -0.3538,  0.1504, -0.9233, -0.6285,  1.7133,  1.2062,  1.6988, -1.3918,\n",
       "        -1.1454, -1.7814,  1.4383,  0.5018, -0.4341,  0.2430,  0.7190, -1.3506,\n",
       "        -0.9531,  0.3832,  0.1936], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
