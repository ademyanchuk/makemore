{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. \n",
    "### Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {}\n",
    "for w in words:\n",
    "  chs = ['<S>'] + list(w) + ['<E>']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    trigram = (ch1, ch2, ch3)\n",
    "    t[trigram] = t.get(trigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'h', '<E>'), 1714),\n",
       " (('n', 'a', '<E>'), 1673),\n",
       " (('a', 'n', '<E>'), 1509),\n",
       " (('o', 'n', '<E>'), 1503),\n",
       " (('<S>', 'm', 'a'), 1453),\n",
       " (('<S>', 'j', 'a'), 1255),\n",
       " (('<S>', 'k', 'a'), 1254),\n",
       " (('e', 'n', '<E>'), 1217),\n",
       " (('l', 'y', 'n'), 976),\n",
       " (('y', 'n', '<E>'), 953),\n",
       " (('a', 'r', 'i'), 950),\n",
       " (('i', 'a', '<E>'), 903),\n",
       " (('i', 'e', '<E>'), 858),\n",
       " (('a', 'n', 'n'), 825),\n",
       " (('e', 'l', 'l'), 822),\n",
       " (('a', 'n', 'a'), 804),\n",
       " (('i', 'a', 'n'), 790),\n",
       " (('m', 'a', 'r'), 776),\n",
       " (('i', 'n', '<E>'), 766),\n",
       " (('e', 'l', '<E>'), 727),\n",
       " (('y', 'a', '<E>'), 716),\n",
       " (('a', 'n', 'i'), 703),\n",
       " (('<S>', 'd', 'a'), 700),\n",
       " (('l', 'a', '<E>'), 684),\n",
       " (('e', 'r', '<E>'), 683),\n",
       " (('i', 'y', 'a'), 669),\n",
       " (('l', 'a', 'n'), 647),\n",
       " (('<S>', 'b', 'r'), 646),\n",
       " (('n', 'n', 'a'), 633),\n",
       " (('<S>', 'a', 'l'), 632),\n",
       " (('<S>', 'c', 'a'), 628),\n",
       " (('r', 'a', '<E>'), 627),\n",
       " (('n', 'i', '<E>'), 625),\n",
       " (('<S>', 'a', 'n'), 623),\n",
       " (('n', 'n', '<E>'), 619),\n",
       " (('n', 'e', '<E>'), 607),\n",
       " (('e', 'e', '<E>'), 605),\n",
       " (('e', 'y', '<E>'), 602),\n",
       " (('<S>', 'k', 'e'), 601),\n",
       " (('a', 'l', 'e'), 601),\n",
       " (('<S>', 's', 'a'), 595),\n",
       " (('a', 'l', 'i'), 575),\n",
       " (('s', 'h', 'a'), 562),\n",
       " (('e', 'l', 'i'), 537),\n",
       " (('<S>', 'd', 'e'), 524),\n",
       " (('l', 'i', 'a'), 518),\n",
       " (('l', 'e', 'e'), 517),\n",
       " (('y', 'n', 'n'), 516),\n",
       " (('y', 'a', 'h'), 511),\n",
       " (('<S>', 'h', 'a'), 505),\n",
       " (('l', 'i', 'n'), 505),\n",
       " (('r', 'i', 'a'), 499),\n",
       " (('<S>', 'e', 'l'), 488),\n",
       " (('a', 'y', 'l'), 483),\n",
       " (('<S>', 'a', 'r'), 482),\n",
       " (('y', 'a', 'n'), 479),\n",
       " (('<S>', 'r', 'a'), 472),\n",
       " (('<S>', 'n', 'a'), 470),\n",
       " (('h', 'a', 'n'), 469),\n",
       " (('<S>', 'l', 'a'), 463),\n",
       " (('i', 'a', 'h'), 461),\n",
       " (('<S>', 'z', 'a'), 456),\n",
       " (('r', 'i', '<E>'), 452),\n",
       " (('l', 'e', 'y'), 443),\n",
       " (('<S>', 's', 'h'), 434),\n",
       " (('a', 'm', 'a'), 431),\n",
       " (('<S>', 'j', 'o'), 429),\n",
       " (('<S>', 't', 'a'), 424),\n",
       " (('<S>', 'j', 'e'), 403),\n",
       " (('l', 'e', 'i'), 401),\n",
       " (('i', 'e', 'l'), 395),\n",
       " (('r', 'i', 'e'), 394),\n",
       " (('<S>', 'm', 'i'), 393),\n",
       " (('a', 'n', 'd'), 392),\n",
       " (('a', 'y', 'a'), 389),\n",
       " (('<S>', 'a', 'm'), 384),\n",
       " (('l', 'e', 'n'), 383),\n",
       " (('<S>', 'r', 'o'), 382),\n",
       " (('y', 'l', 'a'), 381),\n",
       " (('i', 'n', 'a'), 379),\n",
       " (('t', 'o', 'n'), 377),\n",
       " (('a', 'r', 'a'), 371),\n",
       " (('<S>', 'a', 'd'), 366),\n",
       " (('<S>', 'l', 'e'), 366),\n",
       " (('l', 'e', '<E>'), 362),\n",
       " (('r', 'i', 's'), 360),\n",
       " (('a', 'm', 'i'), 355),\n",
       " (('e', 'l', 'y'), 353),\n",
       " (('a', 'l', 'a'), 353),\n",
       " (('<S>', 'c', 'h'), 352),\n",
       " (('s', 'o', 'n'), 341),\n",
       " (('l', 'l', 'a'), 337),\n",
       " (('l', 'l', 'e'), 331),\n",
       " (('h', 'a', 'r'), 329),\n",
       " (('d', 'e', 'n'), 318),\n",
       " (('a', 'l', 'y'), 310),\n",
       " (('e', 'l', 'a'), 308),\n",
       " (('a', 'v', 'i'), 306),\n",
       " (('y', 'l', 'e'), 303),\n",
       " (('i', 'g', 'h'), 290),\n",
       " (('i', 'o', 'n'), 290),\n",
       " (('<S>', 'e', 'm'), 288),\n",
       " (('a', 'r', 'l'), 287),\n",
       " (('i', 's', '<E>'), 287),\n",
       " (('a', 'e', 'l'), 287),\n",
       " (('l', 'i', 'e'), 285),\n",
       " (('h', 'a', '<E>'), 284),\n",
       " (('<S>', 'm', 'e'), 284),\n",
       " (('r', 'e', 'n'), 281),\n",
       " (('u', 's', '<E>'), 280),\n",
       " (('i', 'l', 'a'), 279),\n",
       " (('e', 'n', 'a'), 279),\n",
       " (('e', 'i', 'g'), 279),\n",
       " (('a', 's', 'h'), 276),\n",
       " (('m', 'a', 'n'), 274),\n",
       " (('l', 'l', 'i'), 271),\n",
       " (('l', 'y', '<E>'), 270),\n",
       " (('<S>', 'l', 'i'), 269),\n",
       " (('<S>', 'r', 'e'), 268),\n",
       " (('e', 'r', 'i'), 268),\n",
       " (('n', 'n', 'e'), 261),\n",
       " (('a', 'i', 'l'), 259),\n",
       " (('m', 'i', 'l'), 259),\n",
       " (('<S>', 'c', 'o'), 255),\n",
       " (('b', 'r', 'i'), 254),\n",
       " (('r', 'a', 'y'), 254),\n",
       " (('<S>', 'b', 'e'), 253),\n",
       " (('s', 'a', '<E>'), 253),\n",
       " (('k', 'e', 'n'), 252),\n",
       " (('<S>', 'k', 'i'), 250),\n",
       " (('i', 'r', 'a'), 248),\n",
       " (('r', 'a', 'n'), 248),\n",
       " (('i', 'r', '<E>'), 248),\n",
       " (('<S>', 'y', 'a'), 246),\n",
       " (('<S>', 'a', 'v'), 243),\n",
       " (('i', 'n', 'e'), 241),\n",
       " (('e', 'n', 'n'), 240),\n",
       " (('<S>', 'k', 'h'), 240),\n",
       " (('v', 'a', 'n'), 237),\n",
       " (('c', 'h', 'a'), 236),\n",
       " (('g', 'h', '<E>'), 235),\n",
       " (('c', 'e', '<E>'), 234),\n",
       " (('l', 'a', 'y'), 234),\n",
       " (('r', 'i', 'n'), 234),\n",
       " (('r', 'e', '<E>'), 231),\n",
       " (('<S>', 'k', 'y'), 229),\n",
       " (('a', 'r', '<E>'), 228),\n",
       " (('s', 'e', '<E>'), 228),\n",
       " (('i', 's', 'h'), 227),\n",
       " (('a', 'm', 'e'), 226),\n",
       " (('<S>', 'n', 'i'), 226),\n",
       " (('k', 'a', 'i'), 226),\n",
       " (('l', 'a', 'h'), 224),\n",
       " (('a', 'n', 'e'), 224),\n",
       " (('n', 'i', 'e'), 223),\n",
       " (('r', 'a', 'h'), 222),\n",
       " (('l', 'i', '<E>'), 221),\n",
       " (('n', 'n', 'i'), 221),\n",
       " (('o', 'r', 'i'), 220),\n",
       " (('e', 'l', 'e'), 219),\n",
       " (('k', 'a', 'r'), 218),\n",
       " (('d', 'e', 'l'), 217),\n",
       " (('k', 'a', 'y'), 215),\n",
       " (('j', 'a', 'y'), 212),\n",
       " (('i', 'l', 'l'), 211),\n",
       " (('m', 'a', 'l'), 210),\n",
       " (('k', 'a', '<E>'), 210),\n",
       " (('m', 'e', 'r'), 209),\n",
       " (('y', 'l', 'i'), 209),\n",
       " (('<S>', 't', 'r'), 209),\n",
       " (('r', 'i', 'c'), 209),\n",
       " (('l', 'i', 's'), 208),\n",
       " (('<S>', 'a', 'a'), 207),\n",
       " (('d', 'a', 'n'), 207),\n",
       " (('r', 'e', 'e'), 205),\n",
       " (('i', 'l', 'y'), 203),\n",
       " (('e', 't', 't'), 203),\n",
       " (('d', 'a', 'l'), 203),\n",
       " (('l', 'l', '<E>'), 203),\n",
       " (('b', 'r', 'a'), 203),\n",
       " (('o', 'r', 'a'), 202),\n",
       " (('b', 'e', 'l'), 201),\n",
       " (('r', 'y', '<E>'), 201),\n",
       " (('<S>', 'r', 'i'), 201),\n",
       " (('m', 'o', 'n'), 201),\n",
       " (('e', 'e', 'n'), 200),\n",
       " (('a', 'r', 'e'), 198),\n",
       " (('i', 'l', 'e'), 197),\n",
       " (('t', 'a', '<E>'), 197),\n",
       " (('d', 'a', '<E>'), 197),\n",
       " (('e', 'a', 'n'), 196),\n",
       " (('a', 'l', 'l'), 196),\n",
       " (('r', 'o', 's'), 196),\n",
       " (('a', 'r', 'y'), 195),\n",
       " (('a', 'd', 'e'), 194),\n",
       " (('<S>', 'a', 's'), 194),\n",
       " (('o', 'n', 'n'), 194),\n",
       " (('c', 'a', 'r'), 193),\n",
       " (('n', 'y', '<E>'), 192),\n",
       " (('<S>', 'k', 'o'), 192),\n",
       " (('a', 'r', 'r'), 192),\n",
       " (('<S>', 'a', 'b'), 190),\n",
       " (('a', 'd', 'i'), 190),\n",
       " (('b', 'r', 'e'), 189),\n",
       " (('a', 'i', 'r'), 189),\n",
       " (('a', 'm', '<E>'), 189),\n",
       " (('o', 'n', 'i'), 189),\n",
       " (('m', 'e', 'l'), 188),\n",
       " (('<S>', 'l', 'o'), 186),\n",
       " (('n', 'a', 'h'), 185),\n",
       " (('n', 'd', 'r'), 184),\n",
       " (('a', 'i', '<E>'), 183),\n",
       " (('<S>', 's', 'e'), 182),\n",
       " (('r', 'r', 'i'), 182),\n",
       " (('<S>', 't', 'e'), 181),\n",
       " (('i', 'l', 'i'), 180),\n",
       " (('e', 'y', 'a'), 179),\n",
       " (('t', 'h', '<E>'), 178),\n",
       " (('<S>', 'j', 'u'), 178),\n",
       " (('a', 'y', 'd'), 178),\n",
       " (('l', 'a', 'i'), 177),\n",
       " (('a', 'n', 't'), 177),\n",
       " (('a', 'i', 'n'), 177),\n",
       " (('t', 'e', '<E>'), 175),\n",
       " (('<S>', 'p', 'a'), 175),\n",
       " (('i', 'k', 'a'), 175),\n",
       " (('a', 'n', 'y'), 175),\n",
       " (('a', 'l', '<E>'), 175),\n",
       " (('m', 'a', '<E>'), 174),\n",
       " (('a', 'a', 'n'), 174),\n",
       " (('a', 'b', 'e'), 173),\n",
       " (('l', 'e', 'a'), 173),\n",
       " (('<S>', 'a', 'y'), 173),\n",
       " (('a', 's', '<E>'), 173),\n",
       " (('<S>', 's', 'i'), 172),\n",
       " (('m', 'i', 'r'), 172),\n",
       " (('s', 'i', 'a'), 171),\n",
       " (('k', 'h', 'a'), 171),\n",
       " (('e', 'r', 'e'), 170),\n",
       " (('s', 'h', 'i'), 170),\n",
       " (('<S>', 'b', 'a'), 169),\n",
       " (('t', 'h', 'a'), 168),\n",
       " (('e', 'n', 'i'), 168),\n",
       " (('<S>', 'm', 'o'), 168),\n",
       " (('k', 'a', 'l'), 168),\n",
       " (('r', 'o', 'n'), 168),\n",
       " (('a', 'v', 'e'), 166),\n",
       " (('o', 's', 'e'), 166),\n",
       " (('s', 's', 'a'), 166),\n",
       " (('<S>', 'g', 'r'), 165),\n",
       " (('s', 't', 'o'), 165),\n",
       " (('<S>', 'n', 'e'), 164),\n",
       " (('a', 'd', 'a'), 164),\n",
       " (('r', 'e', 'y'), 163),\n",
       " (('a', 'y', '<E>'), 163),\n",
       " (('<S>', 'l', 'u'), 162),\n",
       " (('d', 'r', 'i'), 162),\n",
       " (('a', 'v', 'a'), 161),\n",
       " (('<S>', 'v', 'i'), 161),\n",
       " (('e', 'm', 'i'), 160),\n",
       " (('v', 'e', 'r'), 160),\n",
       " (('s', 't', 'i'), 159),\n",
       " (('s', 'a', 'n'), 159),\n",
       " (('<S>', 'f', 'a'), 158),\n",
       " (('e', 'a', '<E>'), 158),\n",
       " (('a', 's', 'i'), 157),\n",
       " (('<S>', 'n', 'o'), 156),\n",
       " (('i', 's', 't'), 156),\n",
       " (('<S>', 'e', 'v'), 154),\n",
       " (('s', 't', 'e'), 154),\n",
       " (('<S>', 'a', 'i'), 154),\n",
       " (('t', 'a', 'l'), 153),\n",
       " (('l', 'a', 'r'), 153),\n",
       " (('m', 'a', 'y'), 153),\n",
       " (('e', 's', 's'), 153),\n",
       " (('h', 'a', 'l'), 153),\n",
       " (('d', 'a', 'r'), 153),\n",
       " (('h', 'a', 'm'), 153),\n",
       " (('<S>', 's', 'o'), 152),\n",
       " (('<S>', 'a', 'u'), 152),\n",
       " (('b', 'e', 'r'), 152),\n",
       " (('<S>', 'a', 'z'), 152),\n",
       " (('e', 'n', 'e'), 151),\n",
       " (('k', 'a', 'm'), 151),\n",
       " (('<S>', 'h', 'e'), 151),\n",
       " (('j', 'a', 'm'), 151),\n",
       " (('s', 'h', '<E>'), 149),\n",
       " (('d', 'e', 'r'), 149),\n",
       " (('o', 'r', '<E>'), 148),\n",
       " (('v', 'i', 'n'), 148),\n",
       " (('v', 'i', 'a'), 147),\n",
       " (('e', 's', 't'), 147),\n",
       " (('l', 'o', 'n'), 147),\n",
       " (('o', 'n', 'a'), 147),\n",
       " (('a', 'e', '<E>'), 147),\n",
       " (('r', 'l', 'e'), 146),\n",
       " (('r', 'i', 'o'), 146),\n",
       " (('n', 'e', 'l'), 145),\n",
       " (('a', 'i', 's'), 145),\n",
       " (('e', 'r', 'a'), 145),\n",
       " (('n', 'l', 'e'), 143),\n",
       " (('r', 'e', 'l'), 143),\n",
       " (('h', 'i', '<E>'), 143),\n",
       " (('i', 's', 'a'), 142),\n",
       " (('e', 'v', 'e'), 142),\n",
       " (('t', 'i', 'n'), 142),\n",
       " (('a', 't', 'h'), 142),\n",
       " (('d', 'o', 'n'), 142),\n",
       " (('s', 'e', 'n'), 142),\n",
       " (('m', 'i', 'n'), 141),\n",
       " (('<S>', 's', 'u'), 141),\n",
       " (('k', 'e', 'l'), 141),\n",
       " (('t', 'a', 'n'), 141),\n",
       " (('n', 'i', 'a'), 141),\n",
       " (('r', 'y', 'n'), 140),\n",
       " (('j', 'a', 'n'), 140),\n",
       " (('n', 'a', 'l'), 140),\n",
       " (('e', 'r', 'r'), 140),\n",
       " (('e', 'm', 'a'), 140),\n",
       " (('s', 't', 'a'), 139),\n",
       " (('i', 'o', '<E>'), 139),\n",
       " (('s', 'l', 'e'), 138),\n",
       " (('a', 'i', 'd'), 138),\n",
       " (('e', 's', '<E>'), 138),\n",
       " (('l', 'o', 'r'), 137),\n",
       " (('m', 'a', 'd'), 136),\n",
       " (('s', 'a', 'm'), 136),\n",
       " (('<S>', 'g', 'a'), 136),\n",
       " (('r', 'i', 'y'), 136),\n",
       " (('<S>', 's', 't'), 135),\n",
       " (('i', 'e', 'r'), 135),\n",
       " (('<S>', 'z', 'e'), 135),\n",
       " (('j', 'a', 'h'), 135),\n",
       " (('k', 'i', 'n'), 134),\n",
       " (('l', 'i', 'l'), 133),\n",
       " (('e', 'v', 'a'), 133),\n",
       " (('h', 'a', 'y'), 133),\n",
       " (('t', 'e', 'r'), 133),\n",
       " (('a', 'y', 's'), 133),\n",
       " (('<S>', 't', 'y'), 133),\n",
       " (('h', 'e', 'r'), 132),\n",
       " (('r', 'a', 'i'), 132),\n",
       " (('e', 'o', 'n'), 131),\n",
       " (('<S>', 'd', 'i'), 130),\n",
       " (('c', 'h', 'e'), 130),\n",
       " (('a', 'c', 'e'), 129),\n",
       " (('i', 'c', 'k'), 129),\n",
       " (('d', 'y', '<E>'), 128),\n",
       " (('<S>', 'g', 'i'), 128),\n",
       " (('e', 'm', '<E>'), 128),\n",
       " (('y', 'o', 'n'), 128),\n",
       " (('r', 'a', 'e'), 127),\n",
       " (('n', 'c', 'e'), 127),\n",
       " (('i', 's', 'e'), 126),\n",
       " (('n', 'd', '<E>'), 126),\n",
       " (('<S>', 'p', 'r'), 125),\n",
       " (('i', 'n', 'g'), 125),\n",
       " (('<S>', 'i', 's'), 124),\n",
       " (('m', 'i', '<E>'), 124),\n",
       " (('i', 't', 'h'), 124),\n",
       " (('l', 'l', 'y'), 124),\n",
       " (('o', 'l', 'a'), 124),\n",
       " (('u', 'r', 'i'), 123),\n",
       " (('a', 'z', 'a'), 123),\n",
       " (('j', 'e', 'r'), 123),\n",
       " (('i', 'r', 'e'), 122),\n",
       " (('i', 's', 's'), 122),\n",
       " (('t', 't', 'e'), 121),\n",
       " (('<S>', 'v', 'a'), 121),\n",
       " (('c', 'a', 'l'), 121),\n",
       " (('a', 'k', 'a'), 121),\n",
       " (('z', 'a', 'r'), 121),\n",
       " (('y', 'd', 'e'), 121),\n",
       " (('v', 'i', '<E>'), 121),\n",
       " (('g', 'r', 'a'), 120),\n",
       " (('m', 'a', 'i'), 120),\n",
       " (('c', 'k', '<E>'), 120),\n",
       " (('i', 'l', '<E>'), 119),\n",
       " (('h', 'a', 'i'), 119),\n",
       " (('e', 'n', 'd'), 119),\n",
       " (('v', 'e', 'n'), 119),\n",
       " (('<S>', 'd', 'o'), 119),\n",
       " (('r', 'i', 't'), 119),\n",
       " (('v', 'o', 'n'), 119),\n",
       " (('<S>', 'l', 'y'), 118),\n",
       " (('r', 'y', 'a'), 118),\n",
       " (('l', 'i', 'y'), 117),\n",
       " (('s', 'e', 'l'), 117),\n",
       " (('i', 'm', 'a'), 117),\n",
       " (('b', 'r', 'y'), 116),\n",
       " (('e', 't', 'h'), 114),\n",
       " (('d', 'r', 'e'), 113),\n",
       " (('n', 'a', 'y'), 113),\n",
       " (('k', 'a', 's'), 113),\n",
       " (('t', 'e', 'n'), 113),\n",
       " (('h', 'e', 'l'), 112),\n",
       " (('o', 'r', 'e'), 112),\n",
       " (('<S>', 't', 'o'), 112),\n",
       " (('a', 't', 'a'), 111),\n",
       " (('<S>', 'r', 'y'), 111),\n",
       " (('e', 'i', 'l'), 111),\n",
       " (('r', 'a', 'l'), 111),\n",
       " (('h', 'r', 'i'), 111),\n",
       " (('a', 'h', 'a'), 111),\n",
       " (('t', 'o', 'r'), 110),\n",
       " (('<S>', 'g', 'e'), 110),\n",
       " (('a', 'n', 'g'), 110),\n",
       " (('i', 'd', 'e'), 110),\n",
       " (('m', 'a', 'k'), 109),\n",
       " (('<S>', 't', 'i'), 109),\n",
       " (('n', 'd', 'e'), 109),\n",
       " (('a', 'u', 'r'), 108),\n",
       " (('<S>', 'r', 'u'), 108),\n",
       " (('d', 'y', 'n'), 108),\n",
       " (('n', 'i', 'y'), 108),\n",
       " (('s', 'h', 'e'), 108),\n",
       " (('t', 'r', 'i'), 107),\n",
       " (('n', 'i', 's'), 107),\n",
       " (('n', 'o', '<E>'), 107),\n",
       " (('e', 't', '<E>'), 106),\n",
       " (('d', 'i', 'e'), 106),\n",
       " (('t', 'h', 'e'), 106),\n",
       " (('h', 'e', 'n'), 106),\n",
       " (('a', 'd', '<E>'), 106),\n",
       " (('a', 'i', 'a'), 105),\n",
       " (('j', 'a', 'i'), 105),\n",
       " (('<S>', 'o', 'l'), 104),\n",
       " (('k', 'y', 'l'), 104),\n",
       " (('d', 'i', '<E>'), 104),\n",
       " (('n', 'a', 'n'), 104),\n",
       " (('t', 'r', 'e'), 104),\n",
       " (('l', 'o', '<E>'), 104),\n",
       " (('r', 'a', 'c'), 103),\n",
       " (('a', 'r', 'o'), 103),\n",
       " (('i', 'n', 'n'), 103),\n",
       " (('<S>', 'm', 'y'), 103),\n",
       " (('s', 's', 'i'), 103),\n",
       " (('t', 't', '<E>'), 102),\n",
       " (('c', 'o', 'r'), 102),\n",
       " (('a', 's', 't'), 102),\n",
       " (('a', 'r', 't'), 102),\n",
       " (('n', 'a', 'i'), 102),\n",
       " (('n', 'o', 'r'), 101),\n",
       " (('n', 'a', 't'), 101),\n",
       " (('e', 'r', 'l'), 101),\n",
       " (('l', 'e', 's'), 101),\n",
       " (('a', 'm', 'o'), 101),\n",
       " (('a', 'h', 'i'), 101),\n",
       " (('a', 'i', 'y'), 101),\n",
       " (('o', 'n', 't'), 101),\n",
       " (('e', 'm', 'm'), 100),\n",
       " (('t', 'y', 'n'), 100),\n",
       " (('h', 'a', 'd'), 99),\n",
       " (('g', 'a', 'n'), 99),\n",
       " (('<S>', 't', 'h'), 99),\n",
       " (('i', 't', 'a'), 99),\n",
       " (('l', 'y', 'a'), 99),\n",
       " (('a', 'n', 's'), 99),\n",
       " (('a', 'k', 'i'), 99),\n",
       " (('a', 'n', 'o'), 98),\n",
       " (('d', 'i', 'a'), 98),\n",
       " (('z', 'a', '<E>'), 98),\n",
       " (('m', 'o', 'r'), 98),\n",
       " (('a', 'y', 'n'), 98),\n",
       " (('a', 'k', 'e'), 98),\n",
       " (('m', 'a', 't'), 98),\n",
       " (('y', 'i', 'a'), 98),\n",
       " (('r', 'l', 'i'), 97),\n",
       " (('y', 'e', 'l'), 97),\n",
       " (('z', 'a', 'y'), 97),\n",
       " (('r', 'a', 'm'), 97),\n",
       " (('v', 'a', 'l'), 96),\n",
       " (('u', 'l', 'i'), 96),\n",
       " (('y', 'r', 'i'), 96),\n",
       " (('a', 's', 's'), 96),\n",
       " (('i', 'd', 'a'), 96),\n",
       " (('h', 'o', 'n'), 96),\n",
       " (('<S>', 'k', 'r'), 96),\n",
       " (('m', 'i', 'a'), 95),\n",
       " (('e', 'n', 't'), 95),\n",
       " (('v', 'i', 'e'), 95),\n",
       " (('i', 'm', '<E>'), 95),\n",
       " (('a', 'd', 'd'), 94),\n",
       " (('c', 'h', 'i'), 94),\n",
       " (('i', 'k', '<E>'), 94),\n",
       " (('v', 'a', '<E>'), 93),\n",
       " (('i', 'z', 'a'), 93),\n",
       " (('n', 'e', 's'), 93),\n",
       " (('j', 'o', 's'), 93),\n",
       " (('k', 'a', 't'), 93),\n",
       " (('<S>', 'e', 's'), 93),\n",
       " (('y', 'n', 'e'), 93),\n",
       " (('a', 'z', 'i'), 93),\n",
       " (('c', 'a', 'm'), 92),\n",
       " (('<S>', 'p', 'e'), 92),\n",
       " (('e', 'a', 'h'), 92),\n",
       " (('d', 'e', '<E>'), 92),\n",
       " (('c', 'e', 'l'), 92),\n",
       " (('<S>', 'n', 'y'), 92),\n",
       " (('a', 'r', 's'), 92),\n",
       " (('a', 'r', 'd'), 92),\n",
       " (('l', 'e', 't'), 91),\n",
       " (('<S>', 'w', 'i'), 91),\n",
       " (('i', 'e', 'n'), 91),\n",
       " (('a', 'm', 'y'), 91),\n",
       " (('e', 'i', '<E>'), 91),\n",
       " (('<S>', 'z', 'y'), 91),\n",
       " (('d', 'a', 'm'), 91),\n",
       " (('r', 'o', '<E>'), 91),\n",
       " (('<S>', 'a', 'h'), 91),\n",
       " (('i', 'u', 's'), 91),\n",
       " (('o', 'v', 'a'), 90),\n",
       " (('s', 'a', 'l'), 90),\n",
       " (('n', 'i', 'c'), 90),\n",
       " (('y', 'n', 'a'), 90),\n",
       " (('n', 'd', 'a'), 90),\n",
       " (('<S>', 'e', 'r'), 90),\n",
       " (('d', 'a', 'y'), 90),\n",
       " (('<S>', 'r', 'h'), 90),\n",
       " (('v', 'i', 'o'), 89),\n",
       " (('s', 'y', 'n'), 89),\n",
       " (('n', 'a', 's'), 89),\n",
       " (('m', 'a', 'h'), 89),\n",
       " (('t', 'y', '<E>'), 88),\n",
       " (('a', 'r', 'm'), 88),\n",
       " (('a', 'h', 'm'), 88),\n",
       " (('r', 'e', 't'), 87),\n",
       " (('l', 'e', 'r'), 87),\n",
       " (('i', 'n', 'i'), 87),\n",
       " (('j', 'e', 'n'), 87),\n",
       " (('i', 'n', 'd'), 87),\n",
       " (('g', 'e', 'n'), 86),\n",
       " (('d', 'r', 'a'), 86),\n",
       " (('r', 'e', 's'), 86),\n",
       " (('n', 'g', 'e'), 86),\n",
       " (('o', 'n', 'e'), 86),\n",
       " (('<S>', 'z', 'i'), 86),\n",
       " (('<S>', 'y', 'u'), 86),\n",
       " (('<S>', 'y', 'o'), 86),\n",
       " (('a', 'b', 'r'), 85),\n",
       " (('g', 'e', 'l'), 85),\n",
       " (('<S>', 'b', 'l'), 85),\n",
       " (('d', 'e', 'm'), 85),\n",
       " (('e', 'y', 'l'), 85),\n",
       " (('<S>', 'm', 'u'), 85),\n",
       " (('e', 'r', 'y'), 84),\n",
       " (('l', 'y', 's'), 84),\n",
       " (('h', 'i', 'r'), 84),\n",
       " (('b', 'e', 'n'), 84),\n",
       " (('o', 'l', 'u'), 84),\n",
       " (('u', 'w', 'a'), 84),\n",
       " (('e', 'l', 'o'), 83),\n",
       " (('z', 'e', 'l'), 83),\n",
       " (('o', 'l', 'e'), 83),\n",
       " (('s', 'a', 'r'), 83),\n",
       " (('l', 'e', 'x'), 83),\n",
       " (('e', 'v', 'i'), 83),\n",
       " (('a', 'n', 'c'), 83),\n",
       " (('a', 'a', 'r'), 83),\n",
       " (('e', 's', 'h'), 83),\n",
       " (('<S>', 'q', 'u'), 82),\n",
       " (('j', 'a', 's'), 82),\n",
       " (('m', 'i', 'k'), 82),\n",
       " (('r', 'e', 'i'), 82),\n",
       " (('a', 's', 'e'), 82),\n",
       " (('y', 'l', 'y'), 82),\n",
       " (('n', 'g', '<E>'), 82),\n",
       " (('n', 't', 'a'), 82),\n",
       " (('h', 'i', 'a'), 81),\n",
       " (('l', 'i', 'z'), 81),\n",
       " (('t', 'a', 'y'), 81),\n",
       " (('m', 'a', 'e'), 81),\n",
       " (('j', 'a', 'c'), 81),\n",
       " (('a', 'l', 'o'), 81),\n",
       " (('h', 'i', 'l'), 81),\n",
       " (('n', 'i', 'k'), 81),\n",
       " (('n', 'n', 'y'), 81),\n",
       " (('s', 's', 'e'), 81),\n",
       " (('r', 'l', 'y'), 80),\n",
       " (('e', 'm', 'e'), 80),\n",
       " (('<S>', 'e', 'd'), 80),\n",
       " (('n', 'e', 'e'), 80),\n",
       " (('r', 'r', 'a'), 80),\n",
       " (('m', 'i', 'e'), 80),\n",
       " (('n', 'y', 'a'), 80),\n",
       " (('o', 'u', 'r'), 79),\n",
       " (('<S>', 'f', 'r'), 79),\n",
       " (('a', 'y', 'v'), 79),\n",
       " (('e', 'e', 'l'), 79),\n",
       " (('l', 'u', 'w'), 79),\n",
       " (('i', 'v', 'i'), 78),\n",
       " (('z', 'i', 'e'), 78),\n",
       " (('c', 'o', 'l'), 78),\n",
       " (('y', 'r', 'a'), 78),\n",
       " (('l', 'i', 'o'), 78),\n",
       " (('u', 'n', '<E>'), 78),\n",
       " (('p', 'e', 'r'), 77),\n",
       " (('m', 'a', 'c'), 77),\n",
       " (('o', 'r', 'd'), 77),\n",
       " (('a', 'c', 'h'), 77),\n",
       " (('<S>', 'h', 'o'), 77),\n",
       " (('n', 't', 'e'), 77),\n",
       " (('y', 'a', 'r'), 77),\n",
       " (('j', 'a', 'l'), 77),\n",
       " (('<S>', 'd', 'r'), 77),\n",
       " (('<S>', 'b', 'o'), 77),\n",
       " (('y', 'c', 'e'), 77),\n",
       " (('o', 's', '<E>'), 77),\n",
       " (('s', 'a', 'b'), 76),\n",
       " (('v', 'e', 'l'), 76),\n",
       " (('a', 'b', 'i'), 76),\n",
       " (('e', 'r', 's'), 76),\n",
       " (('n', 'e', 'y'), 76),\n",
       " (('i', 'c', 'h'), 76),\n",
       " (('c', 'a', 's'), 76),\n",
       " (('a', 'y', 'e'), 76),\n",
       " (('u', 's', 't'), 76),\n",
       " (('n', 'a', 'v'), 76),\n",
       " (('d', 'i', 'n'), 76),\n",
       " (('t', 'r', 'a'), 76),\n",
       " (('e', 'e', 'm'), 76),\n",
       " (('u', 'a', 'n'), 76),\n",
       " (('r', 'y', 'l'), 75),\n",
       " (('i', 'r', 'i'), 75),\n",
       " (('m', 'i', 'y'), 75),\n",
       " (('u', 'e', 'l'), 75),\n",
       " (('k', 'e', 'i'), 75),\n",
       " (('k', 'y', 'n'), 75),\n",
       " (('t', 'i', 'a'), 75),\n",
       " (('<S>', 'a', 'k'), 75),\n",
       " (('o', 'm', 'i'), 74),\n",
       " (('j', 'u', 'l'), 74),\n",
       " (('s', 'i', 'e'), 74),\n",
       " (('a', 't', 'i'), 74),\n",
       " (('a', 'h', 'l'), 73),\n",
       " (('<S>', 'j', 'i'), 73),\n",
       " (('a', 't', 't'), 73),\n",
       " (('z', 'a', 'n'), 73),\n",
       " (('e', 'e', 'r'), 73),\n",
       " (('m', 'm', 'a'), 72),\n",
       " (('<S>', 'z', 'o'), 72),\n",
       " (('r', 'e', 'a'), 72),\n",
       " (('<S>', 'a', 't'), 72),\n",
       " (('y', 'l', 'o'), 72),\n",
       " (('t', 'h', 'i'), 72),\n",
       " (('k', 'e', 'y'), 72),\n",
       " (('n', 'a', 'r'), 72),\n",
       " (('r', 'r', 'e'), 72),\n",
       " (('<S>', 'f', 'i'), 71),\n",
       " (('<S>', 's', 'y'), 71),\n",
       " (('c', 'i', 'a'), 71),\n",
       " (('d', 'e', 's'), 71),\n",
       " (('o', 'h', 'a'), 71),\n",
       " (('s', 'a', 'i'), 71),\n",
       " (('t', 'a', 'r'), 71),\n",
       " (('z', 'i', 'a'), 71),\n",
       " (('i', 'n', 'o'), 71),\n",
       " (('e', 'd', '<E>'), 71),\n",
       " (('o', 'l', 'l'), 70),\n",
       " (('q', 'u', 'e'), 70),\n",
       " (('i', 'v', 'a'), 70),\n",
       " (('a', 'r', 'c'), 70),\n",
       " (('k', 'a', 'n'), 70),\n",
       " (('o', 'l', 'i'), 69),\n",
       " (('b', 'r', 'o'), 69),\n",
       " (('l', 'u', 'c'), 69),\n",
       " (('k', 'e', 'r'), 69),\n",
       " (('d', 'a', 'i'), 69),\n",
       " (('r', 'e', 'm'), 69),\n",
       " (('a', 'd', 'r'), 69),\n",
       " (('c', 'h', 'r'), 69),\n",
       " (('d', 'a', 'v'), 69),\n",
       " (('z', 'a', 'i'), 69),\n",
       " (('l', 'a', 'm'), 69),\n",
       " (('y', 'a', 's'), 69),\n",
       " (('m', 'e', 'e'), 69),\n",
       " (('i', 's', 'o'), 68),\n",
       " (('<S>', 'c', 'l'), 68),\n",
       " (('e', 'n', 'z'), 68),\n",
       " (('r', 'y', 's'), 68),\n",
       " (('<S>', 'w', 'a'), 68),\n",
       " (('s', 'i', 'r'), 68),\n",
       " (('i', 'h', 'a'), 68),\n",
       " (('o', 'u', 's'), 68),\n",
       " (('s', 'e', 'r'), 67),\n",
       " (('q', 'u', 'i'), 67),\n",
       " (('<S>', 'v', 'e'), 67),\n",
       " (('m', 'i', 'c'), 67),\n",
       " (('<S>', 'c', 'r'), 67),\n",
       " (('<S>', 'h', 'u'), 67),\n",
       " (('<S>', 'i', 'l'), 67),\n",
       " (('s', 't', 'y'), 67),\n",
       " (('a', 'i', 'z'), 67),\n",
       " (('l', 'a', 'k'), 66),\n",
       " (('a', 't', 'e'), 66),\n",
       " (('i', 'c', '<E>'), 66),\n",
       " (('z', 'a', 'l'), 66),\n",
       " (('i', 'd', '<E>'), 66),\n",
       " (('o', 'm', 'a'), 66),\n",
       " (('h', 'a', 'w'), 66),\n",
       " (('a', 'u', 'n'), 66),\n",
       " (('<S>', 'c', 'e'), 65),\n",
       " (('i', 'l', 'o'), 65),\n",
       " (('a', 'b', 'd'), 65),\n",
       " (('d', 'o', '<E>'), 65),\n",
       " (('d', 'i', 'l'), 64),\n",
       " (('e', 'r', 'o'), 64),\n",
       " (('k', 'r', 'i'), 64),\n",
       " (('y', 's', '<E>'), 64),\n",
       " (('o', 'r', 'r'), 64),\n",
       " (('t', 'e', 'l'), 63),\n",
       " (('i', 's', 'l'), 63),\n",
       " (('n', 's', 'l'), 63),\n",
       " (('i', 'c', 'e'), 63),\n",
       " (('m', 'y', 'a'), 63),\n",
       " (('o', 's', 'a'), 63),\n",
       " (('c', 'a', '<E>'), 63),\n",
       " (('n', 'e', 't'), 63),\n",
       " (('k', 'e', 'e'), 63),\n",
       " (('k', 'o', 'l'), 63),\n",
       " (('d', 'e', 'e'), 63),\n",
       " (('r', 'i', 'l'), 62),\n",
       " (('o', 'r', 'y'), 62),\n",
       " (('k', 'o', 'r'), 62),\n",
       " (('j', 'a', 'k'), 62),\n",
       " (('h', 'a', 's'), 62),\n",
       " (('h', 'a', 'a'), 62),\n",
       " (('i', 'm', 'i'), 62),\n",
       " (('p', 'h', 'i'), 61),\n",
       " (('b', 'e', 't'), 61),\n",
       " (('u', 'n', 'a'), 61),\n",
       " (('a', 'r', 'k'), 61),\n",
       " (('e', 's', 'l'), 61),\n",
       " (('a', 'y', 't'), 61),\n",
       " (('i', 'v', 'e'), 61),\n",
       " (('j', 'e', 's'), 61),\n",
       " (('e', 'n', 's'), 61),\n",
       " (('e', 'n', 'l'), 61),\n",
       " (('k', 'a', 'e'), 61),\n",
       " (('<S>', 'w', 'e'), 61),\n",
       " (('<S>', 'y', 'e'), 61),\n",
       " (('a', 'z', 'e'), 60),\n",
       " (('c', 'l', 'a'), 60),\n",
       " (('m', 'e', 'n'), 60),\n",
       " (('l', 'e', 'o'), 60),\n",
       " (('<S>', 'e', 'n'), 60),\n",
       " (('n', 'd', 'i'), 60),\n",
       " (('r', 'i', 'k'), 60),\n",
       " (('<S>', 'i', 'n'), 60),\n",
       " (('t', 'l', 'e'), 60),\n",
       " (('s', 'i', 'n'), 60),\n",
       " (('t', 'i', '<E>'), 60),\n",
       " (('g', 'e', 'r'), 60),\n",
       " (('a', 's', 'a'), 60),\n",
       " (('a', 'c', 'k'), 59),\n",
       " (('m', 'b', 'e'), 59),\n",
       " (('c', 'i', 'e'), 59),\n",
       " (('<S>', 'i', 'z'), 59),\n",
       " (('a', 'd', 'o'), 59),\n",
       " (('d', 'o', 'r'), 59),\n",
       " (('y', 's', 'e'), 59),\n",
       " (('s', 'l', 'y'), 59),\n",
       " (('z', 'l', 'e'), 59),\n",
       " (('i', 'j', 'a'), 59),\n",
       " (('n', 'e', 'r'), 59),\n",
       " (('w', 'a', '<E>'), 59),\n",
       " (('a', 'v', 'o'), 59),\n",
       " (('i', 'i', '<E>'), 59),\n",
       " (('k', 'o', '<E>'), 59),\n",
       " (('l', 'l', 'o'), 58),\n",
       " (('i', 'n', 's'), 58),\n",
       " (('n', 'i', 't'), 58),\n",
       " (('e', 'n', 'c'), 58),\n",
       " (('y', 's', 'o'), 58),\n",
       " (('g', 'h', 'a'), 58),\n",
       " (('a', 'y', 'c'), 58),\n",
       " (('i', 'z', 'e'), 58),\n",
       " (('v', 'i', 'k'), 58),\n",
       " (('k', 'i', '<E>'), 58),\n",
       " (('t', 'o', '<E>'), 58),\n",
       " (('e', 's', 'i'), 57),\n",
       " (('h', 'i', 'n'), 57),\n",
       " (('e', 'i', 'a'), 57),\n",
       " (('i', 'c', 'a'), 57),\n",
       " (('r', 'o', 'm'), 57),\n",
       " (('r', 'm', 'a'), 57),\n",
       " (('h', 'y', 'a'), 57),\n",
       " (('a', 'd', 'y'), 57),\n",
       " (('a', 'h', 'n'), 57),\n",
       " (('<S>', 'x', 'a'), 57),\n",
       " (('r', 'd', '<E>'), 57),\n",
       " (('w', 'i', 'l'), 56),\n",
       " (('e', 'd', 'e'), 56),\n",
       " (('a', 'c', 'i'), 56),\n",
       " (('u', 'r', 'a'), 56),\n",
       " (('h', 'l', 'a'), 56),\n",
       " (('j', 'a', 'z'), 56),\n",
       " (('s', 's', '<E>'), 56),\n",
       " (('a', 't', '<E>'), 56),\n",
       " (('c', 'a', 'i'), 56),\n",
       " (('d', 'e', 'v'), 56),\n",
       " (('v', 'a', 'r'), 56),\n",
       " (('q', 'u', 'a'), 56),\n",
       " (('<S>', 's', 'k'), 55),\n",
       " (('b', 'y', '<E>'), 55),\n",
       " (('k', 'i', 'a'), 55),\n",
       " (('w', 'i', 'n'), 55),\n",
       " (('t', 'a', 'v'), 55),\n",
       " (('j', 'o', 'h'), 55),\n",
       " (('l', 'a', 's'), 55),\n",
       " (('e', 'd', 'a'), 55),\n",
       " (('f', 'a', 'r'), 55),\n",
       " (('z', 'e', 'n'), 55),\n",
       " (('j', 'a', '<E>'), 55),\n",
       " (('<S>', 'a', 'e'), 55),\n",
       " (('<S>', 'h', 'i'), 55),\n",
       " (('i', 't', '<E>'), 55),\n",
       " (('a', 'y', 'm'), 55),\n",
       " (('t', 'a', 'i'), 55),\n",
       " (('i', 'a', 's'), 55),\n",
       " (('l', 'i', 'v'), 54),\n",
       " (('f', 'i', 'n'), 54),\n",
       " (('j', 'o', 'r'), 54),\n",
       " (('m', 'y', '<E>'), 54),\n",
       " (('r', 'n', 'e'), 54),\n",
       " (('b', 'l', 'a'), 54),\n",
       " (('i', 'a', 'r'), 54),\n",
       " (('a', 'l', 'd'), 54),\n",
       " (('a', 'm', 'r'), 54),\n",
       " (('f', 'r', 'a'), 54),\n",
       " (('n', 't', 'o'), 54),\n",
       " (('s', 'i', '<E>'), 54),\n",
       " (('<S>', 'e', 'i'), 54),\n",
       " (('n', 's', 'h'), 54),\n",
       " (('y', 'r', 'e'), 54),\n",
       " (('n', 'd', 'y'), 53),\n",
       " (('h', 'a', 'v'), 53),\n",
       " (('k', 'a', 'h'), 53),\n",
       " (('t', 't', 'a'), 53),\n",
       " (('s', 'o', 'l'), 53),\n",
       " (('r', 'i', 'g'), 53),\n",
       " (('a', 'e', 'd'), 53),\n",
       " (('n', 'o', 'v'), 52),\n",
       " (('c', 'k', 'e'), 52),\n",
       " (('e', 'g', 'a'), 52),\n",
       " (('i', 'a', 'm'), 52),\n",
       " (('<S>', 'p', 'h'), 52),\n",
       " (('e', 's', 'a'), 52),\n",
       " (('<S>', 'e', 'z'), 52),\n",
       " (('u', 'e', '<E>'), 52),\n",
       " (('h', 'y', 'l'), 52),\n",
       " (('a', 'k', 'y'), 52),\n",
       " (('a', 'w', 'n'), 52),\n",
       " (('a', 'j', 'a'), 52),\n",
       " (('i', 'k', 'o'), 52),\n",
       " (('d', 'd', 'i'), 51),\n",
       " (('g', 'a', 'r'), 51),\n",
       " (('n', 'd', 'o'), 51),\n",
       " (('e', 'i', 'r'), 51),\n",
       " (('s', 'e', 'y'), 51),\n",
       " (('t', 'i', 'e'), 51),\n",
       " (('a', 'm', 'b'), 51),\n",
       " (('p', 'r', 'i'), 51),\n",
       " (('e', 'r', 't'), 51),\n",
       " (('r', 'i', 'd'), 51),\n",
       " (('k', 'i', 'e'), 51),\n",
       " (('j', 'a', 'e'), 51),\n",
       " (('i', 't', 't'), 51),\n",
       " (('h', 'i', 't'), 51),\n",
       " (('a', 'i', 'm'), 51),\n",
       " (('w', 'n', '<E>'), 51),\n",
       " (('r', 'a', 'd'), 51),\n",
       " (('a', 'y', 'o'), 51),\n",
       " (('e', 'a', 'l'), 51),\n",
       " (('g', 'i', 'a'), 50),\n",
       " (('e', 'p', 'h'), 50),\n",
       " (('a', 'i', 't'), 50),\n",
       " (('i', 'x', '<E>'), 50),\n",
       " (('z', 'a', 'h'), 50),\n",
       " (('c', 'a', 'y'), 50),\n",
       " (('a', 'n', 'u'), 50),\n",
       " (('e', 'k', '<E>'), 50),\n",
       " (('r', 'i', 'u'), 50),\n",
       " (('a', 'u', 'd'), 49),\n",
       " (('<S>', 'i', 'v'), 49),\n",
       " (('<S>', 'i', 'r'), 49),\n",
       " (('e', 's', 'e'), 49),\n",
       " (('m', 'y', 'l'), 49),\n",
       " (('<S>', 'f', 'e'), 49),\n",
       " (('i', 'd', 'y'), 49),\n",
       " (('y', 'a', 'l'), 49),\n",
       " (('r', 'e', 'd'), 49),\n",
       " (('h', 'a', 'e'), 49),\n",
       " (('g', 'r', 'e'), 49),\n",
       " (('k', 'y', 'r'), 49),\n",
       " (('b', 'a', 'r'), 49),\n",
       " (('a', 'n', 'v'), 49),\n",
       " (('e', 'r', 'm'), 49),\n",
       " (('m', 'e', 's'), 49),\n",
       " (('j', 'a', 'r'), 49),\n",
       " (('a', 'r', 'v'), 49),\n",
       " (('n', 't', 'i'), 48),\n",
       " (('u', 'r', 'e'), 48),\n",
       " (('k', 'e', '<E>'), 48),\n",
       " (('<S>', 'm', 'c'), 48),\n",
       " (('a', 'k', 'o'), 48),\n",
       " (('w', 'y', 'n'), 48),\n",
       " (('u', 'l', 'a'), 48),\n",
       " (('m', 'e', 'i'), 48),\n",
       " (('n', 'a', 'e'), 48),\n",
       " (('o', 'm', 'e'), 48),\n",
       " (('m', 'a', 's'), 48),\n",
       " (('r', 'a', 's'), 48),\n",
       " (('j', 'a', 'v'), 48),\n",
       " (('u', 'i', 'n'), 47),\n",
       " (('o', 'e', 'l'), 47),\n",
       " (('<S>', 'z', 'u'), 47),\n",
       " (('w', 'e', 'n'), 47),\n",
       " (('n', 'o', 'n'), 47),\n",
       " (('e', 'd', 'i'), 47),\n",
       " (('i', 'n', 'c'), 47),\n",
       " (('a', 'a', 'd'), 47),\n",
       " (('e', 'i', 's'), 47),\n",
       " (('c', 'e', 'n'), 47),\n",
       " (('<S>', 'o', 'r'), 47),\n",
       " (('z', 'a', 'm'), 47),\n",
       " (('z', 'a', 'k'), 47),\n",
       " (('i', 'r', 'o'), 47),\n",
       " (('a', 'a', 'l'), 46),\n",
       " (('n', 'z', 'i'), 46),\n",
       " (('e', 'e', 's'), 46),\n",
       " (('l', 'a', 'u'), 46),\n",
       " (('o', 'n', 'd'), 46),\n",
       " (('n', 'y', 'l'), 46),\n",
       " (('s', 'e', 'a'), 46),\n",
       " (('e', 'm', 'o'), 46),\n",
       " (('<S>', 'c', 'y'), 46),\n",
       " (('s', 'i', 'm'), 46),\n",
       " (('m', 'i', 's'), 46),\n",
       " (('a', 'v', 'y'), 46),\n",
       " (('b', 'a', '<E>'), 46),\n",
       " (('u', 'm', 'a'), 46),\n",
       " (('k', 'h', 'y'), 46),\n",
       " (('r', 'u', 's'), 46),\n",
       " (('a', 'h', 'e'), 46),\n",
       " (('r', 's', 'h'), 46),\n",
       " (('y', 'a', 'a'), 46),\n",
       " (('p', 'a', 'r'), 45),\n",
       " (('h', 'e', 'a'), 45),\n",
       " (('f', 'e', 'r'), 45),\n",
       " (('y', 's', 'i'), 45),\n",
       " (('y', 'd', 'a'), 45),\n",
       " (('m', 'a', 'x'), 45),\n",
       " (('<S>', 'g', 'u'), 45),\n",
       " (('n', 'v', 'i'), 45),\n",
       " (('z', 'e', '<E>'), 45),\n",
       " (('t', 'a', 'm'), 45),\n",
       " (('a', 't', 'o'), 45),\n",
       " (('j', 'o', 'n'), 45),\n",
       " (('a', 'j', '<E>'), 45),\n",
       " (('a', 'v', '<E>'), 45),\n",
       " (('r', 'l', 'o'), 44),\n",
       " (('s', 'k', 'y'), 44),\n",
       " (('n', 't', 'h'), 44),\n",
       " (('i', 't', 'y'), 44),\n",
       " (('j', 'a', 'd'), 44),\n",
       " (('i', 'n', 'l'), 44),\n",
       " (('k', 'i', 'm'), 44),\n",
       " (('o', 's', 'i'), 44),\n",
       " (('g', 'e', '<E>'), 44),\n",
       " (('f', 'r', 'e'), 44),\n",
       " (('k', 'l', 'e'), 44),\n",
       " (('i', 't', 'z'), 44),\n",
       " (('s', 'a', 'h'), 44),\n",
       " (('<S>', 'c', 'i'), 44),\n",
       " (('e', 'n', 'o'), 44),\n",
       " (('d', 'e', 'a'), 44),\n",
       " (('a', 'y', 'r'), 44),\n",
       " (('e', 'v', 'o'), 44),\n",
       " (('c', 'o', 'n'), 44),\n",
       " (('s', 'h', 'o'), 44),\n",
       " (('h', 'm', 'a'), 44),\n",
       " (('e', 'c', 'k'), 44),\n",
       " (('j', 'a', 'x'), 44),\n",
       " (('b', 'a', 's'), 44),\n",
       " (('d', 'h', 'a'), 44),\n",
       " (('o', 'n', 'y'), 43),\n",
       " (('s', 'i', 'd'), 43),\n",
       " (('y', 'e', '<E>'), 43),\n",
       " (('y', 's', 't'), 43),\n",
       " (('l', 'o', 'u'), 43),\n",
       " (('e', 'n', 'y'), 43),\n",
       " (('y', 'v', 'i'), 43),\n",
       " (('s', 'm', 'a'), 43),\n",
       " (('u', 'h', 'a'), 43),\n",
       " (('v', 'e', 'e'), 43),\n",
       " (('m', 'i', 't'), 43),\n",
       " (('t', 'h', 'o'), 43),\n",
       " (('y', 'm', 'a'), 43),\n",
       " (('d', 'i', 's'), 42),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair -> char\n",
    "# m = number of pairs; n = number of chars: same as in bigrams\n",
    "# so our matrix of counts/probs will be m x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually need all possible pairs of our chars, as sampling can come up\n",
    "# with a pair not seen it the actual data. 27*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as with chars, but we need all pairs\n",
    "pairs = []\n",
    "for i in range(27):\n",
    "  for j in range(27):\n",
    "    pairs.append(itos[i] + itos[j])\n",
    "pairs.sort()\n",
    "# need to populate pair to ix and ix to pair dicts\n",
    "pairtoi = {p:i for i,p in enumerate(pairs)}\n",
    "itopair = {i:p for p,i in pairtoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 27)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairtoi), len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matrix of counts how often a pair followed by a char\n",
    "N = torch.zeros((729, 27), dtype=torch.int32)\n",
    "for w in words:\n",
    "  # as we now using pairs, we start with ..\n",
    "  # didn't come up with better solution\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  # we can use indecies, but for simplicity just 3 iters\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    N[ix1, ix2] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float() # N+1 is smoothing, so to not have inf loss on zero prob\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "jakasid.\n",
      "prelay.\n",
      "adin.\n",
      "kairritoper.\n",
      "sathen.\n",
      "sameia.\n",
      "yanileniassibduinrwin.\n",
      "lessiyanayla.\n",
      "te.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "  \n",
    "  out = ['.']  # prepopulate with first .\n",
    "  i = 0 # start sampling from what char follows '..'\n",
    "  while True:\n",
    "    p = P[i]\n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0: # we've sampled end of word\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying different seeds, it looks like more generated words became name-like. Tend to generate very long words as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-504653.)\n",
      "nll=tensor(504653.)\n",
      "2.2119739055633545\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "# for w in [\"alexey\"]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "    # print(f'{ch1}{ch2}{ch3}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing context to have a probability of char following a pair improves loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . e\n",
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of trigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    print(ch1, ch2, ch3)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=729).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 729])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2249,  0.9268,  0.5115,  0.5983, -1.1390,  1.0081, -0.5331, -1.3072,\n",
       "         -1.4007, -1.3394,  1.2692, -0.3741,  2.5223, -1.4576, -0.4786, -1.4972,\n",
       "          0.3316, -0.4075, -2.0935,  0.1361,  0.8890,  0.0319, -0.3023, -0.0750,\n",
       "          0.5372,  1.2407,  0.2319],\n",
       "        [-0.0229, -0.0321,  1.6305, -0.1696, -1.5931, -1.3193, -0.6700,  0.5976,\n",
       "         -0.4984,  1.3065, -1.2362, -0.1958,  1.6151,  1.7665, -0.4873,  0.2932,\n",
       "          1.2997, -0.2488,  0.3454, -1.3379,  0.4373, -0.0130,  0.7801,  0.0419,\n",
       "         -0.2599, -0.4158, -1.4023],\n",
       "        [ 0.0726, -0.0574,  1.0055, -1.3377,  1.5328, -1.1245, -2.0126, -0.1728,\n",
       "          0.8392,  0.3975,  1.6762,  0.0852, -0.8431,  0.8452, -1.9324, -0.1576,\n",
       "         -0.5848, -0.5178,  0.0727, -1.9551,  0.5365,  0.2742,  1.9091,  1.2922,\n",
       "          0.5233, -0.7467,  0.2822],\n",
       "        [-1.9088, -0.1388,  1.0697, -2.1051,  0.3637,  1.2557, -2.4404,  1.2145,\n",
       "          0.3150, -0.1444,  0.6528,  0.1451, -0.3456, -1.3960,  0.5895, -0.2948,\n",
       "          0.1238,  1.7904, -0.6318, -0.3139, -1.3846, -0.0047, -0.0461, -0.5907,\n",
       "         -0.6802, -0.8024, -0.8397],\n",
       "        [ 0.2771,  0.6731, -0.7111,  0.5574,  1.4729,  0.9839,  2.1832,  0.6814,\n",
       "          0.0837, -0.6875, -1.1333, -0.1815,  0.4547, -0.9484, -0.9128,  1.0779,\n",
       "         -0.8997,  0.3127, -1.4502, -1.6800, -0.2758, -0.1034, -1.1582, -0.8128,\n",
       "          0.7350,  1.0445,  1.0776]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((729, 27))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0282, 0.0570, 0.0376, 0.0410, 0.0072, 0.0618, 0.0132, 0.0061, 0.0056,\n",
       "         0.0059, 0.0802, 0.0155, 0.2808, 0.0052, 0.0140, 0.0050, 0.0314, 0.0150,\n",
       "         0.0028, 0.0258, 0.0548, 0.0233, 0.0167, 0.0209, 0.0386, 0.0780, 0.0284],\n",
       "        [0.0230, 0.0228, 0.1201, 0.0199, 0.0048, 0.0063, 0.0120, 0.0428, 0.0143,\n",
       "         0.0869, 0.0068, 0.0193, 0.1183, 0.1376, 0.0145, 0.0315, 0.0863, 0.0183,\n",
       "         0.0332, 0.0062, 0.0364, 0.0232, 0.0513, 0.0245, 0.0181, 0.0155, 0.0058],\n",
       "        [0.0243, 0.0214, 0.0618, 0.0059, 0.1047, 0.0073, 0.0030, 0.0190, 0.0524,\n",
       "         0.0337, 0.1209, 0.0246, 0.0097, 0.0527, 0.0033, 0.0193, 0.0126, 0.0135,\n",
       "         0.0243, 0.0032, 0.0387, 0.0298, 0.1526, 0.0824, 0.0382, 0.0107, 0.0300],\n",
       "        [0.0044, 0.0258, 0.0862, 0.0036, 0.0426, 0.1038, 0.0026, 0.0997, 0.0405,\n",
       "         0.0256, 0.0568, 0.0342, 0.0209, 0.0073, 0.0533, 0.0220, 0.0335, 0.1773,\n",
       "         0.0157, 0.0216, 0.0074, 0.0294, 0.0282, 0.0164, 0.0150, 0.0133, 0.0128],\n",
       "        [0.0300, 0.0446, 0.0112, 0.0397, 0.0993, 0.0609, 0.2020, 0.0450, 0.0247,\n",
       "         0.0114, 0.0073, 0.0190, 0.0359, 0.0088, 0.0091, 0.0669, 0.0093, 0.0311,\n",
       "         0.0053, 0.0042, 0.0173, 0.0205, 0.0071, 0.0101, 0.0475, 0.0647, 0.0669]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0282, 0.0570, 0.0376, 0.0410, 0.0072, 0.0618, 0.0132, 0.0061, 0.0056,\n",
       "        0.0059, 0.0802, 0.0155, 0.2808, 0.0052, 0.0140, 0.0050, 0.0314, 0.0150,\n",
       "        0.0028, 0.0258, 0.0548, 0.0233, 0.0167, 0.0209, 0.0386, 0.0780, 0.0284])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5, 27) @ (27, 27) -> (5, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY ------------------------------>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 729 inputs (all possible pairs)\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: ..e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.01228625513613224\n",
      "log likelihood: -4.399273872375488\n",
      "negative log likelihood: 4.399273872375488\n",
      "--------\n",
      "bigram example 2: .em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.018050700426101685\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "bigram example 3: emm (indexes 148,13)\n",
      "input to the neural net: 148\n",
      "output probabilities from the neural net: tensor([0.0225, 0.1182, 0.0491, 0.0079, 0.0210, 0.0090, 0.0082, 0.0792, 0.0857,\n",
      "        0.0670, 0.0166, 0.0229, 0.0127, 0.0082, 0.1269, 0.0384, 0.0237, 0.0041,\n",
      "        0.0257, 0.0761, 0.0642, 0.0330, 0.0047, 0.0161, 0.0190, 0.0322, 0.0077])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.00817218329757452\n",
      "log likelihood: -4.807019233703613\n",
      "negative log likelihood: 4.807019233703613\n",
      "--------\n",
      "bigram example 4: mma (indexes 364,1)\n",
      "input to the neural net: 364\n",
      "output probabilities from the neural net: tensor([0.0749, 0.0326, 0.0100, 0.0488, 0.0360, 0.0102, 0.0430, 0.0246, 0.0238,\n",
      "        0.0511, 0.0037, 0.0019, 0.0767, 0.0118, 0.0222, 0.0137, 0.0130, 0.0087,\n",
      "        0.0104, 0.0319, 0.0474, 0.0094, 0.0037, 0.2830, 0.0036, 0.0918, 0.0120])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.032586511224508286\n",
      "log likelihood: -3.423856735229492\n",
      "negative log likelihood: 3.423856735229492\n",
      "--------\n",
      "bigram example 5: ma. (indexes 352,0)\n",
      "input to the neural net: 352\n",
      "output probabilities from the neural net: tensor([0.0108, 0.0381, 0.0228, 0.0631, 0.0425, 0.0151, 0.0231, 0.0194, 0.0038,\n",
      "        0.0091, 0.0537, 0.1120, 0.0369, 0.0126, 0.0208, 0.0180, 0.0141, 0.0290,\n",
      "        0.2448, 0.0187, 0.0165, 0.0254, 0.0155, 0.0227, 0.0569, 0.0238, 0.0307])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.010833128355443478\n",
      "log likelihood: -4.525146484375\n",
      "negative log likelihood: 4.525146484375\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 4.233973503112793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itopair[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   5, 148, 364, 352])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.128016948699951\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.', '.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = pairtoi[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, 3.7927768230438232\n",
      "k=1, 3.4378983974456787\n",
      "k=2, 3.321561336517334\n",
      "k=3, 3.1370038986206055\n",
      "k=4, 3.0594258308410645\n",
      "k=5, 2.994174003601074\n",
      "k=6, 2.91180157661438\n",
      "k=7, 2.9094626903533936\n",
      "k=8, 2.8129067420959473\n",
      "k=9, 2.773369073867798\n",
      "k=10, 2.7473950386047363\n",
      "k=11, 2.716261625289917\n",
      "k=12, 2.705533742904663\n",
      "k=13, 2.7144110202789307\n",
      "k=14, 2.6553118228912354\n",
      "k=15, 2.645838975906372\n",
      "k=16, 2.651409149169922\n",
      "k=17, 2.7192015647888184\n",
      "k=18, 2.627261161804199\n",
      "k=19, 2.5751070976257324\n",
      "k=20, 2.5796000957489014\n",
      "k=21, 2.574028968811035\n",
      "k=22, 2.6388494968414307\n",
      "k=23, 2.5547096729278564\n",
      "k=24, 2.544301748275757\n",
      "k=25, 2.5965373516082764\n",
      "k=26, 2.5183115005493164\n",
      "k=27, 2.5199191570281982\n",
      "k=28, 2.592808246612549\n",
      "k=29, 2.5120465755462646\n",
      "k=30, 2.4963674545288086\n",
      "k=31, 2.535010576248169\n",
      "k=32, 2.46429443359375\n",
      "k=33, 2.4678473472595215\n",
      "k=34, 2.513728141784668\n",
      "k=35, 2.4499590396881104\n",
      "k=36, 2.4547183513641357\n",
      "k=37, 2.459859848022461\n",
      "k=38, 2.445643186569214\n",
      "k=39, 2.5028297901153564\n",
      "k=40, 2.4349894523620605\n",
      "k=41, 2.437338352203369\n",
      "k=42, 2.5100502967834473\n",
      "k=43, 2.431997537612915\n",
      "k=44, 2.427827835083008\n",
      "k=45, 2.493957996368408\n",
      "k=46, 2.422333240509033\n",
      "k=47, 2.4184279441833496\n",
      "k=48, 2.4951653480529785\n",
      "k=49, 2.4175832271575928\n",
      "k=50, 2.4048051834106445\n",
      "k=51, 2.456139087677002\n",
      "k=52, 2.3904829025268555\n",
      "k=53, 2.395805597305298\n",
      "k=54, 2.461313247680664\n",
      "k=55, 2.3881752490997314\n",
      "k=56, 2.402830123901367\n",
      "k=57, 2.4746432304382324\n",
      "k=58, 2.3955917358398438\n",
      "k=59, 2.370664119720459\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(60):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() #+ 0.01*(W**2).mean()\n",
    "  print(f'{k=}, {loss.item()}')\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -200 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, 2.4115524291992188\n",
      "k=1, 2.3711133003234863\n",
      "k=2, 2.3531670570373535\n",
      "k=3, 2.3519272804260254\n",
      "k=4, 2.3508434295654297\n",
      "k=5, 2.349788188934326\n",
      "k=6, 2.348755359649658\n",
      "k=7, 2.3477394580841064\n",
      "k=8, 2.346738576889038\n",
      "k=9, 2.3457517623901367\n",
      "k=10, 2.344777822494507\n",
      "k=11, 2.3438167572021484\n",
      "k=12, 2.342867612838745\n",
      "k=13, 2.341930627822876\n",
      "k=14, 2.3410050868988037\n",
      "k=15, 2.3400909900665283\n",
      "k=16, 2.3391876220703125\n",
      "k=17, 2.3382954597473145\n",
      "k=18, 2.337413787841797\n",
      "k=19, 2.3365426063537598\n",
      "k=20, 2.335681676864624\n",
      "k=21, 2.3348309993743896\n",
      "k=22, 2.3339900970458984\n",
      "k=23, 2.3331587314605713\n",
      "k=24, 2.3323373794555664\n",
      "k=25, 2.3315250873565674\n",
      "k=26, 2.3307223320007324\n",
      "k=27, 2.3299286365509033\n",
      "k=28, 2.3291432857513428\n",
      "k=29, 2.328367233276367\n",
      "k=30, 2.3276000022888184\n",
      "k=31, 2.326840877532959\n",
      "k=32, 2.3260903358459473\n",
      "k=33, 2.325347900390625\n",
      "k=34, 2.324613332748413\n",
      "k=35, 2.3238871097564697\n",
      "k=36, 2.3231685161590576\n",
      "k=37, 2.3224575519561768\n",
      "k=38, 2.3217544555664062\n",
      "k=39, 2.321058750152588\n",
      "k=40, 2.3203699588775635\n",
      "k=41, 2.3196890354156494\n",
      "k=42, 2.31901478767395\n",
      "k=43, 2.318347692489624\n",
      "k=44, 2.317687511444092\n",
      "k=45, 2.3170340061187744\n",
      "k=46, 2.31638765335083\n",
      "k=47, 2.315747022628784\n",
      "k=48, 2.3151135444641113\n",
      "k=49, 2.314486026763916\n",
      "k=50, 2.3138654232025146\n",
      "k=51, 2.3132503032684326\n",
      "k=52, 2.3126418590545654\n",
      "k=53, 2.3120391368865967\n",
      "k=54, 2.3114426136016846\n",
      "k=55, 2.310851573944092\n",
      "k=56, 2.3102664947509766\n",
      "k=57, 2.3096871376037598\n",
      "k=58, 2.3091135025024414\n",
      "k=59, 2.3085453510284424\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(60):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=729).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() #+ 0.01*(W**2).mean()\n",
    "  print(f'{k=}, {loss.item()}')\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -100 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasid.\n",
      "prelay.\n",
      "adin.\n",
      "kairritonian.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(5):\n",
    "  \n",
    "  out = ['.']\n",
    "  i = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([i]), num_classes=729).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    j = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[j])\n",
    "    if j == 0:\n",
    "      break\n",
    "    # update index i\n",
    "    pair = ''.join(out[-2:])  # last 2 chars\n",
    "    i = pairtoi[pair]\n",
    "  print(''.join(out[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.6937,  2.1662,  0.9490,  1.1152,  1.2068,  1.1080, -0.1936,  0.2796,\n",
       "         0.5471,  0.1556,  1.5668,  1.7685,  1.1344,  1.6136,  0.8182, -0.2504,\n",
       "         0.0178, -1.7029,  1.1762,  1.4025,  0.9505, -1.8643, -0.2973, -0.5004,\n",
       "        -1.3299,  0.0559,  0.6082], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3681,  0.7741,  0.6876, -1.1817,  1.3476, -0.5805, -1.4108, -1.6406,\n",
       "        -0.0625,  0.4751, -1.2273, -0.2655,  1.8956,  1.3958,  1.8813, -1.8733,\n",
       "        -1.5648, -2.0690,  1.6239,  0.7086, -0.3027,  0.4618,  0.9357, -2.0023,\n",
       "        -1.2318,  0.5929,  0.4618], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
