{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb36da93-1549-4ba3-983b-b0072c2e18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on reimplementing Andrej Karpathy's nano-gpt from this video\n",
    "# https://youtu.be/kCc8FmEb1nY?si=cdnNJrPwDEPQPn0C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f8b0799-2eb2-4476-b042-03d9b2197203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d33324-f131-4daf-8e9b-630f9ab3dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"input.txt\", mode='r') as f:\n",
    "  words = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a207b2-bbe0-429e-9e6d-62b0bc4e43db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(words[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ffde2f-6d2a-4b72-9673-ce5a0cd24401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "vocab = sorted(set(words))\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "print(''.join(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ca03120-fbb5-4281-ad4a-3418514e335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 57, 1, 47, 58, 1, 61, 53, 56, 49, 47, 52, 45, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Is it working?'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple character level tokenization\n",
    "stoi = {c:i for i,c in enumerate(vocab)}\n",
    "itos = {i:c for i,c in enumerate(vocab)}\n",
    "# encode and decode functions\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "print(encode('Is it working?'))\n",
    "decode(encode('Is it working?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2993aecf-85d7-4b44-9b9a-1f08ba8b13bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# we'd like to use torch tensors for training NNs\n",
    "data = torch.tensor(encode(words), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "18e2e876-acf3-49ff-ae29-e82e05fd1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 1003854, test size: 111540\n"
     ]
    }
   ],
   "source": [
    "# train/validation split\n",
    "n = int(0.9 * len(words))\n",
    "train = data[:n]\n",
    "test = data[n:]\n",
    "print(f'train size: {len(train)}, test size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe65f53-05b9-4940-96f5-6334963fe24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n",
      "for input context: tensor([18]) target is: 47\n",
      "for input context: tensor([18, 47]) target is: 56\n",
      "for input context: tensor([18, 47, 56]) target is: 57\n",
      "for input context: tensor([18, 47, 56, 57]) target is: 58\n",
      "for input context: tensor([18, 47, 56, 57, 58]) target is: 1\n",
      "for input context: tensor([18, 47, 56, 57, 58,  1]) target is: 15\n",
      "for input context: tensor([18, 47, 56, 57, 58,  1, 15]) target is: 47\n",
      "for input context: tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is: 58\n"
     ]
    }
   ],
   "source": [
    "# context size = one sampled block gives us block_size of examples to train on\n",
    "block_size = 8\n",
    "block = train[:block_size+1]\n",
    "print(block)\n",
    "for i in range(1, block_size+1):\n",
    "  print(f'for input context: {block[:i]} target is: {block[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b29e1d-a1ae-49e5-a1b1-f11e6aa4ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "# so training examples are defined like this\n",
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48bab30c-e901-4c44-b25a-6d65ae5f4103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "---------\n",
      "for input context: [24] target is: 43\n",
      "for input context: [24, 43] target is: 58\n",
      "for input context: [24, 43, 58] target is: 5\n",
      "for input context: [24, 43, 58, 5] target is: 57\n",
      "for input context: [24, 43, 58, 5, 57] target is: 1\n",
      "for input context: [24, 43, 58, 5, 57, 1] target is: 46\n",
      "for input context: [24, 43, 58, 5, 57, 1, 46] target is: 43\n",
      "for input context: [24, 43, 58, 5, 57, 1, 46, 43] target is: 39\n",
      "for input context: [44] target is: 53\n",
      "for input context: [44, 53] target is: 56\n",
      "for input context: [44, 53, 56] target is: 1\n",
      "for input context: [44, 53, 56, 1] target is: 58\n",
      "for input context: [44, 53, 56, 1, 58] target is: 46\n",
      "for input context: [44, 53, 56, 1, 58, 46] target is: 39\n",
      "for input context: [44, 53, 56, 1, 58, 46, 39] target is: 58\n",
      "for input context: [44, 53, 56, 1, 58, 46, 39, 58] target is: 1\n",
      "for input context: [52] target is: 58\n",
      "for input context: [52, 58] target is: 1\n",
      "for input context: [52, 58, 1] target is: 58\n",
      "for input context: [52, 58, 1, 58] target is: 46\n",
      "for input context: [52, 58, 1, 58, 46] target is: 39\n",
      "for input context: [52, 58, 1, 58, 46, 39] target is: 58\n",
      "for input context: [52, 58, 1, 58, 46, 39, 58] target is: 1\n",
      "for input context: [52, 58, 1, 58, 46, 39, 58, 1] target is: 46\n",
      "for input context: [25] target is: 17\n",
      "for input context: [25, 17] target is: 27\n",
      "for input context: [25, 17, 27] target is: 10\n",
      "for input context: [25, 17, 27, 10] target is: 0\n",
      "for input context: [25, 17, 27, 10, 0] target is: 21\n",
      "for input context: [25, 17, 27, 10, 0, 21] target is: 1\n",
      "for input context: [25, 17, 27, 10, 0, 21, 1] target is: 54\n",
      "for input context: [25, 17, 27, 10, 0, 21, 1, 54] target is: 39\n"
     ]
    }
   ],
   "source": [
    "# we want to work with batches of data as we aren't going to feed in the whole dataset\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "  data = train if split == \"train\" else test\n",
    "  ix = torch.randint(len(data) - block_size, (batch_size,)) # randint range is exclusive\n",
    "  x, y = [], []\n",
    "  for i in ix:\n",
    "    x.append(data[i:i+block_size])\n",
    "    y.append(data[i+1:i+block_size+1])\n",
    "  x = torch.stack(x)\n",
    "  y = torch.stack(y)\n",
    "  return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('---------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "  for t in range(block_size):\n",
    "    context = xb[b, :t+1]\n",
    "    target = yb[b, t]\n",
    "    print(f'for input context: {context.tolist()} target is: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9cd851c0-3278-48aa-b557-2f48ef34feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.648484230041504\n",
      "\n",
      "p fvLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3!dcbf?pGXepydZJSrF$Jrqt!:wwWSzPN\n"
     ]
    }
   ],
   "source": [
    "# bigram character-level language mode\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 32\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "  def __init__(self, vocab_size):\n",
    "    super().__init__()\n",
    "    self.token_lookup_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "  def forward(self, x, target=None):\n",
    "    logits = self.token_lookup_table(x)\n",
    "    if target is None:\n",
    "      loss = None\n",
    "    else:\n",
    "      B, T, C = logits.shape\n",
    "      # to conform to pytorch cross-entropy signature\n",
    "      logits = logits.view(B*T, C)\n",
    "      target = target.view(B*T)\n",
    "      loss = F.cross_entropy(logits, target)\n",
    "    return logits, loss\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def generate(self, idx, max_num_tokens):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_num_tokens):\n",
    "      logits, loss = self(idx)\n",
    "      # only last time step\n",
    "      logits = logits[:, -1, :] # (B, C)\n",
    "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "      next_i = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "      idx = torch.cat((idx, next_i), dim=1) # (B, T+1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "model = BigramModel(vocab_size)\n",
    "Xb, Yb = get_batch('train')\n",
    "logits, loss = model(Xb, Yb)\n",
    "print(loss.item())\n",
    "\n",
    "gen_tokens = model.generate(torch.zeros((1, 1), dtype=torch.long), 100)\n",
    "print(decode(gen_tokens[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "359e48e5-008c-4674-a134-b09db8471e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use adam optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0587ef9-2dc6-454f-9e4c-cf35eefc2727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4569950103759766\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for i in range(10000):\n",
    "  Xb, Yb = get_batch('train')           # get random batch of training examples\n",
    "  logits, loss = model(Xb, Yb)          # do forward pass and compute loss\n",
    "  optimizer.zero_grad(set_to_none=True) # set grads of model parameters to None\n",
    "  loss.backward()                       # backward pass, compute grads\n",
    "  optimizer.step()                      # update model parameters\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "533f8294-29ef-4b47-ba45-e97395ef04b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S: l, whikstter melceat it cr the, f peditesushistou YOfed\n",
      "Wifer t we of I;\n",
      "PStorithe avend Whatin ct are h,\n",
      "con f!\n",
      "O, obleleapt ailk nd wit, nd alo willext sel nesater nco hechawllionoril?\n",
      "Banou t ve ushihth; IORof ithepailacais h t ast s\n",
      "t Is t be IOME ithutarin!\n",
      "\n",
      "Thend l msk ROLETr t y wie it hisel h mernth ictheng c,\n",
      "ABEMangeilogerquzen t s gng soued thay fre e wh:\n",
      "Tond tinyowasagZetlar t gulan, ns.\n",
      "HAnsthend rdl m tomatedereren prad?\n",
      "m, there band atoy ma GLO:\n",
      "Tald.\n",
      "IIUS:\n",
      "\n",
      "Maver plon us aye\n"
     ]
    }
   ],
   "source": [
    "gen_tokens = model.generate(torch.zeros((1, 1), dtype=torch.long), 500)\n",
    "print(decode(gen_tokens[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d1e4d3-c275-46b6-badb-9bbf560b1e0b",
   "metadata": {},
   "source": [
    "## Math trick to understand self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f17b41-2372-458a-9f8a-483e1a981447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "-----\n",
      "b tensor([[[0., 0., 0.],\n",
      "         [1., 2., 0.],\n",
      "         [0., 1., 2.],\n",
      "         [3., 0., 0.]],\n",
      "\n",
      "        [[2., 1., 3.],\n",
      "         [2., 1., 1.],\n",
      "         [1., 1., 2.],\n",
      "         [2., 0., 1.]]])\n",
      "-----\n",
      "c tensor([[[4., 3., 2.],\n",
      "         [4., 3., 2.],\n",
      "         [4., 3., 2.],\n",
      "         [4., 3., 2.]],\n",
      "\n",
      "        [[7., 3., 7.],\n",
      "         [7., 3., 7.],\n",
      "         [7., 3., 7.],\n",
      "         [7., 3., 7.]]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiply with (T, T) matrix gives us a way to aggregate information in more efficient way\n",
    "# Here just summing up columns\n",
    "a = torch.ones((T, T))\n",
    "b = torch.randint_like(x, 4)\n",
    "c = a @ b\n",
    "\n",
    "print('a', a)\n",
    "print('-----')\n",
    "print('b',  b)\n",
    "print('-----')\n",
    "print('c', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b270351d-d7f3-4416-b461-3264713ae573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n",
      "-----\n",
      "b tensor([[[2., 3., 0.],\n",
      "         [2., 1., 2.],\n",
      "         [1., 1., 1.],\n",
      "         [3., 3., 1.]],\n",
      "\n",
      "        [[3., 2., 2.],\n",
      "         [2., 0., 1.],\n",
      "         [1., 0., 2.],\n",
      "         [0., 3., 1.]]])\n",
      "-----\n",
      "c tensor([[[2., 3., 0.],\n",
      "         [4., 4., 2.],\n",
      "         [5., 5., 3.],\n",
      "         [8., 8., 4.]],\n",
      "\n",
      "        [[3., 2., 2.],\n",
      "         [5., 2., 3.],\n",
      "         [6., 2., 5.],\n",
      "         [6., 5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "# but tril gives it extra power to insist on not looking ahead\n",
    "# and now we have a rolling sum of columns in tensor b (in every batch, as we would like to)\n",
    "a = torch.tril(torch.ones((T,T)))\n",
    "b = torch.randint_like(x, 4)\n",
    "c = a @ b\n",
    "\n",
    "print('a', a)\n",
    "print('-----')\n",
    "print('b',  b)\n",
    "print('-----')\n",
    "print('c', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "770da2e5-8982-438a-baa1-97824cd59c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n",
      "-----\n",
      "b tensor([[[0., 3., 1.],\n",
      "         [1., 3., 1.],\n",
      "         [0., 0., 0.],\n",
      "         [3., 3., 1.]],\n",
      "\n",
      "        [[3., 3., 0.],\n",
      "         [1., 3., 2.],\n",
      "         [2., 1., 1.],\n",
      "         [3., 0., 2.]]])\n",
      "-----\n",
      "c tensor([[[0.0000, 3.0000, 1.0000],\n",
      "         [0.5000, 3.0000, 1.0000],\n",
      "         [0.3333, 2.0000, 0.6667],\n",
      "         [1.0000, 2.2500, 0.7500]],\n",
      "\n",
      "        [[3.0000, 3.0000, 0.0000],\n",
      "         [2.0000, 3.0000, 1.0000],\n",
      "         [2.0000, 2.3333, 1.0000],\n",
      "         [2.2500, 1.7500, 1.2500]]])\n"
     ]
    }
   ],
   "source": [
    "# normalize a, such that rows sum to one and we have rolling average\n",
    "a = torch.tril(torch.ones((T,T)))\n",
    "a = a / a.sum(1, keepdim=True)\n",
    "b = torch.randint_like(x, 4)\n",
    "c = a @ b\n",
    "\n",
    "print('a', a)\n",
    "print('-----')\n",
    "print('b',  b)\n",
    "print('-----')\n",
    "print('c', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "945758b5-74cb-4297-a6d3-2350197e46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in bigram-language model we only consider one token to predict next\n",
    "# to go one step further in utilizing context, we can consider an average of\n",
    "# all previous tokens in the block (version 1)\n",
    "B, T, C = 2, 4, 3 # shape\n",
    "x = torch.randint(4, (B,T,C)) * 1.0\n",
    "xbow = torch.zeros_like(x)\n",
    "for b in range(B):\n",
    "  for t in range(T):\n",
    "    xbow[b, t] = x[b, :t+1].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6760f4b5-85dc-4d57-a400-8c4aeaa5a9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 1., 2.],\n",
       "         [0., 2., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [3., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 2.],\n",
       "         [2., 0., 3.],\n",
       "         [3., 0., 3.],\n",
       "         [3., 1., 1.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86c974ad-ea67-457d-9b83-85dd41f1ef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.0000, 1.0000, 2.0000],\n",
       "         [1.5000, 1.5000, 1.5000],\n",
       "         [1.3333, 1.0000, 1.0000],\n",
       "         [1.7500, 0.7500, 0.7500]],\n",
       "\n",
       "        [[0.0000, 0.0000, 2.0000],\n",
       "         [1.0000, 0.0000, 2.5000],\n",
       "         [1.6667, 0.0000, 2.6667],\n",
       "         [2.0000, 0.2500, 2.2500]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53f9d557-9fa3-4a14-98dc-5d0b2c47ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have created xbow (bag of words), which has agregated information about all previous time steps + self via mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4730f3d-efc8-4625-8646-febdc6b64c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize tril to get rolling average via matmul (version 2)\n",
    "wei = torch.tril(torch.ones((T, T)))\n",
    "wei /= wei.sum(1, keepdim=True)\n",
    "print('wei', wei)\n",
    "xbow2 = wei @ x\n",
    "torch.allclose(xbow, xbow2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62db3e12-0bf9-4798-8dc6-b7c85cb14967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize tril via softmax (version 3)\n",
    "# not for this specific case, but I guess if we use normalization as in version 2\n",
    "# and get unlucky with sum to be very close to 0, we can blow up the tensor\n",
    "# softmax avoids it, usig - max(tensor) so largest number is 0 and exp goes to max 1\n",
    "mask = torch.tril(torch.ones((T, T)))\n",
    "wei = torch.masked_fill(torch.zeros_like(wei), mask==0, -torch.inf)\n",
    "wei = F.softmax(wei, 1)\n",
    "print('wei', wei)\n",
    "xbow2 = wei @ x\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "835ad0d2-b278-4c84-bd17-b7216b48201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move to scaled dotproduct self-attention (version 4)\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "nn.init.xavier_uniform_(key.weight)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "nn.init.xavier_uniform_(query.weight)\n",
    "value = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "nn.init.xavier_uniform_(value.weight)\n",
    "\n",
    "# project into communication subspace\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "# k (B, T, 16) @  q (B, T, 16) [need transpose] --> (B, T, T)\n",
    "wei = q @ k.transpose(-1, -2) # communication in search for affininty between tokens\n",
    "wei = wei * (head_size **-0.5) # scale to preserve var, we don't want softmax downstream\n",
    "# to bo too peaky\n",
    "\n",
    "tril = torch.tril(torch.ones((T,T)))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = torch.masked_fill(wei, tril==0, -torch.inf) # mask forbiden communication\n",
    "wei = F.softmax(wei, dim=-1) # make found affinities to become more like weights\n",
    "\n",
    "# projection of my \"values\"\n",
    "v = value(x) # (B, T, 16)\n",
    "# now we \"weight\" our \"values\" with previously found affinities\n",
    "out = wei @ v # (B, T, 16)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81800400-4615-477d-a73a-ddc51b909c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0403, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default kaming init of linear layer\n",
    "# comment weight init lines in previous cell to see the change\n",
    "key.weight.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "157b0a57-0f42-46c0-ab38-d5f7a00cfd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0731),\n",
       " tensor(1.3544, grad_fn=<VarBackward0>),\n",
       " tensor(1.4393, grad_fn=<VarBackward0>))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.var(), k.var(), q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ebb290f9-0d92-4dae-8c2a-5ab4fb9a7a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.1898, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q @ k.transpose(-1, -2)).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8313f925-6632-4fb9-9d40-5abd66c21dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3244, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((q @ k.transpose(-1, -2))* (head_size **-0.5)).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5acd95de-92b4-4594-8830-03c36a4de6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0499, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "852bc4e1-1bfd-4912-aca9-99cb1757b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8124, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171bcdb-8bc1-43bf-87dd-cb63e8731395",
   "metadata": {},
   "source": [
    "## Explore Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "da71f608-45cf-4706-8914-5168b7bc2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I want to elaborate and explore how different initialization schemas\n",
    "# may influence GPT model training. As we know, given matrices A and B, variance\n",
    "# of A @ B depends multiplicatively on var(A), var(B) and their common shape size\n",
    "# (A.shape[1] == B.shape[0]). As we do a lot of matrix multiplications (and we do\n",
    "# a loooot in GPT), the deeper we go the more variance will increase or decrease\n",
    "# leading to vanishing or exploding activations and eventually gradients, preventing or\n",
    "# slowing down learning. LayerNorm and residual connections employed to help with this issue,\n",
    "# one by renormalizing activations and another by allowing signal to propagate through the layer\n",
    "# unaffected by the layer computation and effectively give a way to gradient flow through these\n",
    "# layers unaffected. The natural question is: does initialization really matter?\n",
    "# GPT 1 paper says, that given extensive use of LayerNorm we simply initialize weights with N(0, 0.02)\n",
    "# But if LayerNorm and residual connections would solve all the problems, why bother with specific init strategy?\n",
    "# My assumption is, that it does matter and along with LayerNorm and residual connections allow to train \n",
    "# very deep and wide transformers and achieve better loss minima.\n",
    "\n",
    "# Might be actually because of attention softmaxes become more and more peaky with activation var (and some values) grow to large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2e133a6d-718c-49b9-9d92-8d59764fa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, to answer the question or at least to find a hint, I would like to compare different initializations:\n",
    "# 1. Default (pytorch linear: kamin uniform, embedding: N(0, 1)); 2. One I found tinkering with attention\n",
    "# in the previous section (xavier uniform); 3. GPT 1 paper N(0, 0.02) for all linear layers and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "06a27393-4c7a-4f7b-89bf-5c291082c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "learining_rate = 3e-4\n",
    "n_embd = 384\n",
    "n_heads = 6\n",
    "n_layers = 6\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "12261f5e-578e-4a74-bee0-c3d1208ac11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "with open(\"input.txt\", mode=\"r\") as f:\n",
    "    words = f.read()\n",
    "\n",
    "# Vocab and tokenizer\n",
    "vocab = sorted(set(words))\n",
    "vocab_size = len(vocab)\n",
    "# mappings\n",
    "stoi = {c: i for i, c in enumerate(vocab)}\n",
    "itos = {i: c for i, c in enumerate(vocab)}\n",
    "# encoder and decoder\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "# to tensor and train/test split\n",
    "data = torch.tensor(encode(words), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train = data[:n]\n",
    "test = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b94c0d2b-8ebc-425e-873e-9cfe6f103b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones((block_size, block_size))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q = self.query(x)  # (B, T, H)\n",
    "        k = self.key(x)  # (B, T, H)\n",
    "        aff = q @ k.transpose(-1, -2)  # (B, T, T)\n",
    "        aff *= self.head_size**-0.5  # scale to preserve var\n",
    "        # prevent communication with future tokens\n",
    "        aff = torch.masked_fill(aff, self.tril[:T, :T] == 0, -torch.inf)\n",
    "        aff = F.softmax(aff, dim=-1)\n",
    "        aff = self.do(aff)\n",
    "        # value\n",
    "        v = self.value(x)  # (B, T, H)\n",
    "        out = aff @ v  # (B, T, H)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Multihead Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttention(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(\n",
    "            n_heads * head_size, n_embd\n",
    "        )  # in case we need to project back into C\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B, T, C) and H = C / n_heads\n",
    "        x = torch.concat([head(x) for head in self.heads], dim=-1)  # (B,T,C)\n",
    "        out = self.do(self.proj(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "# Feed Forward\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd * 4, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B,T,C)\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Block - multi-head attention followed by feed-forward\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_heads, head_size)\n",
    "        self.ff = FeedForward()\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B,T,C)\n",
    "        # pre-norm\n",
    "        # x = x + self.mha(self.ln1(x))  # (B,T,C)\n",
    "        # x = x + self.ff(self.ln2(x))  # (B,T,C)\n",
    "        # post-norm\n",
    "        x = self.ln1(x + self.mha(x))\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model definition\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, init_fn):\n",
    "        super().__init__()\n",
    "        self.token_embed_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embed_table = nn.Embedding(block_size, n_embd)\n",
    "        self.emb_do = nn.Dropout(dropout)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(n_heads, n_embd // n_heads) for _ in range(n_layers)]\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        tok_embeds = self.token_embed_table(x)  # (B, T, C)\n",
    "        pos_embeds = self.position_embed_table(torch.arange(T, device=device))  # (T, C)\n",
    "        x = tok_embeds + pos_embeds  # (B, T, C)\n",
    "        x = self.emb_do(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)  # (B, T, C)\n",
    "        x = self.ln(x)\n",
    "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ded7ed12-56d7-4aa5-a51c-16a55b952d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch of random examples\n",
    "def get_batch(split):\n",
    "  data = train if split == \"train\" else test\n",
    "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "  y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "  x, y = x.to(device), y.to(device)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8e4a1ab9-7fc4-461d-8ef1-23931fe2af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_default(m):\n",
    "  pass\n",
    "\n",
    "def init_xavier_uniform(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    if m.bias is not None:\n",
    "      nn.init.zeros_(m.bias)\n",
    "  if isinstance(m, nn.Embedding):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def init_normal(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if m.bias is not None:\n",
    "      nn.init.zeros_(m.bias)\n",
    "  if isinstance(m, nn.Embedding):\n",
    "    nn.init.normal_(m.weight, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c5085520-0731-4b1b-b54f-efe7c01a529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = GPTLanguageModel(init_normal)\n",
    "model.train()\n",
    "model.to(device)\n",
    "# remove weight decay for now\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learining_rate, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "65cfb394-05af-41d8-964d-90080e59e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "Xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4dc2ce7e-9ade-4071-9754-e76a23d82809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits var at iter 1: tensor(0.1509, device='cuda:0', grad_fn=<VarBackward0>)\n",
      "loss 4.241641998291016\n",
      "logits var after 100 iterations: tensor(3.0261, device='cuda:0', grad_fn=<VarBackward0>)\n",
      "loss 1.3023432493209839\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "  logits, loss = model(Xb, yb)\n",
    "  if i == 0:\n",
    "    print('logits var at iter 1:', logits.var())\n",
    "    print('loss', loss.item())\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "print('logits var after 100 iterations:', logits.var())\n",
    "print('loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c16e2bda-64ed-44c7-b00a-5d9e1985476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Default pytorch initialization: var(logits) @1st iteration = 0.32; @100th iteration = 3.47\n",
    "# 2. Xavier uniform initialization: @1st iteration = 1.72; @100th iteration = 6.5\n",
    "# 3. N(0, 0.02) initialization: @1st iteration = 0.135; @100th iteration = 2.76\n",
    "\n",
    "# This experiment shows, that N(0,0.02) init shows the smallest absolute increase of logits variance,\n",
    "# potentially allowing network to train longer w/o activations growth to fast and slowing down training\n",
    "# in the later stages (through softmax becoming too peaky and/or overall zeroing down too many gradients\n",
    "# too soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563ba02-7696-44a0-8188-8e7f538dd756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
